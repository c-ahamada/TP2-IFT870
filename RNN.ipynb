{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 17:55:47.835073: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-04 17:55:47.838057: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-04 17:55:47.863141: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-04 17:55:47.863166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-04 17:55:47.863998: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-04 17:55:47.868957: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-04 17:55:47.869293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-04 17:55:48.483057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from scikeras.wrappers import KerasClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:49.472310441Z",
     "start_time": "2024-04-04T21:55:47.525562028Z"
    }
   },
   "id": "99e205d56b927c92"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "orders_distance_stores_softmax = pd.read_csv(\"données/orders_distance_stores_softmax.csv\", index_col=0)\n",
    "orders_products_prior_specials = pd.read_csv(\"données/order_products__prior_specials.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:49.732939051Z",
     "start_time": "2024-04-04T21:55:49.474376209Z"
    }
   },
   "id": "e8cdbc909d8a429a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:49.961639358Z",
     "start_time": "2024-04-04T21:55:49.737228114Z"
    }
   },
   "outputs": [],
   "source": [
    "orders = pd.merge(orders_distance_stores_softmax, orders_products_prior_specials, on='order_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['user_id', 'store_id', 'distance', 'order_id', 'eval_set',\n       'order_number', 'order_dow', 'order_hour_of_day',\n       'days_since_prior_order', 'product_id', 'add_to_cart_order',\n       'reordered', 'special'],\n      dtype='object')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show columns with their types\n",
    "orders.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:49.967810658Z",
     "start_time": "2024-04-04T21:55:49.965100639Z"
    }
   },
   "id": "6f8d8340dda20b26"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "orders = orders.sample(frac=0.05, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:50.043376582Z",
     "start_time": "2024-04-04T21:55:49.971961647Z"
    }
   },
   "id": "ea72ac611097761c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         user_id  store_id  distance  order_id eval_set  order_number  \\\n86058      12166         3  2.772836    243435    prior            88   \n1170067   205543         9  0.386416   1425899    prior            22   \n852677    148902         0  0.349984   1455360    prior            36   \n346398     59106         9  1.040265   2683498    prior            83   \n1045727   182401         1  0.804848   2474304    prior            86   \n\n         order_dow  order_hour_of_day  days_since_prior_order  product_id  \\\n86058            0                 13                    21.0       48290   \n1170067          6                  9                     0.0        3481   \n852677           4                 18                     4.0       41720   \n346398           2                 17                     3.0        5876   \n1045727          5                 14                     5.0        4562   \n\n         add_to_cart_order  reordered  special  \n86058                   10          1        0  \n1170067                  6          1        0  \n852677                   8          1       30  \n346398                   5          1        0  \n1045727                 15          1       15  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>store_id</th>\n      <th>distance</th>\n      <th>order_id</th>\n      <th>eval_set</th>\n      <th>order_number</th>\n      <th>order_dow</th>\n      <th>order_hour_of_day</th>\n      <th>days_since_prior_order</th>\n      <th>product_id</th>\n      <th>add_to_cart_order</th>\n      <th>reordered</th>\n      <th>special</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>86058</th>\n      <td>12166</td>\n      <td>3</td>\n      <td>2.772836</td>\n      <td>243435</td>\n      <td>prior</td>\n      <td>88</td>\n      <td>0</td>\n      <td>13</td>\n      <td>21.0</td>\n      <td>48290</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1170067</th>\n      <td>205543</td>\n      <td>9</td>\n      <td>0.386416</td>\n      <td>1425899</td>\n      <td>prior</td>\n      <td>22</td>\n      <td>6</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>3481</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>852677</th>\n      <td>148902</td>\n      <td>0</td>\n      <td>0.349984</td>\n      <td>1455360</td>\n      <td>prior</td>\n      <td>36</td>\n      <td>4</td>\n      <td>18</td>\n      <td>4.0</td>\n      <td>41720</td>\n      <td>8</td>\n      <td>1</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>346398</th>\n      <td>59106</td>\n      <td>9</td>\n      <td>1.040265</td>\n      <td>2683498</td>\n      <td>prior</td>\n      <td>83</td>\n      <td>2</td>\n      <td>17</td>\n      <td>3.0</td>\n      <td>5876</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1045727</th>\n      <td>182401</td>\n      <td>1</td>\n      <td>0.804848</td>\n      <td>2474304</td>\n      <td>prior</td>\n      <td>86</td>\n      <td>5</td>\n      <td>14</td>\n      <td>5.0</td>\n      <td>4562</td>\n      <td>15</td>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the first 5 rows\n",
    "orders.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:50.058164189Z",
     "start_time": "2024-04-04T21:55:50.045700130Z"
    }
   },
   "id": "5f9621d7496691ac"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#TO REDO\n",
    "orders.dropna(inplace=True)\n",
    "# drop the eval_set column\n",
    "orders.drop(columns=['eval_set'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:50.096072592Z",
     "start_time": "2024-04-04T21:55:50.058427725Z"
    }
   },
   "id": "57d3d28e1d980ae"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (37072, 11)\n",
      "Shape of X_val: (9269, 11)\n",
      "Shape of X_test: (11586, 11)\n"
     ]
    }
   ],
   "source": [
    "# Charger vos données depuis votre DataFrame\n",
    "# Assumons que votre DataFrame est nommé \"data\"\n",
    "\n",
    "# Séparer les fonctionnalités (X) de la cible (y)\n",
    "X = orders.drop(columns=['reordered'])\n",
    "y = orders['reordered']\n",
    "\n",
    "# Diviser l'ensemble de données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Diviser l'ensemble d'entraînement en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vérifier les formes des ensembles créés\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:50.125139579Z",
     "start_time": "2024-04-04T21:55:50.075087620Z"
    }
   },
   "id": "2cca43413c784d53"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0.],\n       [0., 1.],\n       [0., 1.],\n       ...,\n       [1., 0.],\n       [0., 1.],\n       [0., 1.]], dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming y_train and y_test are your target labels\n",
    "# Convert them to one-hot encoded vectors\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "y_val_one_hot = to_categorical(y_val)\n",
    "\n",
    "y_train_one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T21:55:50.125371557Z",
     "start_time": "2024-04-04T21:55:50.117683535Z"
    }
   },
   "id": "551df5898f8fb88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prédiction de l'attribut re-ordered"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e58cfd501bb0a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n",
    "metrics_fn = keras.metrics.BinaryAccuracy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d527b722c7ac8053"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 905us/step - loss: 2621.7625 - binary_accuracy: 0.6883 - val_loss: 2643.1216 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 756us/step - loss: 1948.1294 - binary_accuracy: 0.6623 - val_loss: 1944.6128 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 755us/step - loss: 1995.0791 - binary_accuracy: 0.6631 - val_loss: 3809.6641 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 753us/step - loss: 1791.8546 - binary_accuracy: 0.6627 - val_loss: 3078.5962 - val_binary_accuracy: 0.2429\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 758us/step - loss: 2153.2078 - binary_accuracy: 0.6621 - val_loss: 1264.2605 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 759us/step - loss: 1360.8098 - binary_accuracy: 0.6648 - val_loss: 1947.0850 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 754us/step - loss: 1289.4417 - binary_accuracy: 0.6644 - val_loss: 2244.3069 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 756us/step - loss: 1827.5361 - binary_accuracy: 0.6670 - val_loss: 1981.9312 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 757us/step - loss: 1332.5178 - binary_accuracy: 0.6681 - val_loss: 616.4504 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 754us/step - loss: 1508.8258 - binary_accuracy: 0.6691 - val_loss: 3088.0923 - val_binary_accuracy: 0.2462\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 917us/step - loss: 1702.5383 - binary_accuracy: 0.5713 - val_loss: 1761.2784 - val_binary_accuracy: 0.7685\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 773us/step - loss: 1572.1375 - binary_accuracy: 0.6595 - val_loss: 253.8628 - val_binary_accuracy: 0.7717\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 776us/step - loss: 1353.9355 - binary_accuracy: 0.6664 - val_loss: 79.2385 - val_binary_accuracy: 0.5477\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 772us/step - loss: 901.0884 - binary_accuracy: 0.6672 - val_loss: 398.9613 - val_binary_accuracy: 0.7829\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 818.9370 - binary_accuracy: 0.6641 - val_loss: 2198.1265 - val_binary_accuracy: 0.2567\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 603.9127 - binary_accuracy: 0.6670 - val_loss: 1495.3561 - val_binary_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 648.2139 - binary_accuracy: 0.6662 - val_loss: 211.9770 - val_binary_accuracy: 0.2772\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 772us/step - loss: 604.1782 - binary_accuracy: 0.6659 - val_loss: 841.2089 - val_binary_accuracy: 0.2542\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 791us/step - loss: 545.2009 - binary_accuracy: 0.6662 - val_loss: 109.0736 - val_binary_accuracy: 0.7652\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 428.1198 - binary_accuracy: 0.6716 - val_loss: 912.3508 - val_binary_accuracy: 0.2540\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1258.2448 - binary_accuracy: 0.5712 - val_loss: 3823.6868 - val_binary_accuracy: 0.2260\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1232.7786 - binary_accuracy: 0.6581 - val_loss: 1186.8623 - val_binary_accuracy: 0.7746\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 1024.6259 - binary_accuracy: 0.6645 - val_loss: 103.6954 - val_binary_accuracy: 0.3686\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 901.0825 - binary_accuracy: 0.6637 - val_loss: 750.1453 - val_binary_accuracy: 0.7796\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 877.7991 - binary_accuracy: 0.6646 - val_loss: 320.8969 - val_binary_accuracy: 0.2460\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 921.9527 - binary_accuracy: 0.6621 - val_loss: 591.3640 - val_binary_accuracy: 0.7785\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 780us/step - loss: 724.5911 - binary_accuracy: 0.6737 - val_loss: 1786.6530 - val_binary_accuracy: 0.7846\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 761.9977 - binary_accuracy: 0.6676 - val_loss: 561.5402 - val_binary_accuracy: 0.7824\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 803.5347 - binary_accuracy: 0.6703 - val_loss: 903.6843 - val_binary_accuracy: 0.2568\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 621.4604 - binary_accuracy: 0.6682 - val_loss: 71.9562 - val_binary_accuracy: 0.7443\n",
      "116/116 [==============================] - 0s 524us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 936us/step - loss: 2537.9448 - binary_accuracy: 0.6796 - val_loss: 858.1761 - val_binary_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 1011.1477 - binary_accuracy: 0.6626 - val_loss: 138.7505 - val_binary_accuracy: 0.7566\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 1016.1892 - binary_accuracy: 0.6631 - val_loss: 465.2598 - val_binary_accuracy: 0.2605\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 797us/step - loss: 931.2511 - binary_accuracy: 0.6623 - val_loss: 813.8853 - val_binary_accuracy: 0.2555\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 818.8958 - binary_accuracy: 0.6662 - val_loss: 517.0142 - val_binary_accuracy: 0.7717\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 959.9213 - binary_accuracy: 0.6639 - val_loss: 222.6327 - val_binary_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 762.6668 - binary_accuracy: 0.6646 - val_loss: 678.6316 - val_binary_accuracy: 0.2581\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 852.9927 - binary_accuracy: 0.6686 - val_loss: 1045.3878 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 850.4869 - binary_accuracy: 0.6670 - val_loss: 755.8578 - val_binary_accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 812.0810 - binary_accuracy: 0.6678 - val_loss: 781.2968 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 686us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 930us/step - loss: 27079.7520 - binary_accuracy: 0.6850 - val_loss: 1239.2458 - val_binary_accuracy: 0.7514\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 2218.5671 - binary_accuracy: 0.6638 - val_loss: 2527.3501 - val_binary_accuracy: 0.7837\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 2375.4417 - binary_accuracy: 0.6657 - val_loss: 1960.7103 - val_binary_accuracy: 0.7837\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1837.4816 - binary_accuracy: 0.6665 - val_loss: 608.5302 - val_binary_accuracy: 0.7389\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1987.3910 - binary_accuracy: 0.6654 - val_loss: 1413.0596 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 2166.0527 - binary_accuracy: 0.6658 - val_loss: 1649.4265 - val_binary_accuracy: 0.7835\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1684.9476 - binary_accuracy: 0.6676 - val_loss: 2805.5850 - val_binary_accuracy: 0.2576\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1494.5245 - binary_accuracy: 0.6665 - val_loss: 3094.1768 - val_binary_accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 1408.6201 - binary_accuracy: 0.6685 - val_loss: 3959.0869 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 1405.7340 - binary_accuracy: 0.6679 - val_loss: 1458.0084 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 504us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 908us/step - loss: 2207.5776 - binary_accuracy: 0.6854 - val_loss: 2208.6033 - val_binary_accuracy: 0.7838\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 762us/step - loss: 1778.6393 - binary_accuracy: 0.6620 - val_loss: 3755.2395 - val_binary_accuracy: 0.7796\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 763us/step - loss: 2211.4224 - binary_accuracy: 0.6582 - val_loss: 1665.6211 - val_binary_accuracy: 0.7713\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 763us/step - loss: 1933.1471 - binary_accuracy: 0.6616 - val_loss: 800.9053 - val_binary_accuracy: 0.7805\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 766us/step - loss: 1677.6819 - binary_accuracy: 0.6646 - val_loss: 478.9928 - val_binary_accuracy: 0.7808\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1684.9657 - binary_accuracy: 0.6602 - val_loss: 1002.1530 - val_binary_accuracy: 0.7838\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 1559.3735 - binary_accuracy: 0.6649 - val_loss: 1506.0468 - val_binary_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 781us/step - loss: 1626.6063 - binary_accuracy: 0.6635 - val_loss: 196.2241 - val_binary_accuracy: 0.3533\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 1130.9438 - binary_accuracy: 0.6710 - val_loss: 263.4555 - val_binary_accuracy: 0.7786\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 768us/step - loss: 1589.1313 - binary_accuracy: 0.6645 - val_loss: 121.6479 - val_binary_accuracy: 0.6994\n",
      "116/116 [==============================] - 0s 502us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 912us/step - loss: 4915.0952 - binary_accuracy: 0.6663 - val_loss: 3277.7915 - val_binary_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 1687.0715 - binary_accuracy: 0.6590 - val_loss: 3316.9800 - val_binary_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 773us/step - loss: 1450.5236 - binary_accuracy: 0.6625 - val_loss: 1215.0245 - val_binary_accuracy: 0.7839\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 767us/step - loss: 1500.7483 - binary_accuracy: 0.6596 - val_loss: 2660.5403 - val_binary_accuracy: 0.2284\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 769us/step - loss: 1126.5422 - binary_accuracy: 0.6614 - val_loss: 1028.3784 - val_binary_accuracy: 0.7830\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 1111.0735 - binary_accuracy: 0.6610 - val_loss: 2490.8232 - val_binary_accuracy: 0.2542\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1140.0071 - binary_accuracy: 0.6629 - val_loss: 640.3746 - val_binary_accuracy: 0.7793\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1049.0992 - binary_accuracy: 0.6617 - val_loss: 924.9725 - val_binary_accuracy: 0.7788\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 781us/step - loss: 921.5366 - binary_accuracy: 0.6655 - val_loss: 1667.0739 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 929.8751 - binary_accuracy: 0.6639 - val_loss: 1549.0938 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 512us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 912us/step - loss: 1627.1610 - binary_accuracy: 0.6892 - val_loss: 815.5238 - val_binary_accuracy: 0.7808\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 765us/step - loss: 1045.1495 - binary_accuracy: 0.6658 - val_loss: 195.7737 - val_binary_accuracy: 0.7116\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 757us/step - loss: 1147.9230 - binary_accuracy: 0.6678 - val_loss: 222.1005 - val_binary_accuracy: 0.7602\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 1011.4369 - binary_accuracy: 0.6642 - val_loss: 2236.4558 - val_binary_accuracy: 0.7830\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 913.0302 - binary_accuracy: 0.6629 - val_loss: 112.1590 - val_binary_accuracy: 0.7753\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 762us/step - loss: 918.3644 - binary_accuracy: 0.6670 - val_loss: 1368.7643 - val_binary_accuracy: 0.2338\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 764us/step - loss: 936.7869 - binary_accuracy: 0.6650 - val_loss: 1229.2822 - val_binary_accuracy: 0.7831\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 971.7206 - binary_accuracy: 0.6696 - val_loss: 3992.8550 - val_binary_accuracy: 0.2315\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 766us/step - loss: 793.0361 - binary_accuracy: 0.6652 - val_loss: 390.8896 - val_binary_accuracy: 0.2581\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 774us/step - loss: 850.1974 - binary_accuracy: 0.6650 - val_loss: 516.8647 - val_binary_accuracy: 0.7739\n",
      "116/116 [==============================] - 0s 508us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 908us/step - loss: 1469.4194 - binary_accuracy: 0.6891 - val_loss: 1528.4451 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 1118.3859 - binary_accuracy: 0.6614 - val_loss: 786.6539 - val_binary_accuracy: 0.2518\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 1159.4984 - binary_accuracy: 0.6663 - val_loss: 395.7116 - val_binary_accuracy: 0.6729\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 763us/step - loss: 926.8817 - binary_accuracy: 0.6621 - val_loss: 1012.3099 - val_binary_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 980.1558 - binary_accuracy: 0.6665 - val_loss: 128.7493 - val_binary_accuracy: 0.7283\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 773us/step - loss: 1068.0928 - binary_accuracy: 0.6607 - val_loss: 77.8326 - val_binary_accuracy: 0.4777\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 795.6476 - binary_accuracy: 0.6639 - val_loss: 245.2769 - val_binary_accuracy: 0.7773\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 674.0673 - binary_accuracy: 0.6709 - val_loss: 1539.3148 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 822us/step - loss: 803.8100 - binary_accuracy: 0.6684 - val_loss: 198.2993 - val_binary_accuracy: 0.7159\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 704.8401 - binary_accuracy: 0.6687 - val_loss: 633.3672 - val_binary_accuracy: 0.2621\n",
      "116/116 [==============================] - 0s 523us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 904us/step - loss: 2180.5696 - binary_accuracy: 0.5645 - val_loss: 4456.2969 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 759us/step - loss: 1457.4786 - binary_accuracy: 0.6651 - val_loss: 943.3934 - val_binary_accuracy: 0.7831\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 760us/step - loss: 1306.7336 - binary_accuracy: 0.6609 - val_loss: 1701.9135 - val_binary_accuracy: 0.7850\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1387.3630 - binary_accuracy: 0.6629 - val_loss: 2864.1643 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 1220.7391 - binary_accuracy: 0.6668 - val_loss: 277.5210 - val_binary_accuracy: 0.7152\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 761us/step - loss: 896.1906 - binary_accuracy: 0.6667 - val_loss: 1809.2257 - val_binary_accuracy: 0.7797\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 1221.0763 - binary_accuracy: 0.6645 - val_loss: 2823.9944 - val_binary_accuracy: 0.7846\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 775us/step - loss: 922.5009 - binary_accuracy: 0.6626 - val_loss: 1319.5369 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 774us/step - loss: 817.0184 - binary_accuracy: 0.6722 - val_loss: 866.0486 - val_binary_accuracy: 0.2615\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 865.3880 - binary_accuracy: 0.6662 - val_loss: 169.0051 - val_binary_accuracy: 0.7700\n",
      "116/116 [==============================] - 0s 522us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 908us/step - loss: 3033.7742 - binary_accuracy: 0.6906 - val_loss: 228.9976 - val_binary_accuracy: 0.7549\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 772us/step - loss: 1769.1921 - binary_accuracy: 0.6646 - val_loss: 1808.6289 - val_binary_accuracy: 0.7730\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 769us/step - loss: 1784.1036 - binary_accuracy: 0.6608 - val_loss: 3494.8611 - val_binary_accuracy: 0.2470\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 1254.5477 - binary_accuracy: 0.6621 - val_loss: 2309.3547 - val_binary_accuracy: 0.7753\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1389.1725 - binary_accuracy: 0.6631 - val_loss: 1271.5532 - val_binary_accuracy: 0.7790\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1432.6722 - binary_accuracy: 0.6642 - val_loss: 1245.4960 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 785us/step - loss: 1136.8826 - binary_accuracy: 0.6653 - val_loss: 766.8373 - val_binary_accuracy: 0.2458\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 781us/step - loss: 1129.8065 - binary_accuracy: 0.6678 - val_loss: 325.5852 - val_binary_accuracy: 0.7798\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 1070.6195 - binary_accuracy: 0.6658 - val_loss: 1001.0462 - val_binary_accuracy: 0.7830\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 1149.3903 - binary_accuracy: 0.6674 - val_loss: 2193.1096 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 536us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 905us/step - loss: 9218.5957 - binary_accuracy: 0.6733 - val_loss: 433.1152 - val_binary_accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 1612.2982 - binary_accuracy: 0.6660 - val_loss: 807.0007 - val_binary_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 761us/step - loss: 1134.3130 - binary_accuracy: 0.6639 - val_loss: 276.5818 - val_binary_accuracy: 0.7482\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 775us/step - loss: 1080.3617 - binary_accuracy: 0.6645 - val_loss: 779.7045 - val_binary_accuracy: 0.2766\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 772us/step - loss: 1141.9835 - binary_accuracy: 0.6623 - val_loss: 703.8549 - val_binary_accuracy: 0.7834\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 771us/step - loss: 1293.4796 - binary_accuracy: 0.6680 - val_loss: 2199.8604 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 780us/step - loss: 1044.3311 - binary_accuracy: 0.6647 - val_loss: 1034.1057 - val_binary_accuracy: 0.7801\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 775us/step - loss: 993.2415 - binary_accuracy: 0.6628 - val_loss: 782.2947 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 774.4733 - binary_accuracy: 0.6664 - val_loss: 2724.9998 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 769us/step - loss: 739.2113 - binary_accuracy: 0.6679 - val_loss: 645.0889 - val_binary_accuracy: 0.7850\n",
      "116/116 [==============================] - 0s 527us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 925us/step - loss: 3587.5581 - binary_accuracy: 0.6962 - val_loss: 1587.5510 - val_binary_accuracy: 0.7770\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 1031.5089 - binary_accuracy: 0.6642 - val_loss: 1683.6886 - val_binary_accuracy: 0.7782\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1180.8047 - binary_accuracy: 0.6619 - val_loss: 1688.9430 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1383.5931 - binary_accuracy: 0.6669 - val_loss: 2227.8928 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 1215.4435 - binary_accuracy: 0.6674 - val_loss: 2726.8533 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 791us/step - loss: 962.9563 - binary_accuracy: 0.6695 - val_loss: 1562.1902 - val_binary_accuracy: 0.2809\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 1106.4343 - binary_accuracy: 0.6684 - val_loss: 926.5657 - val_binary_accuracy: 0.7834\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 847.2029 - binary_accuracy: 0.6646 - val_loss: 1321.9912 - val_binary_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 785us/step - loss: 757.0354 - binary_accuracy: 0.6707 - val_loss: 51.6913 - val_binary_accuracy: 0.6974\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 733.1310 - binary_accuracy: 0.6712 - val_loss: 973.4399 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 514us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 927us/step - loss: 2738.8477 - binary_accuracy: 0.6847 - val_loss: 253.7230 - val_binary_accuracy: 0.3280\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 804.1089 - binary_accuracy: 0.6602 - val_loss: 1010.0506 - val_binary_accuracy: 0.7805\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 794.2898 - binary_accuracy: 0.6607 - val_loss: 2901.2627 - val_binary_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 745.4476 - binary_accuracy: 0.6608 - val_loss: 999.1791 - val_binary_accuracy: 0.7838\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 443.0841 - binary_accuracy: 0.6617 - val_loss: 541.4329 - val_binary_accuracy: 0.2412\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 631.9277 - binary_accuracy: 0.6672 - val_loss: 331.7194 - val_binary_accuracy: 0.7747\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 544.2669 - binary_accuracy: 0.6665 - val_loss: 381.0157 - val_binary_accuracy: 0.7661\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 458.3500 - binary_accuracy: 0.6670 - val_loss: 1322.7878 - val_binary_accuracy: 0.7834\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 367.4094 - binary_accuracy: 0.6686 - val_loss: 201.0526 - val_binary_accuracy: 0.7696\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 781us/step - loss: 351.5812 - binary_accuracy: 0.6653 - val_loss: 270.0654 - val_binary_accuracy: 0.7783\n",
      "116/116 [==============================] - 0s 501us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 911us/step - loss: 3505.1238 - binary_accuracy: 0.6919 - val_loss: 1654.6019 - val_binary_accuracy: 0.7809\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 777us/step - loss: 2212.1799 - binary_accuracy: 0.6616 - val_loss: 4109.0303 - val_binary_accuracy: 0.2288\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1967.6880 - binary_accuracy: 0.6613 - val_loss: 1434.4254 - val_binary_accuracy: 0.7837\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 2133.1489 - binary_accuracy: 0.6650 - val_loss: 396.2444 - val_binary_accuracy: 0.7646\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 2085.6807 - binary_accuracy: 0.6636 - val_loss: 887.1390 - val_binary_accuracy: 0.3768\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1983.8744 - binary_accuracy: 0.6644 - val_loss: 6619.1895 - val_binary_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 1971.5999 - binary_accuracy: 0.6681 - val_loss: 1883.9137 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 1651.2921 - binary_accuracy: 0.6677 - val_loss: 3899.4231 - val_binary_accuracy: 0.7825\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 785us/step - loss: 1737.2825 - binary_accuracy: 0.6630 - val_loss: 1364.4805 - val_binary_accuracy: 0.7838\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 1562.8262 - binary_accuracy: 0.6648 - val_loss: 1184.8124 - val_binary_accuracy: 0.7780\n",
      "116/116 [==============================] - 0s 520us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 903us/step - loss: 4694.1152 - binary_accuracy: 0.6865 - val_loss: 1600.5342 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 763us/step - loss: 1581.8674 - binary_accuracy: 0.6640 - val_loss: 1554.1276 - val_binary_accuracy: 0.7793\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 1518.9352 - binary_accuracy: 0.6627 - val_loss: 778.5810 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 797us/step - loss: 1270.8777 - binary_accuracy: 0.6616 - val_loss: 749.1208 - val_binary_accuracy: 0.7743\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 1290.6622 - binary_accuracy: 0.6649 - val_loss: 1879.5132 - val_binary_accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 944us/step - loss: 979.7480 - binary_accuracy: 0.6659 - val_loss: 1444.5304 - val_binary_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 797us/step - loss: 1070.4878 - binary_accuracy: 0.6646 - val_loss: 2023.6254 - val_binary_accuracy: 0.7817\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 1005.8838 - binary_accuracy: 0.6682 - val_loss: 351.6293 - val_binary_accuracy: 0.7766\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 935.4606 - binary_accuracy: 0.6622 - val_loss: 881.0254 - val_binary_accuracy: 0.7821\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 897.3838 - binary_accuracy: 0.6679 - val_loss: 921.3196 - val_binary_accuracy: 0.7670\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 915us/step - loss: 3588.6140 - binary_accuracy: 0.6859 - val_loss: 1038.4871 - val_binary_accuracy: 0.7092\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 775us/step - loss: 2396.1885 - binary_accuracy: 0.6666 - val_loss: 3509.9512 - val_binary_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 774us/step - loss: 2962.9739 - binary_accuracy: 0.6648 - val_loss: 4298.1152 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 2221.4741 - binary_accuracy: 0.6625 - val_loss: 1848.6294 - val_binary_accuracy: 0.7780\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 2223.7849 - binary_accuracy: 0.6609 - val_loss: 601.9460 - val_binary_accuracy: 0.3711\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 2520.1257 - binary_accuracy: 0.6643 - val_loss: 86.7411 - val_binary_accuracy: 0.6426\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 2109.6406 - binary_accuracy: 0.6652 - val_loss: 3152.0752 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 2554.4417 - binary_accuracy: 0.6604 - val_loss: 1472.2168 - val_binary_accuracy: 0.7727\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 2438.5999 - binary_accuracy: 0.6596 - val_loss: 1664.5186 - val_binary_accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 791us/step - loss: 1820.7379 - binary_accuracy: 0.6620 - val_loss: 2317.2205 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 507us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 906us/step - loss: 2877.6445 - binary_accuracy: 0.6873 - val_loss: 826.9464 - val_binary_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 1617.1761 - binary_accuracy: 0.6647 - val_loss: 2213.1152 - val_binary_accuracy: 0.7798\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 760us/step - loss: 1179.8577 - binary_accuracy: 0.6640 - val_loss: 1710.1854 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 1211.5656 - binary_accuracy: 0.6642 - val_loss: 339.3318 - val_binary_accuracy: 0.7674\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 926.6941 - binary_accuracy: 0.6667 - val_loss: 367.6825 - val_binary_accuracy: 0.7820\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 850.8746 - binary_accuracy: 0.6679 - val_loss: 3430.4912 - val_binary_accuracy: 0.2159\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 957.1674 - binary_accuracy: 0.6666 - val_loss: 1583.2917 - val_binary_accuracy: 0.2219\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 808.0021 - binary_accuracy: 0.6674 - val_loss: 1119.3516 - val_binary_accuracy: 0.7850\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 701.6630 - binary_accuracy: 0.6697 - val_loss: 1459.0876 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 550.6033 - binary_accuracy: 0.6714 - val_loss: 454.4798 - val_binary_accuracy: 0.7811\n",
      "116/116 [==============================] - 0s 516us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 931us/step - loss: 1726.1929 - binary_accuracy: 0.6856 - val_loss: 324.4478 - val_binary_accuracy: 0.7560\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 1015.6945 - binary_accuracy: 0.6620 - val_loss: 128.8651 - val_binary_accuracy: 0.7775\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 834.2675 - binary_accuracy: 0.6616 - val_loss: 2232.3164 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 852.3585 - binary_accuracy: 0.6634 - val_loss: 1067.2480 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 727.6116 - binary_accuracy: 0.6644 - val_loss: 2153.9475 - val_binary_accuracy: 0.2178\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 661.7440 - binary_accuracy: 0.6680 - val_loss: 575.8522 - val_binary_accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 841.1429 - binary_accuracy: 0.6664 - val_loss: 429.2044 - val_binary_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 867.0471 - binary_accuracy: 0.6686 - val_loss: 538.8037 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 791.2281 - binary_accuracy: 0.6647 - val_loss: 1838.5468 - val_binary_accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 741.9800 - binary_accuracy: 0.6689 - val_loss: 154.2413 - val_binary_accuracy: 0.7669\n",
      "116/116 [==============================] - 0s 502us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 920us/step - loss: 8099.0854 - binary_accuracy: 0.6808 - val_loss: 4545.7285 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 2632.3730 - binary_accuracy: 0.6656 - val_loss: 1153.4873 - val_binary_accuracy: 0.7733\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 2048.5481 - binary_accuracy: 0.6631 - val_loss: 1270.8027 - val_binary_accuracy: 0.7793\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1825.2025 - binary_accuracy: 0.6666 - val_loss: 235.0381 - val_binary_accuracy: 0.4144\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 1941.5520 - binary_accuracy: 0.6668 - val_loss: 883.0476 - val_binary_accuracy: 0.7781\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 1921.6851 - binary_accuracy: 0.6678 - val_loss: 3198.9141 - val_binary_accuracy: 0.7789\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2070.1921 - binary_accuracy: 0.6660 - val_loss: 1559.8453 - val_binary_accuracy: 0.7817\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1824.3314 - binary_accuracy: 0.6670 - val_loss: 1171.5764 - val_binary_accuracy: 0.7840\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 1498.7598 - binary_accuracy: 0.6679 - val_loss: 2281.5916 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 796us/step - loss: 1243.1935 - binary_accuracy: 0.6689 - val_loss: 708.6761 - val_binary_accuracy: 0.7852\n",
      "116/116 [==============================] - 0s 508us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 955us/step - loss: 2198.9094 - binary_accuracy: 0.6882 - val_loss: 2651.5591 - val_binary_accuracy: 0.7543\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 1802.3699 - binary_accuracy: 0.6613 - val_loss: 3209.2131 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1756.9047 - binary_accuracy: 0.6643 - val_loss: 3988.0513 - val_binary_accuracy: 0.7798\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 1557.9385 - binary_accuracy: 0.6612 - val_loss: 2131.1221 - val_binary_accuracy: 0.7706\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1440.3923 - binary_accuracy: 0.6595 - val_loss: 2256.9004 - val_binary_accuracy: 0.7842\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 1146.3275 - binary_accuracy: 0.6645 - val_loss: 702.0401 - val_binary_accuracy: 0.7624\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1166.7136 - binary_accuracy: 0.6632 - val_loss: 1536.0269 - val_binary_accuracy: 0.2871\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 1202.9880 - binary_accuracy: 0.6664 - val_loss: 1134.7227 - val_binary_accuracy: 0.7793\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 1158.1479 - binary_accuracy: 0.6654 - val_loss: 63.9398 - val_binary_accuracy: 0.4226\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 1104.6031 - binary_accuracy: 0.6684 - val_loss: 1165.1833 - val_binary_accuracy: 0.7790\n",
      "116/116 [==============================] - 0s 503us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 928us/step - loss: 3265.2578 - binary_accuracy: 0.6923 - val_loss: 3266.3467 - val_binary_accuracy: 0.2310\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 778us/step - loss: 3032.2842 - binary_accuracy: 0.6632 - val_loss: 455.1849 - val_binary_accuracy: 0.7523\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 2744.3965 - binary_accuracy: 0.6653 - val_loss: 744.1607 - val_binary_accuracy: 0.7837\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 2557.8845 - binary_accuracy: 0.6641 - val_loss: 1401.4320 - val_binary_accuracy: 0.7837\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 2194.1865 - binary_accuracy: 0.6639 - val_loss: 1164.4844 - val_binary_accuracy: 0.7808\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 1567.7777 - binary_accuracy: 0.6675 - val_loss: 616.8596 - val_binary_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1575.8779 - binary_accuracy: 0.6678 - val_loss: 408.0147 - val_binary_accuracy: 0.7776\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 1918.1128 - binary_accuracy: 0.6639 - val_loss: 3522.9421 - val_binary_accuracy: 0.7696\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1965.0685 - binary_accuracy: 0.6645 - val_loss: 2085.1401 - val_binary_accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 855us/step - loss: 1646.4736 - binary_accuracy: 0.6658 - val_loss: 1198.2502 - val_binary_accuracy: 0.7847\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 967us/step - loss: 17058.1445 - binary_accuracy: 0.6816 - val_loss: 1274.4998 - val_binary_accuracy: 0.7670\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 1758.7863 - binary_accuracy: 0.6653 - val_loss: 3053.7463 - val_binary_accuracy: 0.2229\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 2072.8943 - binary_accuracy: 0.6624 - val_loss: 3373.9312 - val_binary_accuracy: 0.2281\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1801.2894 - binary_accuracy: 0.6632 - val_loss: 1975.7883 - val_binary_accuracy: 0.7802\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1880.5125 - binary_accuracy: 0.6610 - val_loss: 22.6622 - val_binary_accuracy: 0.7079\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1772.9436 - binary_accuracy: 0.6632 - val_loss: 1325.4550 - val_binary_accuracy: 0.7830\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1583.1614 - binary_accuracy: 0.6658 - val_loss: 46.2356 - val_binary_accuracy: 0.6319\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1350.7871 - binary_accuracy: 0.6630 - val_loss: 2945.2175 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1240.8579 - binary_accuracy: 0.6671 - val_loss: 2370.9756 - val_binary_accuracy: 0.7825\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1045.8081 - binary_accuracy: 0.6648 - val_loss: 1207.4576 - val_binary_accuracy: 0.7829\n",
      "116/116 [==============================] - 0s 512us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 919us/step - loss: 4860.0557 - binary_accuracy: 0.6868 - val_loss: 2860.1736 - val_binary_accuracy: 0.2215\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 791us/step - loss: 1621.6399 - binary_accuracy: 0.6632 - val_loss: 2353.6536 - val_binary_accuracy: 0.2563\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 1253.3295 - binary_accuracy: 0.6602 - val_loss: 1937.2191 - val_binary_accuracy: 0.3068\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1237.9266 - binary_accuracy: 0.6635 - val_loss: 809.0955 - val_binary_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1003.3781 - binary_accuracy: 0.6603 - val_loss: 1710.0334 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 873.4011 - binary_accuracy: 0.6626 - val_loss: 450.5305 - val_binary_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 927.3580 - binary_accuracy: 0.6646 - val_loss: 458.5073 - val_binary_accuracy: 0.7767\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 952.1036 - binary_accuracy: 0.6629 - val_loss: 359.7505 - val_binary_accuracy: 0.7619\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 819.3406 - binary_accuracy: 0.6655 - val_loss: 349.9089 - val_binary_accuracy: 0.3065\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 612.6901 - binary_accuracy: 0.6610 - val_loss: 850.8122 - val_binary_accuracy: 0.2860\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 943us/step - loss: 2762.2529 - binary_accuracy: 0.5734 - val_loss: 3540.8320 - val_binary_accuracy: 0.2371\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 2270.5889 - binary_accuracy: 0.6634 - val_loss: 1892.9445 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 2078.7092 - binary_accuracy: 0.6631 - val_loss: 515.4085 - val_binary_accuracy: 0.7838\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 996us/step - loss: 1814.2948 - binary_accuracy: 0.6669 - val_loss: 1514.4723 - val_binary_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 1558.5769 - binary_accuracy: 0.6632 - val_loss: 341.6837 - val_binary_accuracy: 0.7761\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1197.4191 - binary_accuracy: 0.6688 - val_loss: 2774.5264 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 1048.0038 - binary_accuracy: 0.6633 - val_loss: 731.8711 - val_binary_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 994.4169 - binary_accuracy: 0.6629 - val_loss: 621.4783 - val_binary_accuracy: 0.7824\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 828us/step - loss: 1038.7661 - binary_accuracy: 0.6615 - val_loss: 475.5894 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 870.6812 - binary_accuracy: 0.6678 - val_loss: 569.4332 - val_binary_accuracy: 0.3011\n",
      "116/116 [==============================] - 0s 524us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 922us/step - loss: 2367.7522 - binary_accuracy: 0.5769 - val_loss: 446.1762 - val_binary_accuracy: 0.6889\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 784us/step - loss: 1496.8077 - binary_accuracy: 0.6567 - val_loss: 302.3704 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1296.9294 - binary_accuracy: 0.6604 - val_loss: 520.1187 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1075.7032 - binary_accuracy: 0.6618 - val_loss: 1118.7025 - val_binary_accuracy: 0.2677\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1169.8212 - binary_accuracy: 0.6587 - val_loss: 1624.5795 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 902.2859 - binary_accuracy: 0.6634 - val_loss: 1650.3136 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 671.6667 - binary_accuracy: 0.6612 - val_loss: 2661.9343 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 666.0015 - binary_accuracy: 0.6633 - val_loss: 949.2418 - val_binary_accuracy: 0.7817\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 676.3114 - binary_accuracy: 0.6605 - val_loss: 1635.2538 - val_binary_accuracy: 0.7838\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 677.4818 - binary_accuracy: 0.6638 - val_loss: 173.9828 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 516us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 945us/step - loss: 2003.1011 - binary_accuracy: 0.6907 - val_loss: 2698.7649 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1988.5266 - binary_accuracy: 0.6616 - val_loss: 366.0562 - val_binary_accuracy: 0.7526\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 2137.8977 - binary_accuracy: 0.6591 - val_loss: 4264.9360 - val_binary_accuracy: 0.2269\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 846us/step - loss: 1867.7181 - binary_accuracy: 0.6598 - val_loss: 560.7502 - val_binary_accuracy: 0.2781\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1703.8013 - binary_accuracy: 0.6608 - val_loss: 1636.2019 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1796.3914 - binary_accuracy: 0.6654 - val_loss: 3184.6494 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 902us/step - loss: 1460.1112 - binary_accuracy: 0.6626 - val_loss: 1426.8347 - val_binary_accuracy: 0.7785\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 917.6896 - binary_accuracy: 0.6669 - val_loss: 1187.3801 - val_binary_accuracy: 0.2317\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 935.6169 - binary_accuracy: 0.6613 - val_loss: 903.1511 - val_binary_accuracy: 0.7824\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 1224.1013 - binary_accuracy: 0.6650 - val_loss: 1090.6125 - val_binary_accuracy: 0.2724\n",
      "116/116 [==============================] - 0s 523us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 918us/step - loss: 2361.8259 - binary_accuracy: 0.5770 - val_loss: 1132.6429 - val_binary_accuracy: 0.7742\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 2076.0005 - binary_accuracy: 0.6643 - val_loss: 1446.9009 - val_binary_accuracy: 0.7773\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1932.3718 - binary_accuracy: 0.6648 - val_loss: 1150.1038 - val_binary_accuracy: 0.7752\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1699.5148 - binary_accuracy: 0.6652 - val_loss: 2772.8086 - val_binary_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1685.5116 - binary_accuracy: 0.6626 - val_loss: 1156.3077 - val_binary_accuracy: 0.7822\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1320.2494 - binary_accuracy: 0.6687 - val_loss: 1542.1309 - val_binary_accuracy: 0.7840\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1672.7479 - binary_accuracy: 0.6674 - val_loss: 1835.7476 - val_binary_accuracy: 0.2501\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 1281.0985 - binary_accuracy: 0.6620 - val_loss: 932.2187 - val_binary_accuracy: 0.7728\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1301.9545 - binary_accuracy: 0.6678 - val_loss: 2125.1765 - val_binary_accuracy: 0.2414\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1344.9335 - binary_accuracy: 0.6640 - val_loss: 964.8832 - val_binary_accuracy: 0.7783\n",
      "116/116 [==============================] - 0s 521us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 930us/step - loss: 3862.1077 - binary_accuracy: 0.6858 - val_loss: 2267.1743 - val_binary_accuracy: 0.7756\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1975.9263 - binary_accuracy: 0.6619 - val_loss: 1165.4429 - val_binary_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1522.0736 - binary_accuracy: 0.6646 - val_loss: 1794.6483 - val_binary_accuracy: 0.7839\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1562.1271 - binary_accuracy: 0.6644 - val_loss: 1032.2382 - val_binary_accuracy: 0.2607\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1282.8635 - binary_accuracy: 0.6629 - val_loss: 1851.4120 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1795.7504 - binary_accuracy: 0.6594 - val_loss: 76.9089 - val_binary_accuracy: 0.7630\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1193.2972 - binary_accuracy: 0.6611 - val_loss: 5618.0615 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 1114.8447 - binary_accuracy: 0.6641 - val_loss: 1938.0852 - val_binary_accuracy: 0.2530\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 1099.3309 - binary_accuracy: 0.6658 - val_loss: 245.5399 - val_binary_accuracy: 0.3111\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 1023.1909 - binary_accuracy: 0.6649 - val_loss: 554.0499 - val_binary_accuracy: 0.7718\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 927us/step - loss: 2792.4385 - binary_accuracy: 0.6805 - val_loss: 5098.9800 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 1495.5781 - binary_accuracy: 0.6625 - val_loss: 448.9275 - val_binary_accuracy: 0.7543\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1104.3762 - binary_accuracy: 0.6658 - val_loss: 324.6621 - val_binary_accuracy: 0.7840\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 920.1177 - binary_accuracy: 0.6664 - val_loss: 912.8656 - val_binary_accuracy: 0.7682\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 879.0568 - binary_accuracy: 0.6666 - val_loss: 1341.9918 - val_binary_accuracy: 0.2215\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 715.7713 - binary_accuracy: 0.6651 - val_loss: 125.0975 - val_binary_accuracy: 0.5877\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 789.2929 - binary_accuracy: 0.6650 - val_loss: 937.1348 - val_binary_accuracy: 0.2630\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 751.8151 - binary_accuracy: 0.6633 - val_loss: 1060.2690 - val_binary_accuracy: 0.2525\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 643.2276 - binary_accuracy: 0.6662 - val_loss: 777.4128 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 623.5583 - binary_accuracy: 0.6665 - val_loss: 183.1469 - val_binary_accuracy: 0.7359\n",
      "116/116 [==============================] - 0s 500us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4140.8467 - binary_accuracy: 0.6727 - val_loss: 1432.3622 - val_binary_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 2375.8130 - binary_accuracy: 0.6651 - val_loss: 504.5657 - val_binary_accuracy: 0.7687\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 905us/step - loss: 2747.3247 - binary_accuracy: 0.6602 - val_loss: 1573.1833 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 913us/step - loss: 2609.0132 - binary_accuracy: 0.6624 - val_loss: 564.2777 - val_binary_accuracy: 0.3742\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 980us/step - loss: 2156.1033 - binary_accuracy: 0.6639 - val_loss: 598.3893 - val_binary_accuracy: 0.7562\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 1595.0859 - binary_accuracy: 0.6692 - val_loss: 2299.4084 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 940us/step - loss: 2232.5457 - binary_accuracy: 0.6639 - val_loss: 3678.4680 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 895us/step - loss: 2490.4314 - binary_accuracy: 0.6644 - val_loss: 980.5306 - val_binary_accuracy: 0.7837\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 1613.0710 - binary_accuracy: 0.6641 - val_loss: 782.2745 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 884us/step - loss: 1818.0989 - binary_accuracy: 0.6654 - val_loss: 2785.1108 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 570us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 993us/step - loss: 4071.2141 - binary_accuracy: 0.6861 - val_loss: 697.1147 - val_binary_accuracy: 0.7639\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 914us/step - loss: 2197.9014 - binary_accuracy: 0.6619 - val_loss: 1690.5709 - val_binary_accuracy: 0.2479\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 1999.4624 - binary_accuracy: 0.6591 - val_loss: 999.8271 - val_binary_accuracy: 0.4100\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 1881.7797 - binary_accuracy: 0.6618 - val_loss: 3295.4934 - val_binary_accuracy: 0.2391\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1534.2784 - binary_accuracy: 0.6655 - val_loss: 2614.9014 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1225.1577 - binary_accuracy: 0.6654 - val_loss: 243.2876 - val_binary_accuracy: 0.5572\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 1260.5132 - binary_accuracy: 0.6662 - val_loss: 282.5635 - val_binary_accuracy: 0.6802\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1173.9862 - binary_accuracy: 0.6657 - val_loss: 2027.1899 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1236.8143 - binary_accuracy: 0.6691 - val_loss: 1248.8949 - val_binary_accuracy: 0.7745\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1439.0244 - binary_accuracy: 0.6664 - val_loss: 726.2127 - val_binary_accuracy: 0.7807\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 913us/step - loss: 2186.7051 - binary_accuracy: 0.6941 - val_loss: 1169.5638 - val_binary_accuracy: 0.7846\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1145.6644 - binary_accuracy: 0.6647 - val_loss: 318.2427 - val_binary_accuracy: 0.2971\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 984.4630 - binary_accuracy: 0.6623 - val_loss: 1415.6357 - val_binary_accuracy: 0.7810\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 983.3031 - binary_accuracy: 0.6618 - val_loss: 501.5924 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 778.1252 - binary_accuracy: 0.6644 - val_loss: 1093.1061 - val_binary_accuracy: 0.7840\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 546.2970 - binary_accuracy: 0.6617 - val_loss: 695.5114 - val_binary_accuracy: 0.7834\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 867us/step - loss: 708.0090 - binary_accuracy: 0.6658 - val_loss: 741.7231 - val_binary_accuracy: 0.2536\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 626.5201 - binary_accuracy: 0.6645 - val_loss: 265.3715 - val_binary_accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 611.9793 - binary_accuracy: 0.6653 - val_loss: 1520.0511 - val_binary_accuracy: 0.2197\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 577.4511 - binary_accuracy: 0.6654 - val_loss: 155.3033 - val_binary_accuracy: 0.7816\n",
      "116/116 [==============================] - 0s 507us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 920us/step - loss: 12721.1211 - binary_accuracy: 0.6808 - val_loss: 1151.8575 - val_binary_accuracy: 0.2614\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 2178.8967 - binary_accuracy: 0.6617 - val_loss: 1733.4092 - val_binary_accuracy: 0.7758\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 1877.0104 - binary_accuracy: 0.6633 - val_loss: 336.5150 - val_binary_accuracy: 0.4831\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1808.2925 - binary_accuracy: 0.6626 - val_loss: 2282.6733 - val_binary_accuracy: 0.7744\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1225.1100 - binary_accuracy: 0.6625 - val_loss: 878.3633 - val_binary_accuracy: 0.7769\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 1426.7390 - binary_accuracy: 0.6653 - val_loss: 405.2720 - val_binary_accuracy: 0.7721\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1144.6616 - binary_accuracy: 0.6631 - val_loss: 235.8767 - val_binary_accuracy: 0.7457\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1051.8281 - binary_accuracy: 0.6675 - val_loss: 1444.8673 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 909.3333 - binary_accuracy: 0.6695 - val_loss: 1495.0291 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 968.2784 - binary_accuracy: 0.6642 - val_loss: 717.9575 - val_binary_accuracy: 0.7834\n",
      "116/116 [==============================] - 0s 511us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 914us/step - loss: 5901.5049 - binary_accuracy: 0.6860 - val_loss: 756.3464 - val_binary_accuracy: 0.7657\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 779us/step - loss: 2944.1348 - binary_accuracy: 0.6633 - val_loss: 4082.6267 - val_binary_accuracy: 0.7822\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 3534.5537 - binary_accuracy: 0.6626 - val_loss: 966.8749 - val_binary_accuracy: 0.7775\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 3277.4788 - binary_accuracy: 0.6584 - val_loss: 4442.6777 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 2776.8560 - binary_accuracy: 0.6677 - val_loss: 1906.5968 - val_binary_accuracy: 0.2425\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1677.7852 - binary_accuracy: 0.6604 - val_loss: 931.2991 - val_binary_accuracy: 0.7814\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 2284.8547 - binary_accuracy: 0.6647 - val_loss: 923.7955 - val_binary_accuracy: 0.7827\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2079.9177 - binary_accuracy: 0.6663 - val_loss: 544.4003 - val_binary_accuracy: 0.3243\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 2203.0708 - binary_accuracy: 0.6663 - val_loss: 197.3731 - val_binary_accuracy: 0.7826\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1522.7695 - binary_accuracy: 0.6674 - val_loss: 143.2450 - val_binary_accuracy: 0.4344\n",
      "116/116 [==============================] - 0s 516us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 917us/step - loss: 4474.7549 - binary_accuracy: 0.6140 - val_loss: 852.2164 - val_binary_accuracy: 0.7805\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 1965.7172 - binary_accuracy: 0.6607 - val_loss: 3227.0947 - val_binary_accuracy: 0.7844\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1456.5260 - binary_accuracy: 0.6629 - val_loss: 659.0663 - val_binary_accuracy: 0.7546\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1089.5459 - binary_accuracy: 0.6662 - val_loss: 877.6420 - val_binary_accuracy: 0.7715\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 997.2674 - binary_accuracy: 0.6663 - val_loss: 1363.2213 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 921.4481 - binary_accuracy: 0.6632 - val_loss: 1221.5697 - val_binary_accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 1080.5157 - binary_accuracy: 0.6639 - val_loss: 757.5549 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 632.4714 - binary_accuracy: 0.6643 - val_loss: 158.9745 - val_binary_accuracy: 0.7810\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 797.4456 - binary_accuracy: 0.6628 - val_loss: 1573.4688 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 606.4713 - binary_accuracy: 0.6608 - val_loss: 388.1629 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 531us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 929us/step - loss: 3785.0696 - binary_accuracy: 0.6920 - val_loss: 4047.5891 - val_binary_accuracy: 0.7693\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 2549.4055 - binary_accuracy: 0.6629 - val_loss: 4531.5186 - val_binary_accuracy: 0.7829\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 2294.6753 - binary_accuracy: 0.6604 - val_loss: 1375.6228 - val_binary_accuracy: 0.2322\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 2648.3411 - binary_accuracy: 0.6602 - val_loss: 1384.3748 - val_binary_accuracy: 0.7831\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1366.0239 - binary_accuracy: 0.6649 - val_loss: 1251.0577 - val_binary_accuracy: 0.7841\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1358.7736 - binary_accuracy: 0.6620 - val_loss: 913.5248 - val_binary_accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1808.1359 - binary_accuracy: 0.6627 - val_loss: 612.9444 - val_binary_accuracy: 0.2284\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1665.1088 - binary_accuracy: 0.6623 - val_loss: 2863.3987 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 1429.9871 - binary_accuracy: 0.6641 - val_loss: 1424.3137 - val_binary_accuracy: 0.7642\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 1362.5413 - binary_accuracy: 0.6617 - val_loss: 2669.7791 - val_binary_accuracy: 0.2338\n",
      "116/116 [==============================] - 0s 515us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 934us/step - loss: 1438.4811 - binary_accuracy: 0.5668 - val_loss: 149.4530 - val_binary_accuracy: 0.7511\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 657.7656 - binary_accuracy: 0.6638 - val_loss: 749.1989 - val_binary_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 675.3337 - binary_accuracy: 0.6632 - val_loss: 27.6780 - val_binary_accuracy: 0.7560\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 489.4047 - binary_accuracy: 0.6653 - val_loss: 144.4702 - val_binary_accuracy: 0.7789\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 466.6163 - binary_accuracy: 0.6672 - val_loss: 327.8746 - val_binary_accuracy: 0.7758\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 386.8092 - binary_accuracy: 0.6679 - val_loss: 250.8418 - val_binary_accuracy: 0.7754\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 338.9283 - binary_accuracy: 0.6653 - val_loss: 59.4562 - val_binary_accuracy: 0.7716\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 320.0432 - binary_accuracy: 0.6694 - val_loss: 154.0854 - val_binary_accuracy: 0.7535\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 336.7365 - binary_accuracy: 0.6646 - val_loss: 174.4506 - val_binary_accuracy: 0.7797\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 276.2806 - binary_accuracy: 0.6663 - val_loss: 355.8725 - val_binary_accuracy: 0.7739\n",
      "116/116 [==============================] - 0s 514us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 924us/step - loss: 5044.2310 - binary_accuracy: 0.6767 - val_loss: 5184.8525 - val_binary_accuracy: 0.7844\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1658.0531 - binary_accuracy: 0.6616 - val_loss: 3567.9810 - val_binary_accuracy: 0.2317\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1586.2585 - binary_accuracy: 0.6607 - val_loss: 3857.4470 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1525.1342 - binary_accuracy: 0.6629 - val_loss: 1081.2744 - val_binary_accuracy: 0.2807\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1015.8446 - binary_accuracy: 0.6638 - val_loss: 1538.2756 - val_binary_accuracy: 0.7803\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 953.2941 - binary_accuracy: 0.6628 - val_loss: 1092.4880 - val_binary_accuracy: 0.7840\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 949.9133 - binary_accuracy: 0.6624 - val_loss: 1080.6964 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 913.4297 - binary_accuracy: 0.6605 - val_loss: 421.7740 - val_binary_accuracy: 0.7441\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 1288.9760 - binary_accuracy: 0.6621 - val_loss: 1941.7335 - val_binary_accuracy: 0.7820\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1118.1202 - binary_accuracy: 0.6642 - val_loss: 240.3450 - val_binary_accuracy: 0.7301\n",
      "116/116 [==============================] - 0s 514us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 923us/step - loss: 1807.2114 - binary_accuracy: 0.6794 - val_loss: 1846.3925 - val_binary_accuracy: 0.7771\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1726.4943 - binary_accuracy: 0.6646 - val_loss: 744.0606 - val_binary_accuracy: 0.7814\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1754.0991 - binary_accuracy: 0.6638 - val_loss: 700.9224 - val_binary_accuracy: 0.7239\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 1316.8555 - binary_accuracy: 0.6613 - val_loss: 3085.9473 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1638.7928 - binary_accuracy: 0.6673 - val_loss: 789.4409 - val_binary_accuracy: 0.7834\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1237.9061 - binary_accuracy: 0.6659 - val_loss: 1095.0947 - val_binary_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1331.8270 - binary_accuracy: 0.6661 - val_loss: 1935.0508 - val_binary_accuracy: 0.7775\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1338.6281 - binary_accuracy: 0.6680 - val_loss: 5348.0068 - val_binary_accuracy: 0.2170\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1095.4939 - binary_accuracy: 0.6644 - val_loss: 1891.6807 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 894.9729 - binary_accuracy: 0.6666 - val_loss: 699.4778 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 505us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 946us/step - loss: 4519.5757 - binary_accuracy: 0.6893 - val_loss: 6297.2578 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2719.0308 - binary_accuracy: 0.6639 - val_loss: 11056.7812 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 2714.3281 - binary_accuracy: 0.6643 - val_loss: 2695.3384 - val_binary_accuracy: 0.2199\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 2058.8774 - binary_accuracy: 0.6635 - val_loss: 150.4672 - val_binary_accuracy: 0.7840\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1795.1624 - binary_accuracy: 0.6628 - val_loss: 7763.0967 - val_binary_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1776.2512 - binary_accuracy: 0.6691 - val_loss: 2682.8267 - val_binary_accuracy: 0.7819\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1564.8586 - binary_accuracy: 0.6648 - val_loss: 1529.5834 - val_binary_accuracy: 0.7834\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1270.7306 - binary_accuracy: 0.6624 - val_loss: 1445.2844 - val_binary_accuracy: 0.2422\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1440.9054 - binary_accuracy: 0.6612 - val_loss: 2467.3757 - val_binary_accuracy: 0.7829\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1307.3629 - binary_accuracy: 0.6653 - val_loss: 393.8868 - val_binary_accuracy: 0.7656\n",
      "116/116 [==============================] - 0s 525us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 959us/step - loss: 3178.3398 - binary_accuracy: 0.6868 - val_loss: 3556.2412 - val_binary_accuracy: 0.2610\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 1858.6665 - binary_accuracy: 0.6633 - val_loss: 1170.3560 - val_binary_accuracy: 0.2228\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 1525.5640 - binary_accuracy: 0.6604 - val_loss: 985.3763 - val_binary_accuracy: 0.2771\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 1170.1208 - binary_accuracy: 0.6630 - val_loss: 2748.3730 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1111.8652 - binary_accuracy: 0.6648 - val_loss: 909.3633 - val_binary_accuracy: 0.7395\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 668.8869 - binary_accuracy: 0.6675 - val_loss: 449.0893 - val_binary_accuracy: 0.7840\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 953us/step - loss: 601.0014 - binary_accuracy: 0.6601 - val_loss: 455.3627 - val_binary_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 540.3366 - binary_accuracy: 0.6625 - val_loss: 296.2852 - val_binary_accuracy: 0.7195\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 423.2407 - binary_accuracy: 0.6599 - val_loss: 225.8461 - val_binary_accuracy: 0.7852\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 846us/step - loss: 409.9810 - binary_accuracy: 0.6672 - val_loss: 64.8389 - val_binary_accuracy: 0.7341\n",
      "116/116 [==============================] - 0s 544us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 943us/step - loss: 3778.1646 - binary_accuracy: 0.6829 - val_loss: 8597.2666 - val_binary_accuracy: 0.2289\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 3260.8979 - binary_accuracy: 0.6648 - val_loss: 4800.8989 - val_binary_accuracy: 0.7821\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 2706.0049 - binary_accuracy: 0.6637 - val_loss: 9629.8613 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 2273.6875 - binary_accuracy: 0.6617 - val_loss: 332.1762 - val_binary_accuracy: 0.3835\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 2086.8076 - binary_accuracy: 0.6636 - val_loss: 1002.7977 - val_binary_accuracy: 0.7807\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 2314.9277 - binary_accuracy: 0.6629 - val_loss: 172.3280 - val_binary_accuracy: 0.7537\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2122.1353 - binary_accuracy: 0.6691 - val_loss: 1067.7322 - val_binary_accuracy: 0.7748\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 1497.7697 - binary_accuracy: 0.6655 - val_loss: 3176.6340 - val_binary_accuracy: 0.7839\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 903us/step - loss: 1213.5634 - binary_accuracy: 0.6647 - val_loss: 789.4932 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1335.7738 - binary_accuracy: 0.6677 - val_loss: 1380.7050 - val_binary_accuracy: 0.2514\n",
      "116/116 [==============================] - 0s 519us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 950us/step - loss: 3970.4854 - binary_accuracy: 0.5710 - val_loss: 346.4777 - val_binary_accuracy: 0.7708\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 2885.1755 - binary_accuracy: 0.6590 - val_loss: 304.8919 - val_binary_accuracy: 0.7444\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 2269.5396 - binary_accuracy: 0.6622 - val_loss: 2191.1482 - val_binary_accuracy: 0.2610\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 2627.9905 - binary_accuracy: 0.6598 - val_loss: 933.8865 - val_binary_accuracy: 0.7838\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2347.4846 - binary_accuracy: 0.6619 - val_loss: 1648.7169 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1719.8732 - binary_accuracy: 0.6637 - val_loss: 645.9556 - val_binary_accuracy: 0.7767\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1770.0403 - binary_accuracy: 0.6611 - val_loss: 388.1364 - val_binary_accuracy: 0.7762\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 1358.1060 - binary_accuracy: 0.6638 - val_loss: 741.2314 - val_binary_accuracy: 0.7823\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1238.5524 - binary_accuracy: 0.6628 - val_loss: 1167.5033 - val_binary_accuracy: 0.7842\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1167.6360 - binary_accuracy: 0.6628 - val_loss: 149.0684 - val_binary_accuracy: 0.7658\n",
      "116/116 [==============================] - 0s 514us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 953us/step - loss: 4746.8652 - binary_accuracy: 0.6842 - val_loss: 3952.5823 - val_binary_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 3514.3564 - binary_accuracy: 0.6637 - val_loss: 1324.2299 - val_binary_accuracy: 0.7821\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 2933.5532 - binary_accuracy: 0.6639 - val_loss: 2397.2778 - val_binary_accuracy: 0.2365\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 3162.6616 - binary_accuracy: 0.6681 - val_loss: 2451.7834 - val_binary_accuracy: 0.7850\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 2856.4155 - binary_accuracy: 0.6633 - val_loss: 5604.4653 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 2716.0012 - binary_accuracy: 0.6625 - val_loss: 5508.1226 - val_binary_accuracy: 0.7839\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1934.3573 - binary_accuracy: 0.6677 - val_loss: 3596.1965 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1709.9232 - binary_accuracy: 0.6662 - val_loss: 776.2465 - val_binary_accuracy: 0.7817\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 878us/step - loss: 1533.3983 - binary_accuracy: 0.6639 - val_loss: 1368.0067 - val_binary_accuracy: 0.7839\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1185.2600 - binary_accuracy: 0.6666 - val_loss: 266.1505 - val_binary_accuracy: 0.7762\n",
      "116/116 [==============================] - 0s 525us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 939us/step - loss: 4139.4194 - binary_accuracy: 0.6839 - val_loss: 7039.3726 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 3249.4426 - binary_accuracy: 0.6639 - val_loss: 3863.1675 - val_binary_accuracy: 0.7838\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2352.4138 - binary_accuracy: 0.6678 - val_loss: 926.3359 - val_binary_accuracy: 0.7802\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2311.1877 - binary_accuracy: 0.6658 - val_loss: 646.7379 - val_binary_accuracy: 0.7491\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 916us/step - loss: 2027.1686 - binary_accuracy: 0.6624 - val_loss: 1928.4922 - val_binary_accuracy: 0.7803\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 904us/step - loss: 1575.4700 - binary_accuracy: 0.6626 - val_loss: 1650.0991 - val_binary_accuracy: 0.7851\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1161.2134 - binary_accuracy: 0.6638 - val_loss: 2304.3320 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 828us/step - loss: 933.2009 - binary_accuracy: 0.6644 - val_loss: 1023.2583 - val_binary_accuracy: 0.7842\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 917.5668 - binary_accuracy: 0.6603 - val_loss: 192.6289 - val_binary_accuracy: 0.7414\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 793.6104 - binary_accuracy: 0.6623 - val_loss: 69.5201 - val_binary_accuracy: 0.7472\n",
      "116/116 [==============================] - 0s 515us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 939us/step - loss: 4901.9302 - binary_accuracy: 0.6799 - val_loss: 8126.9619 - val_binary_accuracy: 0.2202\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 2310.0159 - binary_accuracy: 0.6578 - val_loss: 336.1952 - val_binary_accuracy: 0.7445\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2133.8699 - binary_accuracy: 0.6617 - val_loss: 3256.5359 - val_binary_accuracy: 0.7835\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 2157.2349 - binary_accuracy: 0.6631 - val_loss: 2381.5039 - val_binary_accuracy: 0.2231\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1570.7469 - binary_accuracy: 0.6602 - val_loss: 752.5535 - val_binary_accuracy: 0.7519\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1467.0403 - binary_accuracy: 0.6590 - val_loss: 799.0558 - val_binary_accuracy: 0.7711\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 644.5569 - binary_accuracy: 0.6613 - val_loss: 1460.5007 - val_binary_accuracy: 0.2329\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 842.3385 - binary_accuracy: 0.6628 - val_loss: 254.9070 - val_binary_accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 894us/step - loss: 758.4186 - binary_accuracy: 0.6611 - val_loss: 333.6060 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 604.6448 - binary_accuracy: 0.6636 - val_loss: 178.4009 - val_binary_accuracy: 0.2644\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 940us/step - loss: 4042.2312 - binary_accuracy: 0.5744 - val_loss: 6138.2358 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 3036.4998 - binary_accuracy: 0.6651 - val_loss: 2258.0430 - val_binary_accuracy: 0.7836\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 2298.4282 - binary_accuracy: 0.6656 - val_loss: 3227.0095 - val_binary_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2318.7803 - binary_accuracy: 0.6649 - val_loss: 1136.3505 - val_binary_accuracy: 0.7842\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1730.7303 - binary_accuracy: 0.6636 - val_loss: 1983.3225 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 1525.3324 - binary_accuracy: 0.6653 - val_loss: 1935.8054 - val_binary_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1446.5596 - binary_accuracy: 0.6677 - val_loss: 1134.5630 - val_binary_accuracy: 0.3025\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1256.4221 - binary_accuracy: 0.6649 - val_loss: 177.6511 - val_binary_accuracy: 0.7690\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 999.8250 - binary_accuracy: 0.6671 - val_loss: 390.1185 - val_binary_accuracy: 0.2427\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 855us/step - loss: 879.8885 - binary_accuracy: 0.6651 - val_loss: 2305.1545 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 519us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 942us/step - loss: 2442.3176 - binary_accuracy: 0.6874 - val_loss: 1864.2848 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 2195.4331 - binary_accuracy: 0.6624 - val_loss: 529.9983 - val_binary_accuracy: 0.7839\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 2133.3010 - binary_accuracy: 0.6606 - val_loss: 342.4396 - val_binary_accuracy: 0.7716\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1838.8197 - binary_accuracy: 0.6650 - val_loss: 687.7022 - val_binary_accuracy: 0.7718\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1708.4694 - binary_accuracy: 0.6646 - val_loss: 1278.0356 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1624.5056 - binary_accuracy: 0.6624 - val_loss: 4577.3135 - val_binary_accuracy: 0.2166\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1109.2732 - binary_accuracy: 0.6643 - val_loss: 319.9443 - val_binary_accuracy: 0.7846\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1003.8331 - binary_accuracy: 0.6643 - val_loss: 1271.3625 - val_binary_accuracy: 0.2380\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 966.5156 - binary_accuracy: 0.6653 - val_loss: 130.7334 - val_binary_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 936.2797 - binary_accuracy: 0.6645 - val_loss: 826.7416 - val_binary_accuracy: 0.7836\n",
      "116/116 [==============================] - 0s 507us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 932us/step - loss: 3100.0325 - binary_accuracy: 0.6926 - val_loss: 901.2189 - val_binary_accuracy: 0.7819\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 796us/step - loss: 1678.5248 - binary_accuracy: 0.6643 - val_loss: 1351.7197 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1446.6272 - binary_accuracy: 0.6631 - val_loss: 2291.3950 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1155.5496 - binary_accuracy: 0.6632 - val_loss: 897.2493 - val_binary_accuracy: 0.7842\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1165.8901 - binary_accuracy: 0.6641 - val_loss: 166.1948 - val_binary_accuracy: 0.4488\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 956.2681 - binary_accuracy: 0.6635 - val_loss: 970.7587 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 916.5692 - binary_accuracy: 0.6632 - val_loss: 1310.7819 - val_binary_accuracy: 0.7836\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 779.4771 - binary_accuracy: 0.6654 - val_loss: 378.4740 - val_binary_accuracy: 0.7810\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 780.6896 - binary_accuracy: 0.6654 - val_loss: 892.6262 - val_binary_accuracy: 0.2350\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 621.0620 - binary_accuracy: 0.6664 - val_loss: 502.0975 - val_binary_accuracy: 0.7820\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 996us/step - loss: 7142.3022 - binary_accuracy: 0.6871 - val_loss: 3890.3208 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 2777.0173 - binary_accuracy: 0.6598 - val_loss: 1523.5386 - val_binary_accuracy: 0.7829\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 999us/step - loss: 1713.0356 - binary_accuracy: 0.6593 - val_loss: 2407.3965 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 901us/step - loss: 1663.1844 - binary_accuracy: 0.6612 - val_loss: 375.1915 - val_binary_accuracy: 0.7746\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1786.6715 - binary_accuracy: 0.6626 - val_loss: 2372.0208 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1365.4447 - binary_accuracy: 0.6643 - val_loss: 1400.7271 - val_binary_accuracy: 0.7767\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1264.5690 - binary_accuracy: 0.6633 - val_loss: 2442.1855 - val_binary_accuracy: 0.7770\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 941.7548 - binary_accuracy: 0.6610 - val_loss: 786.5476 - val_binary_accuracy: 0.2635\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 901us/step - loss: 1148.3812 - binary_accuracy: 0.6619 - val_loss: 63.4492 - val_binary_accuracy: 0.7598\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 842.9849 - binary_accuracy: 0.6602 - val_loss: 732.1985 - val_binary_accuracy: 0.2322\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 944us/step - loss: 2763.4949 - binary_accuracy: 0.5700 - val_loss: 2179.7817 - val_binary_accuracy: 0.2261\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1546.2092 - binary_accuracy: 0.6583 - val_loss: 802.4513 - val_binary_accuracy: 0.2217\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 1591.6654 - binary_accuracy: 0.6660 - val_loss: 1458.3075 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1361.5255 - binary_accuracy: 0.6628 - val_loss: 1363.7994 - val_binary_accuracy: 0.7803\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1525.7635 - binary_accuracy: 0.6607 - val_loss: 4007.6350 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1214.3450 - binary_accuracy: 0.6681 - val_loss: 784.6467 - val_binary_accuracy: 0.2608\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1278.1852 - binary_accuracy: 0.6632 - val_loss: 1403.0037 - val_binary_accuracy: 0.2498\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1332.5793 - binary_accuracy: 0.6654 - val_loss: 1704.7626 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 941.6823 - binary_accuracy: 0.6642 - val_loss: 302.7067 - val_binary_accuracy: 0.7819\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 848.3768 - binary_accuracy: 0.6639 - val_loss: 44.3736 - val_binary_accuracy: 0.7397\n",
      "116/116 [==============================] - 0s 515us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 935us/step - loss: 3042.4026 - binary_accuracy: 0.6772 - val_loss: 2516.4421 - val_binary_accuracy: 0.7752\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 2012.0503 - binary_accuracy: 0.6653 - val_loss: 254.2445 - val_binary_accuracy: 0.7524\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 1961.7917 - binary_accuracy: 0.6645 - val_loss: 812.6365 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1957.0200 - binary_accuracy: 0.6650 - val_loss: 668.5174 - val_binary_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1608.2233 - binary_accuracy: 0.6634 - val_loss: 691.1790 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1274.2638 - binary_accuracy: 0.6633 - val_loss: 1750.0933 - val_binary_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1321.7078 - binary_accuracy: 0.6614 - val_loss: 3086.7734 - val_binary_accuracy: 0.2363\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 977us/step - loss: 1148.6758 - binary_accuracy: 0.6666 - val_loss: 1758.8615 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 925.1774 - binary_accuracy: 0.6622 - val_loss: 311.3568 - val_binary_accuracy: 0.7712\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 980.2175 - binary_accuracy: 0.6641 - val_loss: 554.7549 - val_binary_accuracy: 0.7785\n",
      "116/116 [==============================] - 0s 516us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 941us/step - loss: 2594.1448 - binary_accuracy: 0.6885 - val_loss: 1501.7834 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1893.3093 - binary_accuracy: 0.6675 - val_loss: 1401.5583 - val_binary_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1391.0466 - binary_accuracy: 0.6688 - val_loss: 3087.2712 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1275.2966 - binary_accuracy: 0.6690 - val_loss: 207.2537 - val_binary_accuracy: 0.7537\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 844.6906 - binary_accuracy: 0.6655 - val_loss: 382.5702 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 792.3652 - binary_accuracy: 0.6619 - val_loss: 503.8352 - val_binary_accuracy: 0.6827\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 743.9197 - binary_accuracy: 0.6667 - val_loss: 141.0525 - val_binary_accuracy: 0.7587\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 470.2991 - binary_accuracy: 0.6657 - val_loss: 525.8428 - val_binary_accuracy: 0.7822\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 462.1513 - binary_accuracy: 0.6684 - val_loss: 219.0967 - val_binary_accuracy: 0.7821\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 424.3199 - binary_accuracy: 0.6634 - val_loss: 381.3415 - val_binary_accuracy: 0.7842\n",
      "116/116 [==============================] - 0s 535us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 959us/step - loss: 3729.4854 - binary_accuracy: 0.6859 - val_loss: 1800.4736 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 2307.3669 - binary_accuracy: 0.6596 - val_loss: 324.1552 - val_binary_accuracy: 0.7771\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1568.0176 - binary_accuracy: 0.6627 - val_loss: 1207.5056 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 908us/step - loss: 1469.4954 - binary_accuracy: 0.6636 - val_loss: 5518.2100 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 1568.7118 - binary_accuracy: 0.6685 - val_loss: 932.6370 - val_binary_accuracy: 0.7730\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 1324.2233 - binary_accuracy: 0.6665 - val_loss: 494.7332 - val_binary_accuracy: 0.7693\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 923.9552 - binary_accuracy: 0.6617 - val_loss: 643.4907 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1044.0637 - binary_accuracy: 0.6620 - val_loss: 624.7043 - val_binary_accuracy: 0.2595\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 999.8623 - binary_accuracy: 0.6623 - val_loss: 321.8120 - val_binary_accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 578.9565 - binary_accuracy: 0.6696 - val_loss: 125.0438 - val_binary_accuracy: 0.2814\n",
      "116/116 [==============================] - 0s 504us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 938us/step - loss: 3051.7646 - binary_accuracy: 0.5775 - val_loss: 90.6229 - val_binary_accuracy: 0.7061\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 2146.7185 - binary_accuracy: 0.6619 - val_loss: 608.2119 - val_binary_accuracy: 0.7727\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 1572.2460 - binary_accuracy: 0.6614 - val_loss: 1463.8501 - val_binary_accuracy: 0.7739\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 1223.7709 - binary_accuracy: 0.6632 - val_loss: 645.4509 - val_binary_accuracy: 0.7815\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1035.5880 - binary_accuracy: 0.6601 - val_loss: 1658.2468 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1089.4174 - binary_accuracy: 0.6582 - val_loss: 1335.7699 - val_binary_accuracy: 0.7825\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1310.8398 - binary_accuracy: 0.6598 - val_loss: 1608.5115 - val_binary_accuracy: 0.7834\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 988.5588 - binary_accuracy: 0.6627 - val_loss: 563.9675 - val_binary_accuracy: 0.7648\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 907us/step - loss: 763.6854 - binary_accuracy: 0.6586 - val_loss: 732.6086 - val_binary_accuracy: 0.7812\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 884us/step - loss: 661.9380 - binary_accuracy: 0.6641 - val_loss: 815.2067 - val_binary_accuracy: 0.7633\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 946us/step - loss: 3989.3284 - binary_accuracy: 0.6797 - val_loss: 9302.0430 - val_binary_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 2629.3203 - binary_accuracy: 0.6626 - val_loss: 6116.4204 - val_binary_accuracy: 0.2158\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 2487.2976 - binary_accuracy: 0.6590 - val_loss: 353.4593 - val_binary_accuracy: 0.5463\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 2126.2485 - binary_accuracy: 0.6612 - val_loss: 505.8929 - val_binary_accuracy: 0.7699\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1973.1455 - binary_accuracy: 0.6626 - val_loss: 250.2971 - val_binary_accuracy: 0.7800\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1443.7765 - binary_accuracy: 0.6647 - val_loss: 696.5209 - val_binary_accuracy: 0.7781\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1711.1635 - binary_accuracy: 0.6592 - val_loss: 1276.5380 - val_binary_accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1458.3848 - binary_accuracy: 0.6596 - val_loss: 1511.7969 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 950us/step - loss: 1340.5280 - binary_accuracy: 0.6646 - val_loss: 176.6919 - val_binary_accuracy: 0.3562\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 1382.5570 - binary_accuracy: 0.6628 - val_loss: 64.6739 - val_binary_accuracy: 0.7633\n",
      "116/116 [==============================] - 0s 520us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 967us/step - loss: 4041.1526 - binary_accuracy: 0.6877 - val_loss: 1657.6952 - val_binary_accuracy: 0.7745\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 2494.3547 - binary_accuracy: 0.6653 - val_loss: 2374.4373 - val_binary_accuracy: 0.7807\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1897.3226 - binary_accuracy: 0.6662 - val_loss: 1081.9004 - val_binary_accuracy: 0.7836\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 1934.7021 - binary_accuracy: 0.6625 - val_loss: 1541.2126 - val_binary_accuracy: 0.7846\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 948us/step - loss: 1524.9816 - binary_accuracy: 0.6661 - val_loss: 1912.7427 - val_binary_accuracy: 0.2553\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 1229.5792 - binary_accuracy: 0.6663 - val_loss: 189.2855 - val_binary_accuracy: 0.7772\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1133.7224 - binary_accuracy: 0.6663 - val_loss: 403.9782 - val_binary_accuracy: 0.7693\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 943.2089 - binary_accuracy: 0.6640 - val_loss: 569.7208 - val_binary_accuracy: 0.7840\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 751.5308 - binary_accuracy: 0.6667 - val_loss: 624.4741 - val_binary_accuracy: 0.7842\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 642.1647 - binary_accuracy: 0.6652 - val_loss: 330.6170 - val_binary_accuracy: 0.7672\n",
      "116/116 [==============================] - 0s 511us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 946us/step - loss: 3525.8816 - binary_accuracy: 0.6793 - val_loss: 5723.2568 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 2963.6655 - binary_accuracy: 0.6578 - val_loss: 1260.8008 - val_binary_accuracy: 0.7842\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 2000.3969 - binary_accuracy: 0.6627 - val_loss: 733.7137 - val_binary_accuracy: 0.7809\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 1776.8497 - binary_accuracy: 0.6592 - val_loss: 1581.0143 - val_binary_accuracy: 0.7841\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1627.2157 - binary_accuracy: 0.6622 - val_loss: 3040.3713 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 1403.9968 - binary_accuracy: 0.6638 - val_loss: 1276.6744 - val_binary_accuracy: 0.2488\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 975.0162 - binary_accuracy: 0.6624 - val_loss: 58.8499 - val_binary_accuracy: 0.5803\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 938.0092 - binary_accuracy: 0.6667 - val_loss: 938.4825 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 774.6496 - binary_accuracy: 0.6596 - val_loss: 857.6847 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 660.8206 - binary_accuracy: 0.6649 - val_loss: 957.5051 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 485us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 924us/step - loss: 3457.0503 - binary_accuracy: 0.6885 - val_loss: 4523.9663 - val_binary_accuracy: 0.7747\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 780us/step - loss: 3493.0842 - binary_accuracy: 0.6623 - val_loss: 1914.5006 - val_binary_accuracy: 0.2660\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2425.8206 - binary_accuracy: 0.6628 - val_loss: 2043.8401 - val_binary_accuracy: 0.2338\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 2059.2642 - binary_accuracy: 0.6637 - val_loss: 128.7935 - val_binary_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 2034.0762 - binary_accuracy: 0.6625 - val_loss: 1138.3834 - val_binary_accuracy: 0.2199\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1896.3217 - binary_accuracy: 0.6654 - val_loss: 1481.1432 - val_binary_accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1865.3751 - binary_accuracy: 0.6652 - val_loss: 1653.9944 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1244.6642 - binary_accuracy: 0.6686 - val_loss: 387.3981 - val_binary_accuracy: 0.7719\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 1409.5465 - binary_accuracy: 0.6648 - val_loss: 977.3064 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 891.7904 - binary_accuracy: 0.6648 - val_loss: 52.1430 - val_binary_accuracy: 0.6227\n",
      "116/116 [==============================] - 0s 512us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 941us/step - loss: 2720.9883 - binary_accuracy: 0.6557 - val_loss: 3737.2346 - val_binary_accuracy: 0.7795\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 796us/step - loss: 1889.6727 - binary_accuracy: 0.6607 - val_loss: 1204.4066 - val_binary_accuracy: 0.7745\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1655.4296 - binary_accuracy: 0.6656 - val_loss: 575.9355 - val_binary_accuracy: 0.2886\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 1558.2069 - binary_accuracy: 0.6663 - val_loss: 1467.5900 - val_binary_accuracy: 0.7821\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1787.5853 - binary_accuracy: 0.6663 - val_loss: 1723.7583 - val_binary_accuracy: 0.7814\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 1609.2725 - binary_accuracy: 0.6685 - val_loss: 765.0225 - val_binary_accuracy: 0.7807\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 1651.7103 - binary_accuracy: 0.6650 - val_loss: 258.4987 - val_binary_accuracy: 0.7830\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 1061.5095 - binary_accuracy: 0.6719 - val_loss: 1027.1775 - val_binary_accuracy: 0.7797\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1245.5282 - binary_accuracy: 0.6740 - val_loss: 2451.1875 - val_binary_accuracy: 0.2316\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1324.3513 - binary_accuracy: 0.6686 - val_loss: 420.6193 - val_binary_accuracy: 0.2464\n",
      "116/116 [==============================] - 0s 548us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 981us/step - loss: 4801.5063 - binary_accuracy: 0.5700 - val_loss: 1168.9019 - val_binary_accuracy: 0.7797\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 2587.0378 - binary_accuracy: 0.6642 - val_loss: 799.3301 - val_binary_accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 2558.4426 - binary_accuracy: 0.6636 - val_loss: 3505.7615 - val_binary_accuracy: 0.7843\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 878us/step - loss: 2670.9978 - binary_accuracy: 0.6623 - val_loss: 258.7908 - val_binary_accuracy: 0.6933\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 855us/step - loss: 2420.7891 - binary_accuracy: 0.6591 - val_loss: 678.9014 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1848.6064 - binary_accuracy: 0.6682 - val_loss: 130.7448 - val_binary_accuracy: 0.7002\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 2299.8113 - binary_accuracy: 0.6675 - val_loss: 2157.0735 - val_binary_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 2218.3831 - binary_accuracy: 0.6680 - val_loss: 828.4138 - val_binary_accuracy: 0.2413\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1630.0186 - binary_accuracy: 0.6673 - val_loss: 650.3139 - val_binary_accuracy: 0.7758\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 1426.2305 - binary_accuracy: 0.6705 - val_loss: 389.6009 - val_binary_accuracy: 0.7758\n",
      "116/116 [==============================] - 0s 557us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 913us/step - loss: 2068.0991 - binary_accuracy: 0.6866 - val_loss: 192.9503 - val_binary_accuracy: 0.7366\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 767us/step - loss: 1322.5306 - binary_accuracy: 0.6623 - val_loss: 109.3891 - val_binary_accuracy: 0.4283\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 791us/step - loss: 1018.8847 - binary_accuracy: 0.6614 - val_loss: 773.9387 - val_binary_accuracy: 0.7821\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 860.6767 - binary_accuracy: 0.6651 - val_loss: 1777.1045 - val_binary_accuracy: 0.2410\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 1064.2091 - binary_accuracy: 0.6674 - val_loss: 2245.6582 - val_binary_accuracy: 0.2378\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 687.8732 - binary_accuracy: 0.6699 - val_loss: 629.3070 - val_binary_accuracy: 0.7824\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 759.5654 - binary_accuracy: 0.6671 - val_loss: 1199.4276 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 796us/step - loss: 639.6373 - binary_accuracy: 0.6670 - val_loss: 836.2896 - val_binary_accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 577.8208 - binary_accuracy: 0.6691 - val_loss: 1055.5663 - val_binary_accuracy: 0.7828\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 442.9051 - binary_accuracy: 0.6698 - val_loss: 395.1554 - val_binary_accuracy: 0.2201\n",
      "116/116 [==============================] - 0s 518us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 922us/step - loss: 3029.6206 - binary_accuracy: 0.5600 - val_loss: 1390.2017 - val_binary_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1009.7004 - binary_accuracy: 0.6565 - val_loss: 59.9329 - val_binary_accuracy: 0.7548\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1068.3468 - binary_accuracy: 0.6632 - val_loss: 1150.7668 - val_binary_accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 963us/step - loss: 819.7474 - binary_accuracy: 0.6644 - val_loss: 961.6031 - val_binary_accuracy: 0.7719\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 852.0502 - binary_accuracy: 0.6650 - val_loss: 636.9326 - val_binary_accuracy: 0.7822\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 817.8329 - binary_accuracy: 0.6643 - val_loss: 706.1158 - val_binary_accuracy: 0.7840\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 780.5728 - binary_accuracy: 0.6678 - val_loss: 2181.4021 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 787us/step - loss: 619.4561 - binary_accuracy: 0.6652 - val_loss: 383.6863 - val_binary_accuracy: 0.7811\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 659.9180 - binary_accuracy: 0.6700 - val_loss: 689.2228 - val_binary_accuracy: 0.7840\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 671.7335 - binary_accuracy: 0.6638 - val_loss: 865.5351 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 539us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 923us/step - loss: 2179.7939 - binary_accuracy: 0.6897 - val_loss: 1621.5375 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1495.7284 - binary_accuracy: 0.6685 - val_loss: 1164.2102 - val_binary_accuracy: 0.7729\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 1368.7682 - binary_accuracy: 0.6620 - val_loss: 4441.5679 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 957.6746 - binary_accuracy: 0.6660 - val_loss: 352.1597 - val_binary_accuracy: 0.4442\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 853.4616 - binary_accuracy: 0.6624 - val_loss: 307.6716 - val_binary_accuracy: 0.7690\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 756.5027 - binary_accuracy: 0.6693 - val_loss: 491.3658 - val_binary_accuracy: 0.7744\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 739.6384 - binary_accuracy: 0.6629 - val_loss: 1064.2241 - val_binary_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 720.4082 - binary_accuracy: 0.6672 - val_loss: 100.9051 - val_binary_accuracy: 0.7529\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 618.6234 - binary_accuracy: 0.6649 - val_loss: 61.8827 - val_binary_accuracy: 0.6244\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 602.0640 - binary_accuracy: 0.6666 - val_loss: 835.9135 - val_binary_accuracy: 0.7822\n",
      "116/116 [==============================] - 0s 491us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 933us/step - loss: 3846.7810 - binary_accuracy: 0.6775 - val_loss: 433.6797 - val_binary_accuracy: 0.2785\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 788us/step - loss: 1303.9370 - binary_accuracy: 0.6623 - val_loss: 899.1749 - val_binary_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 1214.3634 - binary_accuracy: 0.6629 - val_loss: 2373.3564 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 1020.3700 - binary_accuracy: 0.6616 - val_loss: 1547.4823 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1161.1594 - binary_accuracy: 0.6686 - val_loss: 885.7946 - val_binary_accuracy: 0.7733\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 996.0820 - binary_accuracy: 0.6656 - val_loss: 205.0167 - val_binary_accuracy: 0.7700\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 846.1547 - binary_accuracy: 0.6692 - val_loss: 828.5410 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 779.0717 - binary_accuracy: 0.6661 - val_loss: 1089.1703 - val_binary_accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 689.4459 - binary_accuracy: 0.6668 - val_loss: 44.5149 - val_binary_accuracy: 0.7508\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 617.4255 - binary_accuracy: 0.6687 - val_loss: 228.8950 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 549us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 951us/step - loss: 2407.8564 - binary_accuracy: 0.6868 - val_loss: 1497.3079 - val_binary_accuracy: 0.7515\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2587.5510 - binary_accuracy: 0.6559 - val_loss: 1297.1045 - val_binary_accuracy: 0.7827\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 2572.4514 - binary_accuracy: 0.6606 - val_loss: 2134.2422 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 2382.3284 - binary_accuracy: 0.6612 - val_loss: 545.5507 - val_binary_accuracy: 0.7829\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1630.4417 - binary_accuracy: 0.6649 - val_loss: 180.6562 - val_binary_accuracy: 0.7352\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 2007.8615 - binary_accuracy: 0.6612 - val_loss: 1264.1379 - val_binary_accuracy: 0.7677\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 1626.7084 - binary_accuracy: 0.6628 - val_loss: 3332.8462 - val_binary_accuracy: 0.2227\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1871.3721 - binary_accuracy: 0.6616 - val_loss: 568.8104 - val_binary_accuracy: 0.7833\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 1340.8673 - binary_accuracy: 0.6622 - val_loss: 694.9365 - val_binary_accuracy: 0.7685\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 998.9886 - binary_accuracy: 0.6612 - val_loss: 1232.2292 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 562us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 929us/step - loss: 6127.3872 - binary_accuracy: 0.6871 - val_loss: 742.9496 - val_binary_accuracy: 0.7511\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 1086.5309 - binary_accuracy: 0.6635 - val_loss: 619.0593 - val_binary_accuracy: 0.2787\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 826.6443 - binary_accuracy: 0.6643 - val_loss: 405.0703 - val_binary_accuracy: 0.2928\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 979us/step - loss: 707.5322 - binary_accuracy: 0.6637 - val_loss: 968.8340 - val_binary_accuracy: 0.7840\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 731.6330 - binary_accuracy: 0.6691 - val_loss: 1632.2622 - val_binary_accuracy: 0.2268\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 628.9308 - binary_accuracy: 0.6668 - val_loss: 1001.5573 - val_binary_accuracy: 0.2316\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 661.9618 - binary_accuracy: 0.6636 - val_loss: 56.5240 - val_binary_accuracy: 0.7282\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 478.2504 - binary_accuracy: 0.6682 - val_loss: 1138.4323 - val_binary_accuracy: 0.7819\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 552.2680 - binary_accuracy: 0.6691 - val_loss: 976.3879 - val_binary_accuracy: 0.2355\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 423.8604 - binary_accuracy: 0.6661 - val_loss: 319.7144 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 929us/step - loss: 3292.2595 - binary_accuracy: 0.6898 - val_loss: 122.0004 - val_binary_accuracy: 0.7240\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2693.1719 - binary_accuracy: 0.6624 - val_loss: 744.6013 - val_binary_accuracy: 0.7676\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 2522.6780 - binary_accuracy: 0.6643 - val_loss: 4522.5376 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 2152.7102 - binary_accuracy: 0.6642 - val_loss: 4888.2520 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1720.2124 - binary_accuracy: 0.6645 - val_loss: 882.5914 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 1605.4159 - binary_accuracy: 0.6642 - val_loss: 1700.1030 - val_binary_accuracy: 0.2561\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1978.5759 - binary_accuracy: 0.6612 - val_loss: 1048.1669 - val_binary_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 1453.5162 - binary_accuracy: 0.6701 - val_loss: 1728.6857 - val_binary_accuracy: 0.7841\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 1548.6990 - binary_accuracy: 0.6652 - val_loss: 935.2411 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 1428.8961 - binary_accuracy: 0.6674 - val_loss: 3100.2786 - val_binary_accuracy: 0.7850\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 923us/step - loss: 3705.0447 - binary_accuracy: 0.6862 - val_loss: 3760.4329 - val_binary_accuracy: 0.7781\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 3038.3196 - binary_accuracy: 0.6633 - val_loss: 2615.2231 - val_binary_accuracy: 0.7824\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 2334.5007 - binary_accuracy: 0.6622 - val_loss: 3174.6348 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 2127.1064 - binary_accuracy: 0.6666 - val_loss: 6641.0205 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 2307.3950 - binary_accuracy: 0.6636 - val_loss: 504.5848 - val_binary_accuracy: 0.7766\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 2054.6321 - binary_accuracy: 0.6671 - val_loss: 2584.9583 - val_binary_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 904us/step - loss: 2032.2271 - binary_accuracy: 0.6674 - val_loss: 3030.0581 - val_binary_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1785.8730 - binary_accuracy: 0.6643 - val_loss: 4611.2329 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 1728.2842 - binary_accuracy: 0.6709 - val_loss: 5253.6680 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1831.8594 - binary_accuracy: 0.6700 - val_loss: 110.7733 - val_binary_accuracy: 0.6850\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 956us/step - loss: 2879.4043 - binary_accuracy: 0.6676 - val_loss: 6217.6436 - val_binary_accuracy: 0.7844\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 2116.4243 - binary_accuracy: 0.6605 - val_loss: 2121.7905 - val_binary_accuracy: 0.7850\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 2022.2524 - binary_accuracy: 0.6660 - val_loss: 829.7089 - val_binary_accuracy: 0.7505\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 1465.1060 - binary_accuracy: 0.6649 - val_loss: 521.0490 - val_binary_accuracy: 0.7757\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 1146.2188 - binary_accuracy: 0.6660 - val_loss: 73.0328 - val_binary_accuracy: 0.6600\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1094.0253 - binary_accuracy: 0.6641 - val_loss: 616.2448 - val_binary_accuracy: 0.6690\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 800.9686 - binary_accuracy: 0.6594 - val_loss: 1731.5148 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 808.7818 - binary_accuracy: 0.6703 - val_loss: 201.4861 - val_binary_accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 743.1179 - binary_accuracy: 0.6700 - val_loss: 864.9494 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 725.6194 - binary_accuracy: 0.6683 - val_loss: 574.9434 - val_binary_accuracy: 0.3157\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 927us/step - loss: 1728.1613 - binary_accuracy: 0.5848 - val_loss: 2240.6838 - val_binary_accuracy: 0.7594\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 786us/step - loss: 1428.2858 - binary_accuracy: 0.6616 - val_loss: 1974.8663 - val_binary_accuracy: 0.2449\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1431.8964 - binary_accuracy: 0.6653 - val_loss: 496.0457 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 1228.6353 - binary_accuracy: 0.6669 - val_loss: 860.2438 - val_binary_accuracy: 0.7527\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1220.3701 - binary_accuracy: 0.6643 - val_loss: 236.9006 - val_binary_accuracy: 0.3047\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 953.8517 - binary_accuracy: 0.6681 - val_loss: 1727.6337 - val_binary_accuracy: 0.2737\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1228.5884 - binary_accuracy: 0.6677 - val_loss: 373.1561 - val_binary_accuracy: 0.7716\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 1245.9546 - binary_accuracy: 0.6715 - val_loss: 74.8489 - val_binary_accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 1119.6367 - binary_accuracy: 0.6711 - val_loss: 3876.3513 - val_binary_accuracy: 0.2174\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 779.0403 - binary_accuracy: 0.6735 - val_loss: 487.2377 - val_binary_accuracy: 0.7814\n",
      "116/116 [==============================] - 0s 501us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 929us/step - loss: 1360.7999 - binary_accuracy: 0.6823 - val_loss: 1631.7335 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 751.2266 - binary_accuracy: 0.6649 - val_loss: 777.3254 - val_binary_accuracy: 0.7842\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 500.2753 - binary_accuracy: 0.6666 - val_loss: 668.1481 - val_binary_accuracy: 0.2635\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 966us/step - loss: 314.8135 - binary_accuracy: 0.6604 - val_loss: 439.2220 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 282.5988 - binary_accuracy: 0.6658 - val_loss: 643.3869 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 190.9498 - binary_accuracy: 0.6692 - val_loss: 42.6395 - val_binary_accuracy: 0.7761\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 148.7012 - binary_accuracy: 0.6668 - val_loss: 78.1133 - val_binary_accuracy: 0.7811\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 165.0947 - binary_accuracy: 0.6666 - val_loss: 185.4541 - val_binary_accuracy: 0.7840\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 118.1097 - binary_accuracy: 0.6667 - val_loss: 107.3090 - val_binary_accuracy: 0.7842\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 91.5170 - binary_accuracy: 0.6682 - val_loss: 43.6052 - val_binary_accuracy: 0.7604\n",
      "116/116 [==============================] - 0s 508us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 918us/step - loss: 3841.9138 - binary_accuracy: 0.6792 - val_loss: 391.7781 - val_binary_accuracy: 0.3334\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 908.0099 - binary_accuracy: 0.6602 - val_loss: 225.9918 - val_binary_accuracy: 0.7657\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 953.5035 - binary_accuracy: 0.6676 - val_loss: 787.4352 - val_binary_accuracy: 0.7830\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 980us/step - loss: 995.9306 - binary_accuracy: 0.6647 - val_loss: 285.8145 - val_binary_accuracy: 0.6975\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 855.9956 - binary_accuracy: 0.6598 - val_loss: 75.0240 - val_binary_accuracy: 0.7300\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 770.4578 - binary_accuracy: 0.6637 - val_loss: 443.3762 - val_binary_accuracy: 0.7413\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 730.2487 - binary_accuracy: 0.6643 - val_loss: 150.1859 - val_binary_accuracy: 0.6112\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 580.0540 - binary_accuracy: 0.6658 - val_loss: 326.1733 - val_binary_accuracy: 0.7684\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 524.5955 - binary_accuracy: 0.6664 - val_loss: 1569.6161 - val_binary_accuracy: 0.2583\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 375.8429 - binary_accuracy: 0.6643 - val_loss: 401.1033 - val_binary_accuracy: 0.7806\n",
      "116/116 [==============================] - 0s 498us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 920us/step - loss: 12188.8213 - binary_accuracy: 0.6823 - val_loss: 7258.9287 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 3063.1233 - binary_accuracy: 0.6648 - val_loss: 1761.0483 - val_binary_accuracy: 0.7843\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 2787.5847 - binary_accuracy: 0.6624 - val_loss: 2007.0060 - val_binary_accuracy: 0.7828\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 2697.5447 - binary_accuracy: 0.6669 - val_loss: 799.4343 - val_binary_accuracy: 0.7759\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 985us/step - loss: 2220.7024 - binary_accuracy: 0.6639 - val_loss: 5192.7905 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 2746.9895 - binary_accuracy: 0.6646 - val_loss: 1196.5574 - val_binary_accuracy: 0.7830\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 1996.0612 - binary_accuracy: 0.6638 - val_loss: 1374.8865 - val_binary_accuracy: 0.7807\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1834.5504 - binary_accuracy: 0.6689 - val_loss: 486.8170 - val_binary_accuracy: 0.7494\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 1461.9084 - binary_accuracy: 0.6669 - val_loss: 3067.9299 - val_binary_accuracy: 0.7839\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 1316.3281 - binary_accuracy: 0.6668 - val_loss: 1925.2430 - val_binary_accuracy: 0.7812\n",
      "116/116 [==============================] - 0s 501us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 902us/step - loss: 4202.1050 - binary_accuracy: 0.6917 - val_loss: 556.7742 - val_binary_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 945us/step - loss: 1146.0762 - binary_accuracy: 0.6661 - val_loss: 1149.5642 - val_binary_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1528.7196 - binary_accuracy: 0.6655 - val_loss: 3574.8201 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 981.3597 - binary_accuracy: 0.6651 - val_loss: 683.7105 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1044.3146 - binary_accuracy: 0.6655 - val_loss: 1435.8403 - val_binary_accuracy: 0.2462\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 1020.3395 - binary_accuracy: 0.6656 - val_loss: 96.4097 - val_binary_accuracy: 0.5085\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 790us/step - loss: 858.4487 - binary_accuracy: 0.6657 - val_loss: 913.3842 - val_binary_accuracy: 0.2491\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 826.9814 - binary_accuracy: 0.6680 - val_loss: 2523.7566 - val_binary_accuracy: 0.2324\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 796us/step - loss: 702.1375 - binary_accuracy: 0.6695 - val_loss: 456.0525 - val_binary_accuracy: 0.7805\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 662.4300 - binary_accuracy: 0.6690 - val_loss: 1224.1091 - val_binary_accuracy: 0.7844\n",
      "116/116 [==============================] - 0s 499us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 912us/step - loss: 3176.1624 - binary_accuracy: 0.6854 - val_loss: 535.3761 - val_binary_accuracy: 0.7342\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 2355.4895 - binary_accuracy: 0.6626 - val_loss: 161.6738 - val_binary_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 2056.6328 - binary_accuracy: 0.6647 - val_loss: 1368.0647 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 2060.8616 - binary_accuracy: 0.6601 - val_loss: 2562.6582 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 1910.0129 - binary_accuracy: 0.6631 - val_loss: 383.0765 - val_binary_accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 808us/step - loss: 1837.6317 - binary_accuracy: 0.6608 - val_loss: 3053.7651 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1704.9669 - binary_accuracy: 0.6618 - val_loss: 3134.6306 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 1527.2328 - binary_accuracy: 0.6629 - val_loss: 971.8668 - val_binary_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 1251.6515 - binary_accuracy: 0.6641 - val_loss: 2058.5637 - val_binary_accuracy: 0.2284\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1016.2344 - binary_accuracy: 0.6631 - val_loss: 981.8760 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 506us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 905us/step - loss: 2782.1526 - binary_accuracy: 0.6881 - val_loss: 3396.8489 - val_binary_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 783us/step - loss: 1775.4554 - binary_accuracy: 0.6651 - val_loss: 961.3057 - val_binary_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 797us/step - loss: 1561.7361 - binary_accuracy: 0.6670 - val_loss: 1221.7181 - val_binary_accuracy: 0.2595\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 1666.1383 - binary_accuracy: 0.6672 - val_loss: 180.9350 - val_binary_accuracy: 0.6774\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 1355.0557 - binary_accuracy: 0.6672 - val_loss: 629.3925 - val_binary_accuracy: 0.7830\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 684.1362 - binary_accuracy: 0.6691 - val_loss: 229.3568 - val_binary_accuracy: 0.7058\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 794us/step - loss: 616.8161 - binary_accuracy: 0.6663 - val_loss: 224.9516 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 682.5339 - binary_accuracy: 0.6652 - val_loss: 784.9357 - val_binary_accuracy: 0.7839\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 615.4897 - binary_accuracy: 0.6712 - val_loss: 755.7238 - val_binary_accuracy: 0.2420\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 628.4767 - binary_accuracy: 0.6674 - val_loss: 333.9718 - val_binary_accuracy: 0.7851\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 915us/step - loss: 2980.9380 - binary_accuracy: 0.6894 - val_loss: 3066.3184 - val_binary_accuracy: 0.2394\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 774us/step - loss: 1802.6904 - binary_accuracy: 0.6634 - val_loss: 976.6639 - val_binary_accuracy: 0.7639\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 1793.0001 - binary_accuracy: 0.6627 - val_loss: 4272.2422 - val_binary_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 1565.3053 - binary_accuracy: 0.6649 - val_loss: 1675.4666 - val_binary_accuracy: 0.7703\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 880us/step - loss: 1244.0240 - binary_accuracy: 0.6634 - val_loss: 606.8453 - val_binary_accuracy: 0.7592\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1603.9227 - binary_accuracy: 0.6678 - val_loss: 1805.5239 - val_binary_accuracy: 0.2323\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 805us/step - loss: 1168.4031 - binary_accuracy: 0.6649 - val_loss: 453.9019 - val_binary_accuracy: 0.7829\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 1148.8274 - binary_accuracy: 0.6671 - val_loss: 762.1785 - val_binary_accuracy: 0.7840\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 891.2736 - binary_accuracy: 0.6658 - val_loss: 580.5485 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 941.2444 - binary_accuracy: 0.6657 - val_loss: 268.4692 - val_binary_accuracy: 0.7570\n",
      "116/116 [==============================] - 0s 509us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 909us/step - loss: 5116.0015 - binary_accuracy: 0.6827 - val_loss: 5179.3579 - val_binary_accuracy: 0.7823\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 770us/step - loss: 2901.4680 - binary_accuracy: 0.6669 - val_loss: 2009.3363 - val_binary_accuracy: 0.7842\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 2312.2236 - binary_accuracy: 0.6642 - val_loss: 2260.8105 - val_binary_accuracy: 0.7755\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 2332.7324 - binary_accuracy: 0.6636 - val_loss: 254.3012 - val_binary_accuracy: 0.5473\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2122.9275 - binary_accuracy: 0.6689 - val_loss: 2306.9009 - val_binary_accuracy: 0.7811\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 1964.2522 - binary_accuracy: 0.6649 - val_loss: 1096.1675 - val_binary_accuracy: 0.7809\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 798us/step - loss: 1847.8645 - binary_accuracy: 0.6634 - val_loss: 4053.6968 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 2384.9863 - binary_accuracy: 0.6661 - val_loss: 5362.1484 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 792us/step - loss: 1744.7782 - binary_accuracy: 0.6692 - val_loss: 564.5742 - val_binary_accuracy: 0.7810\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 1615.5352 - binary_accuracy: 0.6719 - val_loss: 514.3492 - val_binary_accuracy: 0.7463\n",
      "116/116 [==============================] - 0s 507us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 928us/step - loss: 3725.1252 - binary_accuracy: 0.6829 - val_loss: 595.8611 - val_binary_accuracy: 0.3789\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 782us/step - loss: 2235.1194 - binary_accuracy: 0.6637 - val_loss: 2407.2844 - val_binary_accuracy: 0.7844\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 2396.7288 - binary_accuracy: 0.6645 - val_loss: 1010.7202 - val_binary_accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 904us/step - loss: 1934.1654 - binary_accuracy: 0.6615 - val_loss: 3121.6912 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 2006.6676 - binary_accuracy: 0.6648 - val_loss: 605.9073 - val_binary_accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 945us/step - loss: 1991.2302 - binary_accuracy: 0.6612 - val_loss: 2219.2886 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1235.7719 - binary_accuracy: 0.6662 - val_loss: 314.2393 - val_binary_accuracy: 0.7546\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1324.9323 - binary_accuracy: 0.6643 - val_loss: 2181.5823 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1104.7988 - binary_accuracy: 0.6640 - val_loss: 2505.2197 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 1482.3641 - binary_accuracy: 0.6657 - val_loss: 897.8809 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 545us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 971us/step - loss: 3235.0923 - binary_accuracy: 0.6920 - val_loss: 2114.7678 - val_binary_accuracy: 0.7829\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2821.9587 - binary_accuracy: 0.6645 - val_loss: 2378.4207 - val_binary_accuracy: 0.7839\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 2344.6355 - binary_accuracy: 0.6662 - val_loss: 158.3726 - val_binary_accuracy: 0.6716\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1933.7004 - binary_accuracy: 0.6635 - val_loss: 1594.1931 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1413.1313 - binary_accuracy: 0.6673 - val_loss: 556.5880 - val_binary_accuracy: 0.7734\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 1560.2184 - binary_accuracy: 0.6661 - val_loss: 314.6162 - val_binary_accuracy: 0.7794\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1543.7428 - binary_accuracy: 0.6660 - val_loss: 2714.5767 - val_binary_accuracy: 0.2172\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1270.9723 - binary_accuracy: 0.6649 - val_loss: 1406.3564 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 951us/step - loss: 1240.9922 - binary_accuracy: 0.6674 - val_loss: 253.2816 - val_binary_accuracy: 0.2297\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1167.7335 - binary_accuracy: 0.6677 - val_loss: 2272.5022 - val_binary_accuracy: 0.2453\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 927us/step - loss: 5030.8735 - binary_accuracy: 0.5697 - val_loss: 7329.4448 - val_binary_accuracy: 0.7850\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 2322.1960 - binary_accuracy: 0.6622 - val_loss: 2257.8486 - val_binary_accuracy: 0.7471\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1915.6167 - binary_accuracy: 0.6595 - val_loss: 1035.1555 - val_binary_accuracy: 0.7710\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1688.9718 - binary_accuracy: 0.6648 - val_loss: 1453.4912 - val_binary_accuracy: 0.7846\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1531.5455 - binary_accuracy: 0.6669 - val_loss: 662.6271 - val_binary_accuracy: 0.7821\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 1854.4312 - binary_accuracy: 0.6659 - val_loss: 2142.7939 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1387.5162 - binary_accuracy: 0.6633 - val_loss: 821.5211 - val_binary_accuracy: 0.7268\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1211.2792 - binary_accuracy: 0.6616 - val_loss: 2933.1221 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1413.8086 - binary_accuracy: 0.6663 - val_loss: 520.5787 - val_binary_accuracy: 0.2623\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1020.5706 - binary_accuracy: 0.6693 - val_loss: 74.1131 - val_binary_accuracy: 0.4231\n",
      "116/116 [==============================] - 0s 499us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 909us/step - loss: 3268.8621 - binary_accuracy: 0.6090 - val_loss: 861.6457 - val_binary_accuracy: 0.7672\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 774us/step - loss: 2732.4058 - binary_accuracy: 0.6615 - val_loss: 1381.8317 - val_binary_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 2477.2339 - binary_accuracy: 0.6658 - val_loss: 1609.4240 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 2166.9978 - binary_accuracy: 0.6618 - val_loss: 100.8848 - val_binary_accuracy: 0.7557\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 1453.9099 - binary_accuracy: 0.6628 - val_loss: 776.4342 - val_binary_accuracy: 0.7840\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1610.2607 - binary_accuracy: 0.6645 - val_loss: 2708.0593 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 1257.3833 - binary_accuracy: 0.6684 - val_loss: 489.2085 - val_binary_accuracy: 0.7814\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 1356.7461 - binary_accuracy: 0.6650 - val_loss: 489.0460 - val_binary_accuracy: 0.7679\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 1125.8861 - binary_accuracy: 0.6676 - val_loss: 552.6393 - val_binary_accuracy: 0.7781\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 969.8065 - binary_accuracy: 0.6670 - val_loss: 436.9508 - val_binary_accuracy: 0.7825\n",
      "116/116 [==============================] - 0s 517us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 942us/step - loss: 3598.7432 - binary_accuracy: 0.6905 - val_loss: 1582.6702 - val_binary_accuracy: 0.7837\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 3294.3420 - binary_accuracy: 0.6621 - val_loss: 1928.1547 - val_binary_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 3115.6741 - binary_accuracy: 0.6652 - val_loss: 1793.2976 - val_binary_accuracy: 0.7759\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 2218.1125 - binary_accuracy: 0.6619 - val_loss: 1403.8833 - val_binary_accuracy: 0.7835\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 1710.8247 - binary_accuracy: 0.6640 - val_loss: 2833.4412 - val_binary_accuracy: 0.2384\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 2092.6462 - binary_accuracy: 0.6637 - val_loss: 5436.0566 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 908us/step - loss: 2010.1909 - binary_accuracy: 0.6659 - val_loss: 2497.0220 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1658.4196 - binary_accuracy: 0.6694 - val_loss: 1357.3219 - val_binary_accuracy: 0.2227\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1326.2777 - binary_accuracy: 0.6630 - val_loss: 1546.5797 - val_binary_accuracy: 0.7840\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1378.1907 - binary_accuracy: 0.6688 - val_loss: 1491.8372 - val_binary_accuracy: 0.2535\n",
      "116/116 [==============================] - 0s 500us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4046.8428 - binary_accuracy: 0.5739 - val_loss: 584.0928 - val_binary_accuracy: 0.7764\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 2047.4243 - binary_accuracy: 0.6625 - val_loss: 1059.3394 - val_binary_accuracy: 0.7729\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2186.1665 - binary_accuracy: 0.6585 - val_loss: 595.9386 - val_binary_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 946us/step - loss: 1216.1781 - binary_accuracy: 0.6625 - val_loss: 1923.2688 - val_binary_accuracy: 0.2299\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1145.3264 - binary_accuracy: 0.6614 - val_loss: 1602.3875 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 1080.7805 - binary_accuracy: 0.6657 - val_loss: 150.0592 - val_binary_accuracy: 0.4727\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 1098.3868 - binary_accuracy: 0.6598 - val_loss: 1676.4982 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 867.5148 - binary_accuracy: 0.6640 - val_loss: 215.7160 - val_binary_accuracy: 0.7810\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 504.8381 - binary_accuracy: 0.6677 - val_loss: 266.9579 - val_binary_accuracy: 0.7825\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 602.1075 - binary_accuracy: 0.6643 - val_loss: 591.8306 - val_binary_accuracy: 0.7589\n",
      "116/116 [==============================] - 0s 536us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 941us/step - loss: 6976.6313 - binary_accuracy: 0.6768 - val_loss: 2393.3018 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 2214.9097 - binary_accuracy: 0.6589 - val_loss: 2530.6628 - val_binary_accuracy: 0.7838\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1991.2660 - binary_accuracy: 0.6646 - val_loss: 955.1707 - val_binary_accuracy: 0.7715\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1641.9905 - binary_accuracy: 0.6625 - val_loss: 1633.1202 - val_binary_accuracy: 0.7813\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1426.4625 - binary_accuracy: 0.6665 - val_loss: 1399.2502 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1149.3660 - binary_accuracy: 0.6610 - val_loss: 2305.8472 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 989.2964 - binary_accuracy: 0.6623 - val_loss: 2001.1434 - val_binary_accuracy: 0.2166\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 869.6248 - binary_accuracy: 0.6658 - val_loss: 1997.2776 - val_binary_accuracy: 0.2300\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 987.5656 - binary_accuracy: 0.6689 - val_loss: 1306.3002 - val_binary_accuracy: 0.7841\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 822us/step - loss: 708.7915 - binary_accuracy: 0.6687 - val_loss: 62.0005 - val_binary_accuracy: 0.6684\n",
      "116/116 [==============================] - 0s 533us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 935us/step - loss: 5123.9194 - binary_accuracy: 0.6606 - val_loss: 7565.9062 - val_binary_accuracy: 0.7687\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 3188.9375 - binary_accuracy: 0.6631 - val_loss: 977.0099 - val_binary_accuracy: 0.2835\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 2303.4312 - binary_accuracy: 0.6645 - val_loss: 3218.3074 - val_binary_accuracy: 0.7840\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1844.6200 - binary_accuracy: 0.6647 - val_loss: 898.0409 - val_binary_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 993us/step - loss: 1816.0762 - binary_accuracy: 0.6634 - val_loss: 1841.6927 - val_binary_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 892us/step - loss: 1706.5629 - binary_accuracy: 0.6661 - val_loss: 1423.1758 - val_binary_accuracy: 0.7798\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 1658.1266 - binary_accuracy: 0.6661 - val_loss: 85.1993 - val_binary_accuracy: 0.4984\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1531.3303 - binary_accuracy: 0.6672 - val_loss: 2518.8870 - val_binary_accuracy: 0.3285\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1081.4391 - binary_accuracy: 0.6630 - val_loss: 850.8340 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 844.0880 - binary_accuracy: 0.6710 - val_loss: 747.4122 - val_binary_accuracy: 0.3059\n",
      "116/116 [==============================] - 0s 522us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 932us/step - loss: 3008.1033 - binary_accuracy: 0.5822 - val_loss: 1526.4363 - val_binary_accuracy: 0.2413\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 2206.3284 - binary_accuracy: 0.6626 - val_loss: 336.0709 - val_binary_accuracy: 0.6260\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1319.3500 - binary_accuracy: 0.6655 - val_loss: 709.7593 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1537.0034 - binary_accuracy: 0.6599 - val_loss: 702.4590 - val_binary_accuracy: 0.7841\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 855us/step - loss: 1247.4584 - binary_accuracy: 0.6608 - val_loss: 1144.1914 - val_binary_accuracy: 0.2574\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 949us/step - loss: 971.5736 - binary_accuracy: 0.6626 - val_loss: 1429.2692 - val_binary_accuracy: 0.7803\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 985.3657 - binary_accuracy: 0.6630 - val_loss: 978.1086 - val_binary_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 688.2015 - binary_accuracy: 0.6659 - val_loss: 195.4521 - val_binary_accuracy: 0.7604\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 725.5972 - binary_accuracy: 0.6690 - val_loss: 605.0598 - val_binary_accuracy: 0.2580\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 623.7499 - binary_accuracy: 0.6651 - val_loss: 618.7512 - val_binary_accuracy: 0.7740\n",
      "116/116 [==============================] - 0s 551us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 922us/step - loss: 4101.3628 - binary_accuracy: 0.6881 - val_loss: 6860.8857 - val_binary_accuracy: 0.7831\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 795us/step - loss: 4037.5479 - binary_accuracy: 0.6639 - val_loss: 919.7700 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 810us/step - loss: 1963.2273 - binary_accuracy: 0.6664 - val_loss: 680.9246 - val_binary_accuracy: 0.2431\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 2409.3257 - binary_accuracy: 0.6631 - val_loss: 10558.1309 - val_binary_accuracy: 0.2336\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 3043.9436 - binary_accuracy: 0.6681 - val_loss: 965.1973 - val_binary_accuracy: 0.2434\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1646.3098 - binary_accuracy: 0.6674 - val_loss: 2206.1641 - val_binary_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 1756.7172 - binary_accuracy: 0.6670 - val_loss: 1265.2621 - val_binary_accuracy: 0.7836\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 1175.2616 - binary_accuracy: 0.6669 - val_loss: 314.6193 - val_binary_accuracy: 0.7715\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 964.7011 - binary_accuracy: 0.6698 - val_loss: 1371.6652 - val_binary_accuracy: 0.7838\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1106.3960 - binary_accuracy: 0.6715 - val_loss: 324.6186 - val_binary_accuracy: 0.7807\n",
      "116/116 [==============================] - 0s 514us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 918us/step - loss: 3257.5884 - binary_accuracy: 0.6887 - val_loss: 394.0233 - val_binary_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 789us/step - loss: 1941.0173 - binary_accuracy: 0.6617 - val_loss: 2092.9282 - val_binary_accuracy: 0.7759\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 2239.5098 - binary_accuracy: 0.6632 - val_loss: 692.1983 - val_binary_accuracy: 0.7712\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 821us/step - loss: 1959.5692 - binary_accuracy: 0.6654 - val_loss: 2888.5869 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 1431.1224 - binary_accuracy: 0.6643 - val_loss: 1982.3097 - val_binary_accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 1143.8444 - binary_accuracy: 0.6578 - val_loss: 834.5649 - val_binary_accuracy: 0.7738\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 1036.0023 - binary_accuracy: 0.6689 - val_loss: 851.6569 - val_binary_accuracy: 0.7844\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 843.4445 - binary_accuracy: 0.6604 - val_loss: 177.4926 - val_binary_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 1069.3296 - binary_accuracy: 0.6661 - val_loss: 1218.7435 - val_binary_accuracy: 0.2364\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 807us/step - loss: 790.1575 - binary_accuracy: 0.6678 - val_loss: 1987.8390 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 498us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 947us/step - loss: 6752.6553 - binary_accuracy: 0.6933 - val_loss: 4472.8413 - val_binary_accuracy: 0.2178\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 4081.9819 - binary_accuracy: 0.6634 - val_loss: 5675.3755 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3277.1516 - binary_accuracy: 0.6676 - val_loss: 2217.4412 - val_binary_accuracy: 0.2214\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 3552.2437 - binary_accuracy: 0.6644 - val_loss: 5362.3755 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 2920.6946 - binary_accuracy: 0.6654 - val_loss: 2346.6218 - val_binary_accuracy: 0.2862\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 812us/step - loss: 2356.4705 - binary_accuracy: 0.6654 - val_loss: 8542.8535 - val_binary_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2947.2444 - binary_accuracy: 0.6675 - val_loss: 3457.5015 - val_binary_accuracy: 0.2154\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1785.6055 - binary_accuracy: 0.6673 - val_loss: 3898.1025 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 824us/step - loss: 1688.7147 - binary_accuracy: 0.6666 - val_loss: 2214.3340 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1969.7261 - binary_accuracy: 0.6669 - val_loss: 1465.1036 - val_binary_accuracy: 0.7762\n",
      "116/116 [==============================] - 0s 549us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 2ms/step - loss: 4206.6304 - binary_accuracy: 0.6845 - val_loss: 1060.2345 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 2274.3625 - binary_accuracy: 0.6639 - val_loss: 4635.3403 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 1852.0785 - binary_accuracy: 0.6593 - val_loss: 2401.8274 - val_binary_accuracy: 0.7742\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1796.6022 - binary_accuracy: 0.6651 - val_loss: 1685.6576 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1396.6804 - binary_accuracy: 0.6634 - val_loss: 2644.4526 - val_binary_accuracy: 0.2719\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 915us/step - loss: 1397.5839 - binary_accuracy: 0.6619 - val_loss: 1205.2727 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1309.1770 - binary_accuracy: 0.6674 - val_loss: 350.1289 - val_binary_accuracy: 0.7692\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1117.1829 - binary_accuracy: 0.6656 - val_loss: 129.2009 - val_binary_accuracy: 0.5778\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1153.1306 - binary_accuracy: 0.6644 - val_loss: 95.9347 - val_binary_accuracy: 0.7491\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 818.7056 - binary_accuracy: 0.6625 - val_loss: 251.1760 - val_binary_accuracy: 0.7796\n",
      "116/116 [==============================] - 0s 521us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 955us/step - loss: 4295.2314 - binary_accuracy: 0.6829 - val_loss: 2467.7590 - val_binary_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 2897.2258 - binary_accuracy: 0.6596 - val_loss: 1687.5332 - val_binary_accuracy: 0.2426\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 892us/step - loss: 2278.0303 - binary_accuracy: 0.6620 - val_loss: 972.4727 - val_binary_accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1812.0337 - binary_accuracy: 0.6629 - val_loss: 3456.4087 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2177.1833 - binary_accuracy: 0.6640 - val_loss: 362.9412 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 1803.6737 - binary_accuracy: 0.6628 - val_loss: 46.5815 - val_binary_accuracy: 0.7417\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1661.8413 - binary_accuracy: 0.6655 - val_loss: 331.5665 - val_binary_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1619.0048 - binary_accuracy: 0.6630 - val_loss: 1783.8665 - val_binary_accuracy: 0.7838\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1254.6694 - binary_accuracy: 0.6647 - val_loss: 559.7399 - val_binary_accuracy: 0.2518\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1101.3177 - binary_accuracy: 0.6655 - val_loss: 234.9693 - val_binary_accuracy: 0.7739\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 957us/step - loss: 3539.6399 - binary_accuracy: 0.6851 - val_loss: 254.4611 - val_binary_accuracy: 0.7447\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 806us/step - loss: 2631.9019 - binary_accuracy: 0.6645 - val_loss: 463.7595 - val_binary_accuracy: 0.7761\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2282.2869 - binary_accuracy: 0.6646 - val_loss: 296.4155 - val_binary_accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 2189.7019 - binary_accuracy: 0.6676 - val_loss: 824.4897 - val_binary_accuracy: 0.6234\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1546.3877 - binary_accuracy: 0.6654 - val_loss: 1009.0922 - val_binary_accuracy: 0.5149\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 1633.7448 - binary_accuracy: 0.6607 - val_loss: 1476.9460 - val_binary_accuracy: 0.7831\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1596.2203 - binary_accuracy: 0.6634 - val_loss: 1661.5446 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1374.1072 - binary_accuracy: 0.6636 - val_loss: 1690.4724 - val_binary_accuracy: 0.7838\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1105.6790 - binary_accuracy: 0.6611 - val_loss: 1728.4193 - val_binary_accuracy: 0.7808\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1112.8307 - binary_accuracy: 0.6653 - val_loss: 3059.9316 - val_binary_accuracy: 0.2170\n",
      "116/116 [==============================] - 0s 508us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 942us/step - loss: 3657.9954 - binary_accuracy: 0.5660 - val_loss: 409.3532 - val_binary_accuracy: 0.7771\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 804us/step - loss: 2667.4009 - binary_accuracy: 0.6646 - val_loss: 5479.9614 - val_binary_accuracy: 0.2374\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 822us/step - loss: 2039.5076 - binary_accuracy: 0.6634 - val_loss: 4057.8525 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1611.8268 - binary_accuracy: 0.6622 - val_loss: 517.0178 - val_binary_accuracy: 0.7810\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1447.6759 - binary_accuracy: 0.6642 - val_loss: 2046.6486 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 887us/step - loss: 1452.7241 - binary_accuracy: 0.6652 - val_loss: 805.7025 - val_binary_accuracy: 0.3205\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1352.0374 - binary_accuracy: 0.6631 - val_loss: 580.3150 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1268.6974 - binary_accuracy: 0.6647 - val_loss: 4134.4570 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1092.9193 - binary_accuracy: 0.6688 - val_loss: 238.2311 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 1045.4409 - binary_accuracy: 0.6671 - val_loss: 1285.7334 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 527us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 945us/step - loss: 1990.9542 - binary_accuracy: 0.6857 - val_loss: 236.3870 - val_binary_accuracy: 0.7369\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 1298.1178 - binary_accuracy: 0.6622 - val_loss: 421.3753 - val_binary_accuracy: 0.7583\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1052.5397 - binary_accuracy: 0.6662 - val_loss: 1518.1997 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1026.6790 - binary_accuracy: 0.6625 - val_loss: 57.9498 - val_binary_accuracy: 0.6597\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 810.0724 - binary_accuracy: 0.6621 - val_loss: 1369.2931 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 563.2831 - binary_accuracy: 0.6659 - val_loss: 265.2510 - val_binary_accuracy: 0.7831\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 683.8137 - binary_accuracy: 0.6688 - val_loss: 378.4528 - val_binary_accuracy: 0.7749\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 632.1165 - binary_accuracy: 0.6646 - val_loss: 185.9888 - val_binary_accuracy: 0.7834\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 549.4181 - binary_accuracy: 0.6624 - val_loss: 464.4792 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 422.0199 - binary_accuracy: 0.6672 - val_loss: 514.6692 - val_binary_accuracy: 0.3361\n",
      "116/116 [==============================] - 0s 523us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 936us/step - loss: 3565.6550 - binary_accuracy: 0.5950 - val_loss: 6569.4995 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 799us/step - loss: 3103.2524 - binary_accuracy: 0.6632 - val_loss: 275.5161 - val_binary_accuracy: 0.7425\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 965us/step - loss: 2781.4995 - binary_accuracy: 0.6670 - val_loss: 757.1332 - val_binary_accuracy: 0.2843\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2656.3320 - binary_accuracy: 0.6650 - val_loss: 2449.7048 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 2141.3687 - binary_accuracy: 0.6645 - val_loss: 2218.6995 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 2223.7925 - binary_accuracy: 0.6648 - val_loss: 3376.4819 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1928.3345 - binary_accuracy: 0.6670 - val_loss: 1634.9938 - val_binary_accuracy: 0.2685\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 817us/step - loss: 1824.7738 - binary_accuracy: 0.6663 - val_loss: 2924.3696 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 1306.7424 - binary_accuracy: 0.6661 - val_loss: 767.8666 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 1295.5516 - binary_accuracy: 0.6655 - val_loss: 1847.8356 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 504us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 937us/step - loss: 5678.1182 - binary_accuracy: 0.6844 - val_loss: 5133.2300 - val_binary_accuracy: 0.2243\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 820us/step - loss: 2459.2454 - binary_accuracy: 0.6596 - val_loss: 5372.6880 - val_binary_accuracy: 0.2316\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 1739.4249 - binary_accuracy: 0.6602 - val_loss: 3893.2695 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1790.2781 - binary_accuracy: 0.6625 - val_loss: 2811.6096 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1902.9779 - binary_accuracy: 0.6623 - val_loss: 1983.7220 - val_binary_accuracy: 0.7712\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1408.2687 - binary_accuracy: 0.6643 - val_loss: 1645.8348 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 887us/step - loss: 1483.3871 - binary_accuracy: 0.6639 - val_loss: 1646.2329 - val_binary_accuracy: 0.7807\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 1302.2329 - binary_accuracy: 0.6629 - val_loss: 1447.1548 - val_binary_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 825us/step - loss: 856.2164 - binary_accuracy: 0.6683 - val_loss: 1226.1447 - val_binary_accuracy: 0.7760\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 823us/step - loss: 888.6810 - binary_accuracy: 0.6641 - val_loss: 662.9344 - val_binary_accuracy: 0.7764\n",
      "116/116 [==============================] - 0s 498us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 961us/step - loss: 5270.4170 - binary_accuracy: 0.6889 - val_loss: 9743.0332 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 3054.3853 - binary_accuracy: 0.6618 - val_loss: 875.6498 - val_binary_accuracy: 0.3599\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3299.3657 - binary_accuracy: 0.6642 - val_loss: 1261.7916 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 819us/step - loss: 3082.2263 - binary_accuracy: 0.6681 - val_loss: 6466.9424 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 2284.7051 - binary_accuracy: 0.6666 - val_loss: 2661.6606 - val_binary_accuracy: 0.7840\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 2172.1477 - binary_accuracy: 0.6638 - val_loss: 539.1747 - val_binary_accuracy: 0.7829\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 2445.6653 - binary_accuracy: 0.6647 - val_loss: 4357.3462 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 2062.8933 - binary_accuracy: 0.6667 - val_loss: 981.9914 - val_binary_accuracy: 0.7689\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1889.4259 - binary_accuracy: 0.6656 - val_loss: 1392.1366 - val_binary_accuracy: 0.7749\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1873.5193 - binary_accuracy: 0.6693 - val_loss: 2459.6172 - val_binary_accuracy: 0.7799\n",
      "116/116 [==============================] - 0s 522us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 990us/step - loss: 4021.4109 - binary_accuracy: 0.6879 - val_loss: 4996.2329 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2790.2014 - binary_accuracy: 0.6625 - val_loss: 1007.3349 - val_binary_accuracy: 0.7825\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2315.2000 - binary_accuracy: 0.6613 - val_loss: 1131.2202 - val_binary_accuracy: 0.7636\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 822us/step - loss: 1741.3667 - binary_accuracy: 0.6642 - val_loss: 689.3123 - val_binary_accuracy: 0.2980\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 1229.4559 - binary_accuracy: 0.6664 - val_loss: 1029.8627 - val_binary_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1104.7847 - binary_accuracy: 0.6667 - val_loss: 481.2503 - val_binary_accuracy: 0.2625\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 904us/step - loss: 1353.0692 - binary_accuracy: 0.6659 - val_loss: 2247.7820 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 859.0543 - binary_accuracy: 0.6662 - val_loss: 656.3809 - val_binary_accuracy: 0.7839\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 760.8324 - binary_accuracy: 0.6642 - val_loss: 81.2720 - val_binary_accuracy: 0.7680\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 624.6406 - binary_accuracy: 0.6656 - val_loss: 903.5793 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 519us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 960us/step - loss: 4214.0898 - binary_accuracy: 0.6891 - val_loss: 13450.2578 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 802us/step - loss: 3632.2874 - binary_accuracy: 0.6616 - val_loss: 1416.8368 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 3386.7217 - binary_accuracy: 0.6614 - val_loss: 559.3065 - val_binary_accuracy: 0.7391\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 2521.2244 - binary_accuracy: 0.6651 - val_loss: 5183.4648 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 2130.6782 - binary_accuracy: 0.6639 - val_loss: 1223.6404 - val_binary_accuracy: 0.7840\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 846us/step - loss: 1744.6595 - binary_accuracy: 0.6675 - val_loss: 2204.6001 - val_binary_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 899us/step - loss: 1296.3033 - binary_accuracy: 0.6644 - val_loss: 1986.0604 - val_binary_accuracy: 0.2190\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1406.3953 - binary_accuracy: 0.6628 - val_loss: 980.5785 - val_binary_accuracy: 0.7816\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 983.1616 - binary_accuracy: 0.6634 - val_loss: 282.9164 - val_binary_accuracy: 0.7794\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 900.6046 - binary_accuracy: 0.6677 - val_loss: 77.9675 - val_binary_accuracy: 0.5423\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 946us/step - loss: 4346.0264 - binary_accuracy: 0.6346 - val_loss: 1076.4647 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 2182.5906 - binary_accuracy: 0.6632 - val_loss: 6070.6592 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 2098.9336 - binary_accuracy: 0.6630 - val_loss: 3603.9778 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1943.5734 - binary_accuracy: 0.6620 - val_loss: 950.4472 - val_binary_accuracy: 0.7666\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1456.4850 - binary_accuracy: 0.6656 - val_loss: 4779.1455 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1201.1095 - binary_accuracy: 0.6626 - val_loss: 1447.3114 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 896us/step - loss: 715.0457 - binary_accuracy: 0.6620 - val_loss: 192.8018 - val_binary_accuracy: 0.3925\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 668.1204 - binary_accuracy: 0.6658 - val_loss: 147.0098 - val_binary_accuracy: 0.7805\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 766.3458 - binary_accuracy: 0.6625 - val_loss: 907.2886 - val_binary_accuracy: 0.2211\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 589.6734 - binary_accuracy: 0.6665 - val_loss: 406.9030 - val_binary_accuracy: 0.7833\n",
      "116/116 [==============================] - 0s 513us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 961us/step - loss: 5503.5732 - binary_accuracy: 0.6885 - val_loss: 10148.4082 - val_binary_accuracy: 0.7847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 822us/step - loss: 3795.4380 - binary_accuracy: 0.6652 - val_loss: 1327.8245 - val_binary_accuracy: 0.7847\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 2732.5493 - binary_accuracy: 0.6606 - val_loss: 1418.0341 - val_binary_accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2054.0266 - binary_accuracy: 0.6655 - val_loss: 4090.9758 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 2097.3696 - binary_accuracy: 0.6641 - val_loss: 3694.3628 - val_binary_accuracy: 0.2517\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1616.7876 - binary_accuracy: 0.6663 - val_loss: 712.1768 - val_binary_accuracy: 0.3137\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 1848.4523 - binary_accuracy: 0.6670 - val_loss: 286.3642 - val_binary_accuracy: 0.7602\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1259.8086 - binary_accuracy: 0.6655 - val_loss: 53.6907 - val_binary_accuracy: 0.7559\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1158.6475 - binary_accuracy: 0.6685 - val_loss: 1454.3799 - val_binary_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 1304.0558 - binary_accuracy: 0.6625 - val_loss: 660.5148 - val_binary_accuracy: 0.7794\n",
      "116/116 [==============================] - 0s 525us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 952us/step - loss: 3586.3306 - binary_accuracy: 0.6886 - val_loss: 3372.6279 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 3202.0400 - binary_accuracy: 0.6636 - val_loss: 256.7699 - val_binary_accuracy: 0.6890\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2041.2496 - binary_accuracy: 0.6672 - val_loss: 1964.5844 - val_binary_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 867us/step - loss: 1905.6766 - binary_accuracy: 0.6602 - val_loss: 2851.2253 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1674.1327 - binary_accuracy: 0.6691 - val_loss: 1458.7152 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1385.8373 - binary_accuracy: 0.6678 - val_loss: 694.9181 - val_binary_accuracy: 0.7779\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1180.7445 - binary_accuracy: 0.6712 - val_loss: 78.7356 - val_binary_accuracy: 0.7504\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 1091.8973 - binary_accuracy: 0.6659 - val_loss: 529.5557 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1040.7925 - binary_accuracy: 0.6664 - val_loss: 607.5513 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 872.3019 - binary_accuracy: 0.6623 - val_loss: 576.1257 - val_binary_accuracy: 0.7838\n",
      "116/116 [==============================] - 0s 536us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 940us/step - loss: 3582.9551 - binary_accuracy: 0.6844 - val_loss: 1084.0944 - val_binary_accuracy: 0.7834\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 818us/step - loss: 2820.3083 - binary_accuracy: 0.6607 - val_loss: 2307.6069 - val_binary_accuracy: 0.7648\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 2770.7734 - binary_accuracy: 0.6580 - val_loss: 1064.5596 - val_binary_accuracy: 0.7699\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 828us/step - loss: 1882.1594 - binary_accuracy: 0.6624 - val_loss: 964.3688 - val_binary_accuracy: 0.3067\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1443.8015 - binary_accuracy: 0.6629 - val_loss: 589.0253 - val_binary_accuracy: 0.2246\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1341.3846 - binary_accuracy: 0.6655 - val_loss: 104.7139 - val_binary_accuracy: 0.7065\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 907us/step - loss: 1142.2542 - binary_accuracy: 0.6627 - val_loss: 506.8680 - val_binary_accuracy: 0.3752\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1044.4734 - binary_accuracy: 0.6619 - val_loss: 488.5400 - val_binary_accuracy: 0.7780\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 694.6862 - binary_accuracy: 0.6641 - val_loss: 999.2339 - val_binary_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 578.9768 - binary_accuracy: 0.6703 - val_loss: 1464.3042 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 526us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 955us/step - loss: 5157.1553 - binary_accuracy: 0.6873 - val_loss: 2492.0737 - val_binary_accuracy: 0.7633\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 811us/step - loss: 3421.0193 - binary_accuracy: 0.6622 - val_loss: 349.2556 - val_binary_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 2579.5503 - binary_accuracy: 0.6598 - val_loss: 5288.2212 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2235.9309 - binary_accuracy: 0.6635 - val_loss: 2881.2493 - val_binary_accuracy: 0.7788\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1773.9679 - binary_accuracy: 0.6593 - val_loss: 3604.0442 - val_binary_accuracy: 0.2407\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2115.5444 - binary_accuracy: 0.6590 - val_loss: 102.5511 - val_binary_accuracy: 0.5149\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 1666.5748 - binary_accuracy: 0.6652 - val_loss: 2953.6899 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1787.2152 - binary_accuracy: 0.6659 - val_loss: 3332.7544 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 1140.2698 - binary_accuracy: 0.6628 - val_loss: 1289.8090 - val_binary_accuracy: 0.7841\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1252.5385 - binary_accuracy: 0.6646 - val_loss: 822.1201 - val_binary_accuracy: 0.7692\n",
      "116/116 [==============================] - 0s 521us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 951us/step - loss: 3615.0640 - binary_accuracy: 0.6846 - val_loss: 842.2427 - val_binary_accuracy: 0.7835\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 1481.2954 - binary_accuracy: 0.6692 - val_loss: 1078.4722 - val_binary_accuracy: 0.2509\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1576.1642 - binary_accuracy: 0.6666 - val_loss: 1456.7346 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1324.7659 - binary_accuracy: 0.6633 - val_loss: 2714.8535 - val_binary_accuracy: 0.7801\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 1035.4548 - binary_accuracy: 0.6659 - val_loss: 1219.2418 - val_binary_accuracy: 0.7783\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 966.1528 - binary_accuracy: 0.6653 - val_loss: 1430.2930 - val_binary_accuracy: 0.2216\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 906us/step - loss: 914.4271 - binary_accuracy: 0.6669 - val_loss: 391.1736 - val_binary_accuracy: 0.7571\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 764.5946 - binary_accuracy: 0.6665 - val_loss: 1366.1353 - val_binary_accuracy: 0.2411\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 717.1266 - binary_accuracy: 0.6659 - val_loss: 852.0667 - val_binary_accuracy: 0.7823\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 556.8478 - binary_accuracy: 0.6681 - val_loss: 101.0789 - val_binary_accuracy: 0.2787\n",
      "116/116 [==============================] - 0s 544us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 947us/step - loss: 4950.6382 - binary_accuracy: 0.5731 - val_loss: 4490.3335 - val_binary_accuracy: 0.7716\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 2970.7546 - binary_accuracy: 0.6620 - val_loss: 7230.0161 - val_binary_accuracy: 0.2187\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2900.2292 - binary_accuracy: 0.6632 - val_loss: 1986.8687 - val_binary_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 2206.3357 - binary_accuracy: 0.6628 - val_loss: 1294.2791 - val_binary_accuracy: 0.7554\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2206.3330 - binary_accuracy: 0.6624 - val_loss: 4218.3716 - val_binary_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 2113.7766 - binary_accuracy: 0.6635 - val_loss: 1496.3329 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 916us/step - loss: 1756.9995 - binary_accuracy: 0.6624 - val_loss: 1237.0034 - val_binary_accuracy: 0.7824\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 971us/step - loss: 1508.8365 - binary_accuracy: 0.6643 - val_loss: 640.1442 - val_binary_accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 907us/step - loss: 1313.5635 - binary_accuracy: 0.6659 - val_loss: 1642.5839 - val_binary_accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 892us/step - loss: 1186.3066 - binary_accuracy: 0.6648 - val_loss: 474.1867 - val_binary_accuracy: 0.7780\n",
      "116/116 [==============================] - 0s 544us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 954us/step - loss: 4572.9058 - binary_accuracy: 0.6868 - val_loss: 2422.7844 - val_binary_accuracy: 0.7850\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 3609.5544 - binary_accuracy: 0.6587 - val_loss: 11467.3486 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 2362.1553 - binary_accuracy: 0.6632 - val_loss: 754.2909 - val_binary_accuracy: 0.7830\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 2194.0706 - binary_accuracy: 0.6645 - val_loss: 218.1341 - val_binary_accuracy: 0.7628\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 1693.9432 - binary_accuracy: 0.6627 - val_loss: 3345.9104 - val_binary_accuracy: 0.7817\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 2129.1279 - binary_accuracy: 0.6620 - val_loss: 1916.5709 - val_binary_accuracy: 0.2406\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 902us/step - loss: 1305.5566 - binary_accuracy: 0.6637 - val_loss: 2684.0073 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1226.1307 - binary_accuracy: 0.6643 - val_loss: 423.6349 - val_binary_accuracy: 0.2982\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 1144.5559 - binary_accuracy: 0.6645 - val_loss: 427.7118 - val_binary_accuracy: 0.7632\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 1266.0782 - binary_accuracy: 0.6651 - val_loss: 555.9677 - val_binary_accuracy: 0.7837\n",
      "116/116 [==============================] - 0s 520us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 987us/step - loss: 3812.8696 - binary_accuracy: 0.6856 - val_loss: 7312.6577 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4224.0522 - binary_accuracy: 0.6620 - val_loss: 7759.2837 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 2651.8455 - binary_accuracy: 0.6631 - val_loss: 583.6216 - val_binary_accuracy: 0.7707\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 2337.8633 - binary_accuracy: 0.6622 - val_loss: 4313.7539 - val_binary_accuracy: 0.7839\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 1996.4886 - binary_accuracy: 0.6633 - val_loss: 1458.6960 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 1578.7894 - binary_accuracy: 0.6663 - val_loss: 3337.3015 - val_binary_accuracy: 0.7756\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 1739.7682 - binary_accuracy: 0.6648 - val_loss: 74.8400 - val_binary_accuracy: 0.4378\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 867us/step - loss: 1300.9004 - binary_accuracy: 0.6625 - val_loss: 1893.2756 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1062.9758 - binary_accuracy: 0.6669 - val_loss: 86.9678 - val_binary_accuracy: 0.6319\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 805.7048 - binary_accuracy: 0.6667 - val_loss: 2358.6123 - val_binary_accuracy: 0.7834\n",
      "116/116 [==============================] - 0s 538us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 962us/step - loss: 3363.5557 - binary_accuracy: 0.6843 - val_loss: 1621.2217 - val_binary_accuracy: 0.7685\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 2321.3411 - binary_accuracy: 0.6612 - val_loss: 3434.1807 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 880us/step - loss: 2256.6011 - binary_accuracy: 0.6641 - val_loss: 2231.3044 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 1444.1836 - binary_accuracy: 0.6644 - val_loss: 1561.6769 - val_binary_accuracy: 0.7830\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 947us/step - loss: 1319.9508 - binary_accuracy: 0.6649 - val_loss: 404.6181 - val_binary_accuracy: 0.2670\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1064.6698 - binary_accuracy: 0.6664 - val_loss: 693.9863 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 846.1702 - binary_accuracy: 0.6671 - val_loss: 471.4121 - val_binary_accuracy: 0.7806\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 810.7556 - binary_accuracy: 0.6624 - val_loss: 349.1712 - val_binary_accuracy: 0.7730\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 727.8275 - binary_accuracy: 0.6675 - val_loss: 242.4770 - val_binary_accuracy: 0.7822\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 493.7363 - binary_accuracy: 0.6680 - val_loss: 516.3856 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 558us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 4828.0601 - binary_accuracy: 0.6952 - val_loss: 2056.0969 - val_binary_accuracy: 0.7672\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2871.1023 - binary_accuracy: 0.6618 - val_loss: 7558.9702 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3488.7302 - binary_accuracy: 0.6673 - val_loss: 5384.9116 - val_binary_accuracy: 0.2249\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 2169.3096 - binary_accuracy: 0.6660 - val_loss: 3275.3069 - val_binary_accuracy: 0.2574\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 921us/step - loss: 2165.7375 - binary_accuracy: 0.6661 - val_loss: 1224.3263 - val_binary_accuracy: 0.7800\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 1687.4500 - binary_accuracy: 0.6652 - val_loss: 4974.0674 - val_binary_accuracy: 0.2151\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 801us/step - loss: 1516.2194 - binary_accuracy: 0.6665 - val_loss: 1431.0431 - val_binary_accuracy: 0.7839\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1453.2975 - binary_accuracy: 0.6663 - val_loss: 1104.4152 - val_binary_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 803us/step - loss: 1159.1316 - binary_accuracy: 0.6663 - val_loss: 69.0267 - val_binary_accuracy: 0.7249\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 800us/step - loss: 969.4269 - binary_accuracy: 0.6670 - val_loss: 321.3159 - val_binary_accuracy: 0.7790\n",
      "116/116 [==============================] - 0s 510us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 934us/step - loss: 4913.5117 - binary_accuracy: 0.6808 - val_loss: 4930.7036 - val_binary_accuracy: 0.7839\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 793us/step - loss: 3737.0686 - binary_accuracy: 0.6644 - val_loss: 1423.1400 - val_binary_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 797us/step - loss: 3550.4260 - binary_accuracy: 0.6599 - val_loss: 1889.6776 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 816us/step - loss: 2307.7495 - binary_accuracy: 0.6640 - val_loss: 250.9513 - val_binary_accuracy: 0.7682\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1955.8254 - binary_accuracy: 0.6642 - val_loss: 1552.3486 - val_binary_accuracy: 0.7833\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 814us/step - loss: 1564.2765 - binary_accuracy: 0.6620 - val_loss: 752.6066 - val_binary_accuracy: 0.3283\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 815us/step - loss: 1331.0563 - binary_accuracy: 0.6631 - val_loss: 1502.2107 - val_binary_accuracy: 0.7829\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1347.1152 - binary_accuracy: 0.6630 - val_loss: 371.7034 - val_binary_accuracy: 0.7811\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 979us/step - loss: 1458.4004 - binary_accuracy: 0.6619 - val_loss: 111.5394 - val_binary_accuracy: 0.4543\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 1226.1527 - binary_accuracy: 0.6598 - val_loss: 1790.4591 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 550us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5396.7729 - binary_accuracy: 0.6902 - val_loss: 7429.9224 - val_binary_accuracy: 0.2595\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 2865.9358 - binary_accuracy: 0.6663 - val_loss: 212.6599 - val_binary_accuracy: 0.5261\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 2811.5833 - binary_accuracy: 0.6607 - val_loss: 752.5658 - val_binary_accuracy: 0.7834\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 878us/step - loss: 1904.9080 - binary_accuracy: 0.6685 - val_loss: 441.7488 - val_binary_accuracy: 0.2860\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 895us/step - loss: 2205.6260 - binary_accuracy: 0.6676 - val_loss: 3401.4851 - val_binary_accuracy: 0.2156\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1478.8824 - binary_accuracy: 0.6606 - val_loss: 1743.9033 - val_binary_accuracy: 0.7768\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 1461.0137 - binary_accuracy: 0.6686 - val_loss: 664.6154 - val_binary_accuracy: 0.7781\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1224.7505 - binary_accuracy: 0.6651 - val_loss: 1723.1517 - val_binary_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1078.4808 - binary_accuracy: 0.6609 - val_loss: 392.3034 - val_binary_accuracy: 0.2536\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 965us/step - loss: 1014.4417 - binary_accuracy: 0.6653 - val_loss: 206.8013 - val_binary_accuracy: 0.7405\n",
      "116/116 [==============================] - 0s 705us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 969us/step - loss: 7580.0581 - binary_accuracy: 0.6789 - val_loss: 2384.4592 - val_binary_accuracy: 0.2405\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 3539.8572 - binary_accuracy: 0.6624 - val_loss: 6030.0371 - val_binary_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 884us/step - loss: 2868.8892 - binary_accuracy: 0.6646 - val_loss: 191.1084 - val_binary_accuracy: 0.3953\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1780.0231 - binary_accuracy: 0.6595 - val_loss: 86.8058 - val_binary_accuracy: 0.7508\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 919us/step - loss: 1498.9272 - binary_accuracy: 0.6611 - val_loss: 1273.1082 - val_binary_accuracy: 0.7814\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 1461.1301 - binary_accuracy: 0.6600 - val_loss: 1208.6672 - val_binary_accuracy: 0.7833\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1167.7379 - binary_accuracy: 0.6634 - val_loss: 929.6200 - val_binary_accuracy: 0.7775\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 980.3083 - binary_accuracy: 0.6622 - val_loss: 227.8582 - val_binary_accuracy: 0.7825\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 899us/step - loss: 889.8537 - binary_accuracy: 0.6635 - val_loss: 1715.4785 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 819.8384 - binary_accuracy: 0.6638 - val_loss: 1304.7556 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 574us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 975us/step - loss: 5939.8545 - binary_accuracy: 0.6878 - val_loss: 5457.6235 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 3040.7063 - binary_accuracy: 0.6598 - val_loss: 4219.7183 - val_binary_accuracy: 0.2186\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 895us/step - loss: 2435.2065 - binary_accuracy: 0.6609 - val_loss: 3782.4456 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1804.0127 - binary_accuracy: 0.6650 - val_loss: 7822.1851 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 884us/step - loss: 1356.9391 - binary_accuracy: 0.6614 - val_loss: 506.9860 - val_binary_accuracy: 0.7618\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 1249.7213 - binary_accuracy: 0.6622 - val_loss: 878.2152 - val_binary_accuracy: 0.7536\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 1234.4009 - binary_accuracy: 0.6629 - val_loss: 673.0573 - val_binary_accuracy: 0.7522\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 1105.8474 - binary_accuracy: 0.6640 - val_loss: 172.1578 - val_binary_accuracy: 0.7783\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 1156.2292 - binary_accuracy: 0.6595 - val_loss: 374.5157 - val_binary_accuracy: 0.2659\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 882.8885 - binary_accuracy: 0.6647 - val_loss: 1307.3849 - val_binary_accuracy: 0.2424\n",
      "116/116 [==============================] - 0s 562us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 963us/step - loss: 3397.2764 - binary_accuracy: 0.5731 - val_loss: 7337.9609 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 894us/step - loss: 2842.8145 - binary_accuracy: 0.6656 - val_loss: 1094.2809 - val_binary_accuracy: 0.7784\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2166.2122 - binary_accuracy: 0.6658 - val_loss: 3005.8108 - val_binary_accuracy: 0.7776\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 2351.6921 - binary_accuracy: 0.6627 - val_loss: 1391.6990 - val_binary_accuracy: 0.7828\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 1555.2123 - binary_accuracy: 0.6652 - val_loss: 3687.2185 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 1443.8440 - binary_accuracy: 0.6640 - val_loss: 3875.1892 - val_binary_accuracy: 0.2309\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 1593.7003 - binary_accuracy: 0.6644 - val_loss: 502.8423 - val_binary_accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 1259.3140 - binary_accuracy: 0.6668 - val_loss: 621.0117 - val_binary_accuracy: 0.7718\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 949.4398 - binary_accuracy: 0.6695 - val_loss: 759.6115 - val_binary_accuracy: 0.7817\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 880us/step - loss: 1141.4409 - binary_accuracy: 0.6680 - val_loss: 537.7349 - val_binary_accuracy: 0.7727\n",
      "116/116 [==============================] - 0s 549us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 970us/step - loss: 4396.2979 - binary_accuracy: 0.6868 - val_loss: 1934.9537 - val_binary_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 895us/step - loss: 3292.6780 - binary_accuracy: 0.6624 - val_loss: 2439.8564 - val_binary_accuracy: 0.7838\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2460.0332 - binary_accuracy: 0.6629 - val_loss: 851.6385 - val_binary_accuracy: 0.2831\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2189.7769 - binary_accuracy: 0.6615 - val_loss: 922.6005 - val_binary_accuracy: 0.7811\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 1392.1903 - binary_accuracy: 0.6626 - val_loss: 270.1497 - val_binary_accuracy: 0.7483\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1348.1162 - binary_accuracy: 0.6682 - val_loss: 732.2452 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 1483.1815 - binary_accuracy: 0.6631 - val_loss: 1091.9225 - val_binary_accuracy: 0.7828\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 1184.2327 - binary_accuracy: 0.6649 - val_loss: 1688.8893 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 730.4655 - binary_accuracy: 0.6666 - val_loss: 602.4393 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 688.2133 - binary_accuracy: 0.6630 - val_loss: 1659.4794 - val_binary_accuracy: 0.7842\n",
      "116/116 [==============================] - 0s 546us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 965us/step - loss: 5907.1177 - binary_accuracy: 0.6845 - val_loss: 7107.6040 - val_binary_accuracy: 0.7823\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 3041.2468 - binary_accuracy: 0.6604 - val_loss: 698.1838 - val_binary_accuracy: 0.2491\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 2929.4133 - binary_accuracy: 0.6613 - val_loss: 2343.3735 - val_binary_accuracy: 0.7667\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 2289.4771 - binary_accuracy: 0.6627 - val_loss: 424.6935 - val_binary_accuracy: 0.7520\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 902us/step - loss: 1808.2415 - binary_accuracy: 0.6640 - val_loss: 5300.0972 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 1605.8835 - binary_accuracy: 0.6638 - val_loss: 3749.9175 - val_binary_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 1394.6704 - binary_accuracy: 0.6636 - val_loss: 2448.8552 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 992.3620 - binary_accuracy: 0.6648 - val_loss: 1934.8506 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 993.1972 - binary_accuracy: 0.6608 - val_loss: 1462.2567 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 839.3649 - binary_accuracy: 0.6646 - val_loss: 594.1800 - val_binary_accuracy: 0.7774\n",
      "116/116 [==============================] - 0s 557us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 984us/step - loss: 3478.2986 - binary_accuracy: 0.6889 - val_loss: 869.4672 - val_binary_accuracy: 0.7746\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1440.3562 - binary_accuracy: 0.6649 - val_loss: 836.3351 - val_binary_accuracy: 0.7821\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1444.2167 - binary_accuracy: 0.6638 - val_loss: 1280.7102 - val_binary_accuracy: 0.7833\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 892us/step - loss: 1254.4821 - binary_accuracy: 0.6619 - val_loss: 1416.5947 - val_binary_accuracy: 0.7846\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 945.9305 - binary_accuracy: 0.6651 - val_loss: 457.3217 - val_binary_accuracy: 0.7833\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 812.5629 - binary_accuracy: 0.6681 - val_loss: 640.4750 - val_binary_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 812.5201 - binary_accuracy: 0.6727 - val_loss: 1297.6151 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 953us/step - loss: 550.4808 - binary_accuracy: 0.6705 - val_loss: 38.4503 - val_binary_accuracy: 0.5312\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 555.4654 - binary_accuracy: 0.6710 - val_loss: 342.6239 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 884us/step - loss: 622.8533 - binary_accuracy: 0.6727 - val_loss: 16.3898 - val_binary_accuracy: 0.7467\n",
      "116/116 [==============================] - 0s 700us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3066.6719 - binary_accuracy: 0.6841 - val_loss: 561.2352 - val_binary_accuracy: 0.2830\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 2035.6693 - binary_accuracy: 0.6634 - val_loss: 1647.6104 - val_binary_accuracy: 0.2263\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 1759.1938 - binary_accuracy: 0.6640 - val_loss: 2251.2449 - val_binary_accuracy: 0.2775\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1459.2651 - binary_accuracy: 0.6630 - val_loss: 1733.1797 - val_binary_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 911us/step - loss: 1302.7841 - binary_accuracy: 0.6658 - val_loss: 661.1376 - val_binary_accuracy: 0.7698\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1605.5817 - binary_accuracy: 0.6672 - val_loss: 130.8684 - val_binary_accuracy: 0.7254\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 883.6069 - binary_accuracy: 0.6660 - val_loss: 1678.6746 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 785.1724 - binary_accuracy: 0.6682 - val_loss: 874.5305 - val_binary_accuracy: 0.7850\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 650.5889 - binary_accuracy: 0.6685 - val_loss: 988.5547 - val_binary_accuracy: 0.7841\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 669.0741 - binary_accuracy: 0.6686 - val_loss: 123.4546 - val_binary_accuracy: 0.7839\n",
      "116/116 [==============================] - 0s 532us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3507.9006 - binary_accuracy: 0.6885 - val_loss: 2679.4905 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 2495.6155 - binary_accuracy: 0.6638 - val_loss: 1390.9467 - val_binary_accuracy: 0.7691\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 2073.3342 - binary_accuracy: 0.6621 - val_loss: 3986.5708 - val_binary_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 2106.9397 - binary_accuracy: 0.6645 - val_loss: 3483.6482 - val_binary_accuracy: 0.7838\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 889us/step - loss: 1977.6683 - binary_accuracy: 0.6672 - val_loss: 510.3110 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1418.8007 - binary_accuracy: 0.6665 - val_loss: 340.7753 - val_binary_accuracy: 0.7600\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1364.9408 - binary_accuracy: 0.6703 - val_loss: 73.8049 - val_binary_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1231.3339 - binary_accuracy: 0.6710 - val_loss: 377.0309 - val_binary_accuracy: 0.7690\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1220.3590 - binary_accuracy: 0.6684 - val_loss: 194.3835 - val_binary_accuracy: 0.7819\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1151.5209 - binary_accuracy: 0.6708 - val_loss: 2283.9951 - val_binary_accuracy: 0.2204\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 959us/step - loss: 4115.4023 - binary_accuracy: 0.5663 - val_loss: 144.2439 - val_binary_accuracy: 0.7543\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 828us/step - loss: 2207.0496 - binary_accuracy: 0.6636 - val_loss: 395.7429 - val_binary_accuracy: 0.3779\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 2174.0334 - binary_accuracy: 0.6597 - val_loss: 1133.0299 - val_binary_accuracy: 0.7738\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1259.3320 - binary_accuracy: 0.6658 - val_loss: 397.9198 - val_binary_accuracy: 0.3332\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 1067.6382 - binary_accuracy: 0.6659 - val_loss: 467.9619 - val_binary_accuracy: 0.5428\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 854.2300 - binary_accuracy: 0.6626 - val_loss: 448.6726 - val_binary_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 763.3835 - binary_accuracy: 0.6656 - val_loss: 520.2005 - val_binary_accuracy: 0.7582\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 986us/step - loss: 707.7361 - binary_accuracy: 0.6655 - val_loss: 287.2610 - val_binary_accuracy: 0.7851\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 826us/step - loss: 632.6779 - binary_accuracy: 0.6667 - val_loss: 1679.4580 - val_binary_accuracy: 0.2632\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 518.3259 - binary_accuracy: 0.6679 - val_loss: 155.7374 - val_binary_accuracy: 0.6823\n",
      "116/116 [==============================] - 0s 547us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 971us/step - loss: 3804.8723 - binary_accuracy: 0.6678 - val_loss: 429.0535 - val_binary_accuracy: 0.3363\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 813us/step - loss: 2392.4807 - binary_accuracy: 0.6650 - val_loss: 9049.4746 - val_binary_accuracy: 0.7838\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 905us/step - loss: 2611.1294 - binary_accuracy: 0.6594 - val_loss: 1186.9205 - val_binary_accuracy: 0.2787\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 2092.9727 - binary_accuracy: 0.6643 - val_loss: 3385.7170 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 1352.0635 - binary_accuracy: 0.6672 - val_loss: 538.9404 - val_binary_accuracy: 0.7829\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1969.3208 - binary_accuracy: 0.6679 - val_loss: 2219.1150 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1430.3149 - binary_accuracy: 0.6689 - val_loss: 2126.9424 - val_binary_accuracy: 0.2507\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 1389.9739 - binary_accuracy: 0.6688 - val_loss: 126.8938 - val_binary_accuracy: 0.7700\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 887us/step - loss: 1198.5479 - binary_accuracy: 0.6673 - val_loss: 1236.9895 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 872.4921 - binary_accuracy: 0.6702 - val_loss: 1845.0525 - val_binary_accuracy: 0.7837\n",
      "116/116 [==============================] - 0s 532us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 957us/step - loss: 4016.5515 - binary_accuracy: 0.6843 - val_loss: 4205.3442 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 809us/step - loss: 3112.6375 - binary_accuracy: 0.6662 - val_loss: 1542.6671 - val_binary_accuracy: 0.2418\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 921us/step - loss: 2659.1104 - binary_accuracy: 0.6655 - val_loss: 888.2014 - val_binary_accuracy: 0.7852\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 2377.9312 - binary_accuracy: 0.6666 - val_loss: 3155.0303 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2122.6938 - binary_accuracy: 0.6646 - val_loss: 5346.2095 - val_binary_accuracy: 0.2297\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 2103.6697 - binary_accuracy: 0.6650 - val_loss: 607.1629 - val_binary_accuracy: 0.3210\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 1863.2632 - binary_accuracy: 0.6634 - val_loss: 2959.8994 - val_binary_accuracy: 0.7851\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1799.0233 - binary_accuracy: 0.6682 - val_loss: 993.9034 - val_binary_accuracy: 0.2599\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1396.8278 - binary_accuracy: 0.6695 - val_loss: 1336.1927 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 913us/step - loss: 1485.4723 - binary_accuracy: 0.6653 - val_loss: 1114.2251 - val_binary_accuracy: 0.2377\n",
      "116/116 [==============================] - 0s 551us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4149.4360 - binary_accuracy: 0.5671 - val_loss: 500.1907 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 921us/step - loss: 1958.6244 - binary_accuracy: 0.6625 - val_loss: 1785.2854 - val_binary_accuracy: 0.2386\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2444.0093 - binary_accuracy: 0.6584 - val_loss: 4330.1230 - val_binary_accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1776.3774 - binary_accuracy: 0.6659 - val_loss: 469.1815 - val_binary_accuracy: 0.7841\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1204.0840 - binary_accuracy: 0.6647 - val_loss: 4205.2598 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1537.9604 - binary_accuracy: 0.6640 - val_loss: 366.9871 - val_binary_accuracy: 0.7653\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 1121.7617 - binary_accuracy: 0.6623 - val_loss: 4423.2993 - val_binary_accuracy: 0.2177\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 1141.7019 - binary_accuracy: 0.6659 - val_loss: 605.8392 - val_binary_accuracy: 0.7782\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 887.3063 - binary_accuracy: 0.6684 - val_loss: 802.9460 - val_binary_accuracy: 0.2259\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 713.0283 - binary_accuracy: 0.6685 - val_loss: 38.9962 - val_binary_accuracy: 0.6069\n",
      "116/116 [==============================] - 0s 518us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 964us/step - loss: 4482.8242 - binary_accuracy: 0.6510 - val_loss: 1743.1571 - val_binary_accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2322.4192 - binary_accuracy: 0.6672 - val_loss: 4878.8228 - val_binary_accuracy: 0.2286\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2111.2896 - binary_accuracy: 0.6623 - val_loss: 872.8076 - val_binary_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 955us/step - loss: 1632.1952 - binary_accuracy: 0.6636 - val_loss: 707.5086 - val_binary_accuracy: 0.7834\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 1865.8193 - binary_accuracy: 0.6610 - val_loss: 3440.3103 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1359.1559 - binary_accuracy: 0.6692 - val_loss: 1796.3143 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1149.4569 - binary_accuracy: 0.6645 - val_loss: 281.9265 - val_binary_accuracy: 0.7165\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 883.5610 - binary_accuracy: 0.6647 - val_loss: 2009.4957 - val_binary_accuracy: 0.7842\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 759.9599 - binary_accuracy: 0.6719 - val_loss: 681.5704 - val_binary_accuracy: 0.7840\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 759.9053 - binary_accuracy: 0.6678 - val_loss: 364.4837 - val_binary_accuracy: 0.7850\n",
      "116/116 [==============================] - 0s 521us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 994us/step - loss: 2520.1086 - binary_accuracy: 0.6912 - val_loss: 854.4687 - val_binary_accuracy: 0.7754\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1517.5437 - binary_accuracy: 0.6630 - val_loss: 927.9946 - val_binary_accuracy: 0.2564\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 845us/step - loss: 1257.6360 - binary_accuracy: 0.6626 - val_loss: 956.8259 - val_binary_accuracy: 0.7833\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 838.0192 - binary_accuracy: 0.6643 - val_loss: 54.8661 - val_binary_accuracy: 0.7077\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 773.6160 - binary_accuracy: 0.6678 - val_loss: 115.6998 - val_binary_accuracy: 0.7646\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 552.2363 - binary_accuracy: 0.6654 - val_loss: 252.4984 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 216.9527 - binary_accuracy: 0.6657 - val_loss: 81.1580 - val_binary_accuracy: 0.7703\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 91.1000 - binary_accuracy: 0.6661 - val_loss: 11.2571 - val_binary_accuracy: 0.7737\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 42.4939 - binary_accuracy: 0.6669 - val_loss: 13.2100 - val_binary_accuracy: 0.3061\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 13.1435 - binary_accuracy: 0.7090 - val_loss: 0.5833 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 525us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 981us/step - loss: 7994.2856 - binary_accuracy: 0.6912 - val_loss: 1228.3549 - val_binary_accuracy: 0.7798\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2146.5073 - binary_accuracy: 0.6676 - val_loss: 324.9625 - val_binary_accuracy: 0.7844\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1419.1907 - binary_accuracy: 0.6635 - val_loss: 4339.0537 - val_binary_accuracy: 0.2276\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 851us/step - loss: 1474.6672 - binary_accuracy: 0.6649 - val_loss: 1286.6359 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1404.6272 - binary_accuracy: 0.6690 - val_loss: 1364.9236 - val_binary_accuracy: 0.7850\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1333.4343 - binary_accuracy: 0.6682 - val_loss: 1696.2762 - val_binary_accuracy: 0.2671\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1422.4160 - binary_accuracy: 0.6695 - val_loss: 1586.2899 - val_binary_accuracy: 0.2837\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1103.8734 - binary_accuracy: 0.6702 - val_loss: 1892.5768 - val_binary_accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 948.1337 - binary_accuracy: 0.6710 - val_loss: 1653.2465 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 882.7112 - binary_accuracy: 0.6682 - val_loss: 1195.4412 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 531us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 963us/step - loss: 3553.4563 - binary_accuracy: 0.6925 - val_loss: 1850.0615 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 846us/step - loss: 2959.6692 - binary_accuracy: 0.6641 - val_loss: 4534.5381 - val_binary_accuracy: 0.7840\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 3104.8713 - binary_accuracy: 0.6614 - val_loss: 4208.0073 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 1769.6449 - binary_accuracy: 0.6621 - val_loss: 5318.7837 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1885.6674 - binary_accuracy: 0.6668 - val_loss: 876.9256 - val_binary_accuracy: 0.2507\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 2022.1708 - binary_accuracy: 0.6650 - val_loss: 5040.6162 - val_binary_accuracy: 0.2451\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1823.1088 - binary_accuracy: 0.6648 - val_loss: 1826.8003 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 1964.6249 - binary_accuracy: 0.6623 - val_loss: 2235.2471 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1214.8507 - binary_accuracy: 0.6636 - val_loss: 157.7408 - val_binary_accuracy: 0.7765\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 993.6812 - binary_accuracy: 0.6681 - val_loss: 37.1136 - val_binary_accuracy: 0.6566\n",
      "116/116 [==============================] - 0s 518us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4591.4663 - binary_accuracy: 0.6618 - val_loss: 2261.4199 - val_binary_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 3023.7188 - binary_accuracy: 0.6627 - val_loss: 3060.0159 - val_binary_accuracy: 0.7360\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 3257.3186 - binary_accuracy: 0.6665 - val_loss: 3402.0098 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2137.7234 - binary_accuracy: 0.6659 - val_loss: 1851.5784 - val_binary_accuracy: 0.7797\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 2219.6860 - binary_accuracy: 0.6635 - val_loss: 683.6558 - val_binary_accuracy: 0.7839\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1997.5748 - binary_accuracy: 0.6644 - val_loss: 343.1574 - val_binary_accuracy: 0.3559\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1284.9652 - binary_accuracy: 0.6655 - val_loss: 603.0527 - val_binary_accuracy: 0.4336\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 959.2767 - binary_accuracy: 0.6676 - val_loss: 710.5707 - val_binary_accuracy: 0.7840\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 828us/step - loss: 1213.3887 - binary_accuracy: 0.6673 - val_loss: 690.1314 - val_binary_accuracy: 0.7747\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 829us/step - loss: 844.2310 - binary_accuracy: 0.6723 - val_loss: 1000.9265 - val_binary_accuracy: 0.2225\n",
      "116/116 [==============================] - 0s 523us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 959us/step - loss: 5726.9951 - binary_accuracy: 0.5687 - val_loss: 13710.4209 - val_binary_accuracy: 0.2164\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 3676.7898 - binary_accuracy: 0.6631 - val_loss: 952.1027 - val_binary_accuracy: 0.7687\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 3783.9453 - binary_accuracy: 0.6649 - val_loss: 2923.6970 - val_binary_accuracy: 0.7786\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 847us/step - loss: 3634.3000 - binary_accuracy: 0.6641 - val_loss: 3350.2390 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2485.8420 - binary_accuracy: 0.6675 - val_loss: 287.1202 - val_binary_accuracy: 0.4939\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2878.9084 - binary_accuracy: 0.6682 - val_loss: 1099.2076 - val_binary_accuracy: 0.7808\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2510.5039 - binary_accuracy: 0.6632 - val_loss: 2693.2502 - val_binary_accuracy: 0.3385\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1795.8705 - binary_accuracy: 0.6657 - val_loss: 1323.5270 - val_binary_accuracy: 0.7825\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1247.1322 - binary_accuracy: 0.6708 - val_loss: 2401.8289 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1873.2180 - binary_accuracy: 0.6671 - val_loss: 688.7227 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 521us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 4536.8394 - binary_accuracy: 0.6851 - val_loss: 2539.9192 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4438.1377 - binary_accuracy: 0.6657 - val_loss: 297.5865 - val_binary_accuracy: 0.7220\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 3601.1985 - binary_accuracy: 0.6663 - val_loss: 4196.7593 - val_binary_accuracy: 0.7835\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 2946.2195 - binary_accuracy: 0.6633 - val_loss: 233.0004 - val_binary_accuracy: 0.4310\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 2726.4966 - binary_accuracy: 0.6610 - val_loss: 6056.4146 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 2446.8118 - binary_accuracy: 0.6626 - val_loss: 2475.7590 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 1987.3168 - binary_accuracy: 0.6616 - val_loss: 866.3304 - val_binary_accuracy: 0.7631\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1863.2916 - binary_accuracy: 0.6670 - val_loss: 222.3899 - val_binary_accuracy: 0.7710\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 833us/step - loss: 1945.0887 - binary_accuracy: 0.6682 - val_loss: 880.8141 - val_binary_accuracy: 0.2607\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1461.9391 - binary_accuracy: 0.6698 - val_loss: 323.0754 - val_binary_accuracy: 0.2680\n",
      "116/116 [==============================] - 0s 536us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 950us/step - loss: 2418.0046 - binary_accuracy: 0.5785 - val_loss: 1969.5100 - val_binary_accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1410.5027 - binary_accuracy: 0.6659 - val_loss: 608.6949 - val_binary_accuracy: 0.7772\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1190.4427 - binary_accuracy: 0.6639 - val_loss: 275.5132 - val_binary_accuracy: 0.2545\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1239.2570 - binary_accuracy: 0.6634 - val_loss: 1332.9954 - val_binary_accuracy: 0.7835\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 984.1345 - binary_accuracy: 0.6654 - val_loss: 857.9579 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 682.6414 - binary_accuracy: 0.6672 - val_loss: 258.5663 - val_binary_accuracy: 0.7852\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 723.8349 - binary_accuracy: 0.6712 - val_loss: 689.2009 - val_binary_accuracy: 0.2716\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 423.8852 - binary_accuracy: 0.6689 - val_loss: 446.7588 - val_binary_accuracy: 0.7838\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 461.4832 - binary_accuracy: 0.6676 - val_loss: 25.9097 - val_binary_accuracy: 0.7061\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 849us/step - loss: 395.4259 - binary_accuracy: 0.6715 - val_loss: 33.7823 - val_binary_accuracy: 0.4322\n",
      "116/116 [==============================] - 0s 513us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2898.3032 - binary_accuracy: 0.6077 - val_loss: 3382.1677 - val_binary_accuracy: 0.7798\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 1900.5842 - binary_accuracy: 0.6589 - val_loss: 534.5273 - val_binary_accuracy: 0.7834\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1939.2798 - binary_accuracy: 0.6667 - val_loss: 579.5861 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 1964.2751 - binary_accuracy: 0.6673 - val_loss: 3525.9119 - val_binary_accuracy: 0.2380\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1783.8223 - binary_accuracy: 0.6655 - val_loss: 1150.7758 - val_binary_accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 1366.3622 - binary_accuracy: 0.6657 - val_loss: 846.9093 - val_binary_accuracy: 0.2767\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 1365.5270 - binary_accuracy: 0.6675 - val_loss: 802.1290 - val_binary_accuracy: 0.7758\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 1126.8204 - binary_accuracy: 0.6708 - val_loss: 2917.5320 - val_binary_accuracy: 0.2268\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 1028.9510 - binary_accuracy: 0.6657 - val_loss: 2209.3813 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1028.2842 - binary_accuracy: 0.6702 - val_loss: 1135.2703 - val_binary_accuracy: 0.7850\n",
      "116/116 [==============================] - 0s 529us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 954us/step - loss: 4595.7637 - binary_accuracy: 0.6915 - val_loss: 3796.7246 - val_binary_accuracy: 0.2726\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 2824.6372 - binary_accuracy: 0.6573 - val_loss: 4723.1167 - val_binary_accuracy: 0.7729\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 3117.0547 - binary_accuracy: 0.6613 - val_loss: 821.3958 - val_binary_accuracy: 0.7823\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 2477.0959 - binary_accuracy: 0.6638 - val_loss: 2299.4160 - val_binary_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 1732.4851 - binary_accuracy: 0.6661 - val_loss: 936.3342 - val_binary_accuracy: 0.2752\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1733.8988 - binary_accuracy: 0.6623 - val_loss: 1201.8510 - val_binary_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1584.1536 - binary_accuracy: 0.6661 - val_loss: 187.7263 - val_binary_accuracy: 0.7855\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1427.1218 - binary_accuracy: 0.6681 - val_loss: 712.5917 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 855us/step - loss: 1389.2261 - binary_accuracy: 0.6630 - val_loss: 919.4930 - val_binary_accuracy: 0.2653\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1328.6118 - binary_accuracy: 0.6724 - val_loss: 1050.0405 - val_binary_accuracy: 0.7847\n",
      "116/116 [==============================] - 0s 527us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1829.8958 - binary_accuracy: 0.6896 - val_loss: 1330.7031 - val_binary_accuracy: 0.7748\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 895us/step - loss: 1397.9553 - binary_accuracy: 0.6652 - val_loss: 1418.9531 - val_binary_accuracy: 0.7813\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1426.9506 - binary_accuracy: 0.6616 - val_loss: 876.9719 - val_binary_accuracy: 0.7781\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 1152.3698 - binary_accuracy: 0.6685 - val_loss: 615.8310 - val_binary_accuracy: 0.7807\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 991.7448 - binary_accuracy: 0.6680 - val_loss: 382.5590 - val_binary_accuracy: 0.2791\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 939.8685 - binary_accuracy: 0.6627 - val_loss: 593.6329 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 850us/step - loss: 865.9019 - binary_accuracy: 0.6698 - val_loss: 457.6824 - val_binary_accuracy: 0.7813\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 697.7891 - binary_accuracy: 0.6663 - val_loss: 534.3661 - val_binary_accuracy: 0.7824\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 631.6632 - binary_accuracy: 0.6728 - val_loss: 483.6614 - val_binary_accuracy: 0.7721\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 770.8829 - binary_accuracy: 0.6720 - val_loss: 377.2015 - val_binary_accuracy: 0.7834\n",
      "116/116 [==============================] - 0s 538us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 979us/step - loss: 8279.9648 - binary_accuracy: 0.6826 - val_loss: 156.3484 - val_binary_accuracy: 0.6630\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2395.0295 - binary_accuracy: 0.6651 - val_loss: 858.7596 - val_binary_accuracy: 0.7758\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 2183.8616 - binary_accuracy: 0.6623 - val_loss: 4132.3994 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 1961.0714 - binary_accuracy: 0.6643 - val_loss: 2791.9062 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1374.6047 - binary_accuracy: 0.6681 - val_loss: 662.4765 - val_binary_accuracy: 0.7666\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1441.0103 - binary_accuracy: 0.6681 - val_loss: 312.3073 - val_binary_accuracy: 0.3094\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 843us/step - loss: 1158.5007 - binary_accuracy: 0.6706 - val_loss: 284.1059 - val_binary_accuracy: 0.7833\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 994.0818 - binary_accuracy: 0.6724 - val_loss: 2364.6255 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1233.5366 - binary_accuracy: 0.6673 - val_loss: 1783.9995 - val_binary_accuracy: 0.7759\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1046.3350 - binary_accuracy: 0.6679 - val_loss: 1647.7283 - val_binary_accuracy: 0.2185\n",
      "116/116 [==============================] - 0s 529us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 958us/step - loss: 2547.6370 - binary_accuracy: 0.5664 - val_loss: 315.4687 - val_binary_accuracy: 0.7485\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 2187.8967 - binary_accuracy: 0.6660 - val_loss: 2582.0996 - val_binary_accuracy: 0.2169\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 1685.3600 - binary_accuracy: 0.6661 - val_loss: 798.0726 - val_binary_accuracy: 0.2329\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 852us/step - loss: 1414.7875 - binary_accuracy: 0.6643 - val_loss: 126.4163 - val_binary_accuracy: 0.5924\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 834us/step - loss: 1178.3353 - binary_accuracy: 0.6670 - val_loss: 1617.7285 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1036.9270 - binary_accuracy: 0.6686 - val_loss: 733.8918 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 813.1612 - binary_accuracy: 0.6674 - val_loss: 1007.3458 - val_binary_accuracy: 0.7851\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 831us/step - loss: 880.3765 - binary_accuracy: 0.6690 - val_loss: 864.6126 - val_binary_accuracy: 0.2226\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 742.1234 - binary_accuracy: 0.6691 - val_loss: 1222.2606 - val_binary_accuracy: 0.2468\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 625.5921 - binary_accuracy: 0.6699 - val_loss: 1264.9286 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 540us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 986us/step - loss: 4096.4976 - binary_accuracy: 0.6881 - val_loss: 217.7171 - val_binary_accuracy: 0.4715\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 904us/step - loss: 3228.9158 - binary_accuracy: 0.6630 - val_loss: 693.7609 - val_binary_accuracy: 0.3671\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2399.3892 - binary_accuracy: 0.6652 - val_loss: 2427.7573 - val_binary_accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 2107.9229 - binary_accuracy: 0.6654 - val_loss: 2370.9192 - val_binary_accuracy: 0.7850\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 844us/step - loss: 1824.8944 - binary_accuracy: 0.6666 - val_loss: 969.3723 - val_binary_accuracy: 0.7825\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1428.1047 - binary_accuracy: 0.6669 - val_loss: 1603.5906 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1497.7964 - binary_accuracy: 0.6658 - val_loss: 1836.1750 - val_binary_accuracy: 0.2315\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 853us/step - loss: 1240.6954 - binary_accuracy: 0.6650 - val_loss: 2820.9128 - val_binary_accuracy: 0.7842\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 979.4590 - binary_accuracy: 0.6678 - val_loss: 393.9648 - val_binary_accuracy: 0.7849\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 737.4085 - binary_accuracy: 0.6711 - val_loss: 745.3978 - val_binary_accuracy: 0.2666\n",
      "116/116 [==============================] - 0s 531us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 970us/step - loss: 4658.1348 - binary_accuracy: 0.5743 - val_loss: 4351.0669 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 2800.0891 - binary_accuracy: 0.6622 - val_loss: 549.0687 - val_binary_accuracy: 0.7373\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 1881.9320 - binary_accuracy: 0.6637 - val_loss: 1215.2902 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1977.1595 - binary_accuracy: 0.6659 - val_loss: 172.4648 - val_binary_accuracy: 0.6727\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 1820.6494 - binary_accuracy: 0.6660 - val_loss: 873.4568 - val_binary_accuracy: 0.2353\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1408.3077 - binary_accuracy: 0.6691 - val_loss: 384.7026 - val_binary_accuracy: 0.7840\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1545.7354 - binary_accuracy: 0.6630 - val_loss: 169.6601 - val_binary_accuracy: 0.7710\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 1605.3014 - binary_accuracy: 0.6686 - val_loss: 985.6558 - val_binary_accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 900us/step - loss: 1208.7017 - binary_accuracy: 0.6688 - val_loss: 2723.6021 - val_binary_accuracy: 0.7847\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 983.8547 - binary_accuracy: 0.6696 - val_loss: 462.0137 - val_binary_accuracy: 0.7755\n",
      "116/116 [==============================] - 0s 549us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4111.6270 - binary_accuracy: 0.6855 - val_loss: 4393.8125 - val_binary_accuracy: 0.7834\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 2660.0103 - binary_accuracy: 0.6673 - val_loss: 941.8607 - val_binary_accuracy: 0.7660\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 2187.3525 - binary_accuracy: 0.6624 - val_loss: 2259.2529 - val_binary_accuracy: 0.2173\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 2371.4170 - binary_accuracy: 0.6663 - val_loss: 905.3558 - val_binary_accuracy: 0.7528\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1995.7983 - binary_accuracy: 0.6666 - val_loss: 3661.9897 - val_binary_accuracy: 0.7850\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 1641.1724 - binary_accuracy: 0.6661 - val_loss: 1584.2461 - val_binary_accuracy: 0.7740\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1276.7338 - binary_accuracy: 0.6660 - val_loss: 2871.1802 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1203.3937 - binary_accuracy: 0.6707 - val_loss: 886.6606 - val_binary_accuracy: 0.2253\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 851.4146 - binary_accuracy: 0.6684 - val_loss: 67.3214 - val_binary_accuracy: 0.7541\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 876.0789 - binary_accuracy: 0.6718 - val_loss: 962.9752 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 528us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 983us/step - loss: 4701.9067 - binary_accuracy: 0.6870 - val_loss: 16455.0000 - val_binary_accuracy: 0.2270\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 3889.7322 - binary_accuracy: 0.6639 - val_loss: 2446.2695 - val_binary_accuracy: 0.7814\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 3215.3269 - binary_accuracy: 0.6642 - val_loss: 1662.8152 - val_binary_accuracy: 0.7781\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 2067.4185 - binary_accuracy: 0.6658 - val_loss: 433.2631 - val_binary_accuracy: 0.7663\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 1987.0181 - binary_accuracy: 0.6678 - val_loss: 737.1638 - val_binary_accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 899us/step - loss: 1587.2998 - binary_accuracy: 0.6639 - val_loss: 4334.0864 - val_binary_accuracy: 0.7839\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 1260.5114 - binary_accuracy: 0.6684 - val_loss: 866.9388 - val_binary_accuracy: 0.7816\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 1093.0461 - binary_accuracy: 0.6669 - val_loss: 872.8744 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1028.7411 - binary_accuracy: 0.6664 - val_loss: 3147.7161 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1094.4355 - binary_accuracy: 0.6650 - val_loss: 784.7401 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 533us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3981.0166 - binary_accuracy: 0.6956 - val_loss: 5347.4917 - val_binary_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 2842.8501 - binary_accuracy: 0.6613 - val_loss: 1477.0249 - val_binary_accuracy: 0.7758\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 2251.5405 - binary_accuracy: 0.6664 - val_loss: 4969.8921 - val_binary_accuracy: 0.2365\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1953.3263 - binary_accuracy: 0.6635 - val_loss: 4698.3477 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1503.9556 - binary_accuracy: 0.6655 - val_loss: 1067.5123 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 1544.6654 - binary_accuracy: 0.6643 - val_loss: 4768.1665 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 890us/step - loss: 1136.7378 - binary_accuracy: 0.6659 - val_loss: 61.2318 - val_binary_accuracy: 0.6668\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 913us/step - loss: 881.1704 - binary_accuracy: 0.6698 - val_loss: 251.4625 - val_binary_accuracy: 0.5224\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 981.1012 - binary_accuracy: 0.6681 - val_loss: 528.3916 - val_binary_accuracy: 0.2353\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 764.2842 - binary_accuracy: 0.6683 - val_loss: 1000.3262 - val_binary_accuracy: 0.7839\n",
      "116/116 [==============================] - 0s 542us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 957us/step - loss: 4112.7764 - binary_accuracy: 0.6865 - val_loss: 5622.0391 - val_binary_accuracy: 0.2354\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 3859.2542 - binary_accuracy: 0.6607 - val_loss: 2864.5493 - val_binary_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2152.2114 - binary_accuracy: 0.6632 - val_loss: 2546.6094 - val_binary_accuracy: 0.2439\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 1937.1219 - binary_accuracy: 0.6631 - val_loss: 3315.3564 - val_binary_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 839us/step - loss: 1413.6891 - binary_accuracy: 0.6677 - val_loss: 3521.1169 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1507.0295 - binary_accuracy: 0.6670 - val_loss: 1478.3983 - val_binary_accuracy: 0.7798\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1213.9253 - binary_accuracy: 0.6696 - val_loss: 2695.5530 - val_binary_accuracy: 0.2408\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 911us/step - loss: 1142.2144 - binary_accuracy: 0.6674 - val_loss: 3234.8193 - val_binary_accuracy: 0.2156\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 975us/step - loss: 974.4059 - binary_accuracy: 0.6648 - val_loss: 274.8315 - val_binary_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 989us/step - loss: 850.0956 - binary_accuracy: 0.6683 - val_loss: 815.4310 - val_binary_accuracy: 0.7842\n",
      "116/116 [==============================] - 0s 602us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 963us/step - loss: 3953.5969 - binary_accuracy: 0.6877 - val_loss: 3080.2917 - val_binary_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 832us/step - loss: 2057.2336 - binary_accuracy: 0.6645 - val_loss: 420.4200 - val_binary_accuracy: 0.7839\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1859.1757 - binary_accuracy: 0.6623 - val_loss: 2358.5479 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 897us/step - loss: 1733.3949 - binary_accuracy: 0.6639 - val_loss: 3852.3958 - val_binary_accuracy: 0.7841\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 1584.0175 - binary_accuracy: 0.6615 - val_loss: 1504.8584 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 1260.7148 - binary_accuracy: 0.6615 - val_loss: 425.5388 - val_binary_accuracy: 0.7733\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 913us/step - loss: 1377.1835 - binary_accuracy: 0.6634 - val_loss: 740.4787 - val_binary_accuracy: 0.7693\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 891us/step - loss: 1711.6281 - binary_accuracy: 0.6650 - val_loss: 2045.5337 - val_binary_accuracy: 0.7850\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1350.8505 - binary_accuracy: 0.6675 - val_loss: 37.7228 - val_binary_accuracy: 0.7771\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 916us/step - loss: 1049.7505 - binary_accuracy: 0.6633 - val_loss: 408.4520 - val_binary_accuracy: 0.7840\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4263.5620 - binary_accuracy: 0.6908 - val_loss: 1987.8676 - val_binary_accuracy: 0.7805\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1850.5770 - binary_accuracy: 0.6618 - val_loss: 1228.7258 - val_binary_accuracy: 0.2657\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1657.3252 - binary_accuracy: 0.6664 - val_loss: 412.7958 - val_binary_accuracy: 0.2928\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1292.4523 - binary_accuracy: 0.6634 - val_loss: 2519.7683 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 1340.0688 - binary_accuracy: 0.6647 - val_loss: 641.3812 - val_binary_accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 943.5444 - binary_accuracy: 0.6642 - val_loss: 402.7769 - val_binary_accuracy: 0.3463\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 700.7635 - binary_accuracy: 0.6620 - val_loss: 964.2609 - val_binary_accuracy: 0.7848\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 774.0586 - binary_accuracy: 0.6663 - val_loss: 31.3730 - val_binary_accuracy: 0.6893\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 896us/step - loss: 492.9301 - binary_accuracy: 0.6690 - val_loss: 737.7212 - val_binary_accuracy: 0.2481\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 909us/step - loss: 669.6609 - binary_accuracy: 0.6666 - val_loss: 1905.7402 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 537us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 947us/step - loss: 4624.8564 - binary_accuracy: 0.6884 - val_loss: 10575.7510 - val_binary_accuracy: 0.2232\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 827us/step - loss: 4393.7246 - binary_accuracy: 0.6640 - val_loss: 3278.9390 - val_binary_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 3974.7688 - binary_accuracy: 0.6651 - val_loss: 6622.4819 - val_binary_accuracy: 0.2218\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 3120.7988 - binary_accuracy: 0.6604 - val_loss: 1575.3574 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 2172.8364 - binary_accuracy: 0.6685 - val_loss: 98.5962 - val_binary_accuracy: 0.5453\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1474.6692 - binary_accuracy: 0.6645 - val_loss: 140.6908 - val_binary_accuracy: 0.5348\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1545.4366 - binary_accuracy: 0.6672 - val_loss: 1175.6393 - val_binary_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 841us/step - loss: 1472.3317 - binary_accuracy: 0.6681 - val_loss: 2569.4690 - val_binary_accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 882us/step - loss: 1239.4580 - binary_accuracy: 0.6641 - val_loss: 1089.8839 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 899us/step - loss: 1012.7805 - binary_accuracy: 0.6696 - val_loss: 77.5131 - val_binary_accuracy: 0.7828\n",
      "116/116 [==============================] - 0s 533us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 947us/step - loss: 3793.4302 - binary_accuracy: 0.6864 - val_loss: 771.2409 - val_binary_accuracy: 0.7713\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 836us/step - loss: 3700.8127 - binary_accuracy: 0.6650 - val_loss: 4332.0571 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 2161.3965 - binary_accuracy: 0.6591 - val_loss: 1691.7977 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2343.6582 - binary_accuracy: 0.6692 - val_loss: 2701.9656 - val_binary_accuracy: 0.7850\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1762.5427 - binary_accuracy: 0.6675 - val_loss: 3607.0833 - val_binary_accuracy: 0.2224\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1293.0481 - binary_accuracy: 0.6694 - val_loss: 2649.6482 - val_binary_accuracy: 0.2334\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 867us/step - loss: 1646.8978 - binary_accuracy: 0.6679 - val_loss: 2257.9260 - val_binary_accuracy: 0.2438\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1361.5850 - binary_accuracy: 0.6697 - val_loss: 2242.1257 - val_binary_accuracy: 0.7842\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 1233.8094 - binary_accuracy: 0.6639 - val_loss: 380.2873 - val_binary_accuracy: 0.7779\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 767.8218 - binary_accuracy: 0.6709 - val_loss: 1255.4761 - val_binary_accuracy: 0.7847\n",
      "116/116 [==============================] - 0s 526us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 960us/step - loss: 5409.8296 - binary_accuracy: 0.6883 - val_loss: 591.4620 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 840us/step - loss: 3903.8323 - binary_accuracy: 0.6595 - val_loss: 2239.5405 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 2888.2510 - binary_accuracy: 0.6615 - val_loss: 280.7729 - val_binary_accuracy: 0.3078\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 2556.6926 - binary_accuracy: 0.6648 - val_loss: 841.9821 - val_binary_accuracy: 0.7714\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 876us/step - loss: 1643.9866 - binary_accuracy: 0.6669 - val_loss: 1104.4104 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1480.1272 - binary_accuracy: 0.6673 - val_loss: 3792.6123 - val_binary_accuracy: 0.7831\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1804.8352 - binary_accuracy: 0.6625 - val_loss: 811.0291 - val_binary_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1175.4994 - binary_accuracy: 0.6676 - val_loss: 1057.1045 - val_binary_accuracy: 0.7717\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 940.0523 - binary_accuracy: 0.6685 - val_loss: 68.6493 - val_binary_accuracy: 0.7529\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 915us/step - loss: 1016.5256 - binary_accuracy: 0.6674 - val_loss: 1366.8429 - val_binary_accuracy: 0.7843\n",
      "116/116 [==============================] - 0s 544us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 958us/step - loss: 6843.7451 - binary_accuracy: 0.6847 - val_loss: 92.9377 - val_binary_accuracy: 0.7542\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 2672.6633 - binary_accuracy: 0.6611 - val_loss: 3523.2529 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2091.4126 - binary_accuracy: 0.6669 - val_loss: 146.6978 - val_binary_accuracy: 0.7507\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 2125.7493 - binary_accuracy: 0.6657 - val_loss: 969.7318 - val_binary_accuracy: 0.2516\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 2027.0551 - binary_accuracy: 0.6652 - val_loss: 1219.5405 - val_binary_accuracy: 0.7731\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 1344.3534 - binary_accuracy: 0.6642 - val_loss: 2309.9861 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1411.2616 - binary_accuracy: 0.6653 - val_loss: 1295.9550 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 1331.7950 - binary_accuracy: 0.6705 - val_loss: 4623.5952 - val_binary_accuracy: 0.2221\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 903us/step - loss: 1430.6837 - binary_accuracy: 0.6699 - val_loss: 144.3849 - val_binary_accuracy: 0.3954\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 859us/step - loss: 1091.5000 - binary_accuracy: 0.6700 - val_loss: 986.1489 - val_binary_accuracy: 0.7672\n",
      "116/116 [==============================] - 0s 530us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 965us/step - loss: 4441.1089 - binary_accuracy: 0.6854 - val_loss: 1433.0555 - val_binary_accuracy: 0.7694\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 835us/step - loss: 2688.6633 - binary_accuracy: 0.6645 - val_loss: 161.3978 - val_binary_accuracy: 0.5756\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 877us/step - loss: 2518.9973 - binary_accuracy: 0.6636 - val_loss: 2023.0612 - val_binary_accuracy: 0.7693\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 2033.3779 - binary_accuracy: 0.6624 - val_loss: 2407.2209 - val_binary_accuracy: 0.2318\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1365.9507 - binary_accuracy: 0.6688 - val_loss: 1028.0330 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 888us/step - loss: 1594.6616 - binary_accuracy: 0.6664 - val_loss: 876.4138 - val_binary_accuracy: 0.3132\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1481.1959 - binary_accuracy: 0.6657 - val_loss: 310.6397 - val_binary_accuracy: 0.7594\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 938us/step - loss: 1173.9662 - binary_accuracy: 0.6665 - val_loss: 311.2191 - val_binary_accuracy: 0.7348\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 903.9118 - binary_accuracy: 0.6674 - val_loss: 301.5337 - val_binary_accuracy: 0.3141\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 881us/step - loss: 722.1693 - binary_accuracy: 0.6712 - val_loss: 106.0000 - val_binary_accuracy: 0.6141\n",
      "116/116 [==============================] - 0s 536us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 986us/step - loss: 10233.2666 - binary_accuracy: 0.6500 - val_loss: 1830.1555 - val_binary_accuracy: 0.7846\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 972us/step - loss: 3531.6934 - binary_accuracy: 0.6627 - val_loss: 5632.7441 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 902us/step - loss: 2862.5767 - binary_accuracy: 0.6600 - val_loss: 2461.7131 - val_binary_accuracy: 0.7850\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 2896.3308 - binary_accuracy: 0.6663 - val_loss: 138.8279 - val_binary_accuracy: 0.4511\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 2192.1008 - binary_accuracy: 0.6633 - val_loss: 3119.2668 - val_binary_accuracy: 0.7837\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 861us/step - loss: 1400.1138 - binary_accuracy: 0.6622 - val_loss: 3008.3574 - val_binary_accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 856us/step - loss: 1581.0748 - binary_accuracy: 0.6609 - val_loss: 1037.9393 - val_binary_accuracy: 0.7822\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 912us/step - loss: 959.4860 - binary_accuracy: 0.6647 - val_loss: 188.7599 - val_binary_accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 838us/step - loss: 1405.7000 - binary_accuracy: 0.6653 - val_loss: 1694.4629 - val_binary_accuracy: 0.2593\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 884.5834 - binary_accuracy: 0.6639 - val_loss: 466.7038 - val_binary_accuracy: 0.7841\n",
      "116/116 [==============================] - 0s 520us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 953us/step - loss: 3990.7305 - binary_accuracy: 0.6911 - val_loss: 1757.0240 - val_binary_accuracy: 0.7835\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 837us/step - loss: 2164.2705 - binary_accuracy: 0.6649 - val_loss: 999.9982 - val_binary_accuracy: 0.7590\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1674.6882 - binary_accuracy: 0.6633 - val_loss: 2150.6338 - val_binary_accuracy: 0.7789\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 864us/step - loss: 1620.2087 - binary_accuracy: 0.6642 - val_loss: 1078.0559 - val_binary_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 873us/step - loss: 2096.3975 - binary_accuracy: 0.6645 - val_loss: 2954.2478 - val_binary_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 865us/step - loss: 1294.9756 - binary_accuracy: 0.6670 - val_loss: 3017.8816 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 1630.7231 - binary_accuracy: 0.6661 - val_loss: 254.1408 - val_binary_accuracy: 0.7649\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 1113.1810 - binary_accuracy: 0.6676 - val_loss: 1229.4984 - val_binary_accuracy: 0.7765\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 867us/step - loss: 925.7076 - binary_accuracy: 0.6639 - val_loss: 1352.7297 - val_binary_accuracy: 0.2423\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 869us/step - loss: 1081.1580 - binary_accuracy: 0.6650 - val_loss: 456.8114 - val_binary_accuracy: 0.7780\n",
      "116/116 [==============================] - 0s 535us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 949us/step - loss: 4162.2881 - binary_accuracy: 0.6889 - val_loss: 4097.0703 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 2445.3833 - binary_accuracy: 0.6598 - val_loss: 5442.6758 - val_binary_accuracy: 0.7801\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2027.8385 - binary_accuracy: 0.6618 - val_loss: 3363.0691 - val_binary_accuracy: 0.7829\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 2100.1709 - binary_accuracy: 0.6629 - val_loss: 3468.8005 - val_binary_accuracy: 0.2420\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1905.7230 - binary_accuracy: 0.6636 - val_loss: 3150.1941 - val_binary_accuracy: 0.7842\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1760.0209 - binary_accuracy: 0.6620 - val_loss: 3662.3667 - val_binary_accuracy: 0.7762\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 863us/step - loss: 1038.5985 - binary_accuracy: 0.6652 - val_loss: 3067.8313 - val_binary_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 922us/step - loss: 1115.6046 - binary_accuracy: 0.6666 - val_loss: 134.9213 - val_binary_accuracy: 0.7779\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 1098.4966 - binary_accuracy: 0.6659 - val_loss: 2680.8845 - val_binary_accuracy: 0.7842\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 1007.7210 - binary_accuracy: 0.6684 - val_loss: 413.8708 - val_binary_accuracy: 0.7826\n",
      "116/116 [==============================] - 0s 535us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 7041.4946 - binary_accuracy: 0.6877 - val_loss: 2025.3313 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 858us/step - loss: 3982.2551 - binary_accuracy: 0.6640 - val_loss: 9241.1553 - val_binary_accuracy: 0.2231\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 3552.2124 - binary_accuracy: 0.6598 - val_loss: 2336.5781 - val_binary_accuracy: 0.7730\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 2464.4639 - binary_accuracy: 0.6634 - val_loss: 6083.9307 - val_binary_accuracy: 0.2245\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 2179.2620 - binary_accuracy: 0.6672 - val_loss: 1832.4368 - val_binary_accuracy: 0.7703\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 870us/step - loss: 2055.2988 - binary_accuracy: 0.6620 - val_loss: 480.4249 - val_binary_accuracy: 0.6056\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 871us/step - loss: 1458.6090 - binary_accuracy: 0.6689 - val_loss: 590.8512 - val_binary_accuracy: 0.7725\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 939us/step - loss: 1251.1865 - binary_accuracy: 0.6683 - val_loss: 1468.6262 - val_binary_accuracy: 0.2833\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 880us/step - loss: 1213.3011 - binary_accuracy: 0.6634 - val_loss: 683.3713 - val_binary_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 868us/step - loss: 663.7859 - binary_accuracy: 0.6664 - val_loss: 1114.1531 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 544us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 953us/step - loss: 5732.4478 - binary_accuracy: 0.6884 - val_loss: 4235.6543 - val_binary_accuracy: 0.7844\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 842us/step - loss: 4338.9727 - binary_accuracy: 0.6644 - val_loss: 4398.2686 - val_binary_accuracy: 0.7754\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 4198.6064 - binary_accuracy: 0.6632 - val_loss: 753.0707 - val_binary_accuracy: 0.7819\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 862us/step - loss: 3763.4998 - binary_accuracy: 0.6623 - val_loss: 636.4288 - val_binary_accuracy: 0.2650\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 854us/step - loss: 2338.9270 - binary_accuracy: 0.6637 - val_loss: 3888.3203 - val_binary_accuracy: 0.2562\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1985.4375 - binary_accuracy: 0.6633 - val_loss: 299.2677 - val_binary_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 886us/step - loss: 1460.9623 - binary_accuracy: 0.6692 - val_loss: 240.2148 - val_binary_accuracy: 0.6148\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 883us/step - loss: 1441.7552 - binary_accuracy: 0.6623 - val_loss: 1128.6860 - val_binary_accuracy: 0.7839\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 857us/step - loss: 1276.3862 - binary_accuracy: 0.6699 - val_loss: 386.3705 - val_binary_accuracy: 0.7755\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 866us/step - loss: 1280.5848 - binary_accuracy: 0.6712 - val_loss: 2776.6292 - val_binary_accuracy: 0.2433\n",
      "116/116 [==============================] - 0s 531us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 3677.2935 - binary_accuracy: 0.5724 - val_loss: 1267.7015 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 830us/step - loss: 1477.8114 - binary_accuracy: 0.6633 - val_loss: 315.8658 - val_binary_accuracy: 0.7682\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 879us/step - loss: 1273.9792 - binary_accuracy: 0.6648 - val_loss: 502.1401 - val_binary_accuracy: 0.2389\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 875us/step - loss: 1313.2629 - binary_accuracy: 0.6607 - val_loss: 1339.3414 - val_binary_accuracy: 0.2205\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 872us/step - loss: 1190.3060 - binary_accuracy: 0.6625 - val_loss: 346.8248 - val_binary_accuracy: 0.7837\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 874us/step - loss: 812.8262 - binary_accuracy: 0.6659 - val_loss: 1292.3849 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 887us/step - loss: 881.6235 - binary_accuracy: 0.6639 - val_loss: 109.1769 - val_binary_accuracy: 0.7852\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 885us/step - loss: 643.8155 - binary_accuracy: 0.6687 - val_loss: 811.8139 - val_binary_accuracy: 0.7837\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 914us/step - loss: 694.7151 - binary_accuracy: 0.6694 - val_loss: 1034.8409 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 893us/step - loss: 521.1730 - binary_accuracy: 0.6701 - val_loss: 1071.0017 - val_binary_accuracy: 0.2150\n",
      "116/116 [==============================] - 0s 531us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 5377.1743 - binary_accuracy: 0.5675 - val_loss: 419.5869 - val_binary_accuracy: 0.7595\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 848us/step - loss: 3332.7688 - binary_accuracy: 0.6656 - val_loss: 1003.8986 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 860us/step - loss: 2482.2009 - binary_accuracy: 0.6662 - val_loss: 980.6878 - val_binary_accuracy: 0.3254\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 1834.8995 - binary_accuracy: 0.6656 - val_loss: 1911.6897 - val_binary_accuracy: 0.7846\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 947us/step - loss: 1575.3730 - binary_accuracy: 0.6703 - val_loss: 841.0552 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 919us/step - loss: 1353.8799 - binary_accuracy: 0.6664 - val_loss: 437.6900 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 958us/step - loss: 1406.9690 - binary_accuracy: 0.6674 - val_loss: 1468.6920 - val_binary_accuracy: 0.7749\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 2ms/step - loss: 1195.1277 - binary_accuracy: 0.6670 - val_loss: 439.7466 - val_binary_accuracy: 0.7851\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 703.8597 - binary_accuracy: 0.6690 - val_loss: 1277.3002 - val_binary_accuracy: 0.2314\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 780.1929 - binary_accuracy: 0.6691 - val_loss: 560.9117 - val_binary_accuracy: 0.2862\n",
      "116/116 [==============================] - 0s 772us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 7535.8911 - binary_accuracy: 0.5811 - val_loss: 2761.1472 - val_binary_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 4595.8359 - binary_accuracy: 0.6644 - val_loss: 9886.4492 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 940us/step - loss: 3727.8591 - binary_accuracy: 0.6645 - val_loss: 649.4785 - val_binary_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 2808.2283 - binary_accuracy: 0.6639 - val_loss: 232.8890 - val_binary_accuracy: 0.7830\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 2119.9102 - binary_accuracy: 0.6634 - val_loss: 216.1212 - val_binary_accuracy: 0.5679\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 1658.3165 - binary_accuracy: 0.6635 - val_loss: 1856.9703 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 984us/step - loss: 1046.7334 - binary_accuracy: 0.6709 - val_loss: 1611.0145 - val_binary_accuracy: 0.7721\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 939us/step - loss: 1172.8738 - binary_accuracy: 0.6638 - val_loss: 908.3057 - val_binary_accuracy: 0.2561\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1174.2333 - binary_accuracy: 0.6645 - val_loss: 264.9835 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 959us/step - loss: 828.5417 - binary_accuracy: 0.6660 - val_loss: 1181.9263 - val_binary_accuracy: 0.7838\n",
      "116/116 [==============================] - 0s 548us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 6142.7363 - binary_accuracy: 0.6876 - val_loss: 3468.0671 - val_binary_accuracy: 0.7844\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 901us/step - loss: 4126.2910 - binary_accuracy: 0.6663 - val_loss: 4181.6641 - val_binary_accuracy: 0.7844\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 974us/step - loss: 2937.3787 - binary_accuracy: 0.6600 - val_loss: 439.8892 - val_binary_accuracy: 0.7387\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 939us/step - loss: 2409.3835 - binary_accuracy: 0.6616 - val_loss: 882.0490 - val_binary_accuracy: 0.7734\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 1825.0599 - binary_accuracy: 0.6658 - val_loss: 953.5054 - val_binary_accuracy: 0.3204\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 918us/step - loss: 1602.7001 - binary_accuracy: 0.6662 - val_loss: 1268.8220 - val_binary_accuracy: 0.2386\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 1392.5065 - binary_accuracy: 0.6667 - val_loss: 101.5539 - val_binary_accuracy: 0.4006\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 987us/step - loss: 1012.6751 - binary_accuracy: 0.6660 - val_loss: 322.7913 - val_binary_accuracy: 0.7714\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 999us/step - loss: 927.9795 - binary_accuracy: 0.6644 - val_loss: 821.2598 - val_binary_accuracy: 0.2869\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 940us/step - loss: 665.2085 - binary_accuracy: 0.6632 - val_loss: 208.2560 - val_binary_accuracy: 0.7650\n",
      "116/116 [==============================] - 0s 571us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 6148.5005 - binary_accuracy: 0.6841 - val_loss: 8991.4141 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3399.5583 - binary_accuracy: 0.6636 - val_loss: 4591.7227 - val_binary_accuracy: 0.7842\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 2483.7043 - binary_accuracy: 0.6653 - val_loss: 914.4630 - val_binary_accuracy: 0.7713\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 960us/step - loss: 1735.9425 - binary_accuracy: 0.6651 - val_loss: 2222.1111 - val_binary_accuracy: 0.7795\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 916us/step - loss: 1376.8181 - binary_accuracy: 0.6620 - val_loss: 487.1111 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 1110.6226 - binary_accuracy: 0.6612 - val_loss: 326.3943 - val_binary_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 925.6368 - binary_accuracy: 0.6696 - val_loss: 236.2908 - val_binary_accuracy: 0.7809\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 967us/step - loss: 725.5957 - binary_accuracy: 0.6666 - val_loss: 2210.5310 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 623.2579 - binary_accuracy: 0.6695 - val_loss: 364.5504 - val_binary_accuracy: 0.7822\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 960us/step - loss: 459.1366 - binary_accuracy: 0.6693 - val_loss: 96.9398 - val_binary_accuracy: 0.7634\n",
      "116/116 [==============================] - 0s 561us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 7727.1479 - binary_accuracy: 0.6841 - val_loss: 6274.9717 - val_binary_accuracy: 0.7842\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 5122.3999 - binary_accuracy: 0.6625 - val_loss: 1832.9934 - val_binary_accuracy: 0.7499\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3749.8120 - binary_accuracy: 0.6646 - val_loss: 1949.7723 - val_binary_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3074.5024 - binary_accuracy: 0.6618 - val_loss: 1547.2329 - val_binary_accuracy: 0.7600\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 943us/step - loss: 2153.3875 - binary_accuracy: 0.6640 - val_loss: 335.4565 - val_binary_accuracy: 0.7557\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 978us/step - loss: 1824.7073 - binary_accuracy: 0.6638 - val_loss: 3875.9746 - val_binary_accuracy: 0.7731\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 1592.6742 - binary_accuracy: 0.6656 - val_loss: 1358.9982 - val_binary_accuracy: 0.2480\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 1318.7889 - binary_accuracy: 0.6607 - val_loss: 368.5458 - val_binary_accuracy: 0.7719\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 990.5850 - binary_accuracy: 0.6653 - val_loss: 1446.9480 - val_binary_accuracy: 0.7823\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 943us/step - loss: 774.3927 - binary_accuracy: 0.6671 - val_loss: 83.8884 - val_binary_accuracy: 0.6401\n",
      "116/116 [==============================] - 0s 557us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 6438.8037 - binary_accuracy: 0.6610 - val_loss: 2408.0798 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 2985.9624 - binary_accuracy: 0.6630 - val_loss: 4133.9971 - val_binary_accuracy: 0.2530\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 1849.1310 - binary_accuracy: 0.6663 - val_loss: 897.2978 - val_binary_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 946us/step - loss: 1736.3037 - binary_accuracy: 0.6646 - val_loss: 3211.6809 - val_binary_accuracy: 0.2297\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 982us/step - loss: 1746.8981 - binary_accuracy: 0.6622 - val_loss: 170.6469 - val_binary_accuracy: 0.7787\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 1056.1864 - binary_accuracy: 0.6646 - val_loss: 1173.3499 - val_binary_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 1067.7357 - binary_accuracy: 0.6646 - val_loss: 104.9928 - val_binary_accuracy: 0.7363\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 768.7618 - binary_accuracy: 0.6639 - val_loss: 794.5137 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 668.8487 - binary_accuracy: 0.6670 - val_loss: 35.1967 - val_binary_accuracy: 0.7403\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 426.7421 - binary_accuracy: 0.6634 - val_loss: 94.8960 - val_binary_accuracy: 0.6828\n",
      "116/116 [==============================] - 0s 567us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5607.8994 - binary_accuracy: 0.6677 - val_loss: 3888.5566 - val_binary_accuracy: 0.7846\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 3530.4321 - binary_accuracy: 0.6641 - val_loss: 1796.7515 - val_binary_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 944us/step - loss: 2650.9771 - binary_accuracy: 0.6630 - val_loss: 700.0683 - val_binary_accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 970us/step - loss: 1824.5966 - binary_accuracy: 0.6620 - val_loss: 3672.1179 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 947us/step - loss: 1701.0992 - binary_accuracy: 0.6611 - val_loss: 284.8307 - val_binary_accuracy: 0.7852\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 1401.0677 - binary_accuracy: 0.6652 - val_loss: 792.0308 - val_binary_accuracy: 0.7808\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 939us/step - loss: 942.6697 - binary_accuracy: 0.6685 - val_loss: 1030.0432 - val_binary_accuracy: 0.7831\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 1193.7673 - binary_accuracy: 0.6652 - val_loss: 257.3745 - val_binary_accuracy: 0.7679\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 900.7610 - binary_accuracy: 0.6655 - val_loss: 1390.7717 - val_binary_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 667.2670 - binary_accuracy: 0.6700 - val_loss: 116.0069 - val_binary_accuracy: 0.7795\n",
      "116/116 [==============================] - 0s 557us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4526.1328 - binary_accuracy: 0.6897 - val_loss: 1569.4132 - val_binary_accuracy: 0.2347\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 2540.0605 - binary_accuracy: 0.6634 - val_loss: 4319.3818 - val_binary_accuracy: 0.7844\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 980us/step - loss: 2661.7593 - binary_accuracy: 0.6630 - val_loss: 882.0005 - val_binary_accuracy: 0.7815\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 1512.3718 - binary_accuracy: 0.6640 - val_loss: 704.3395 - val_binary_accuracy: 0.2478\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 1411.6265 - binary_accuracy: 0.6604 - val_loss: 3030.8232 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 1447.3170 - binary_accuracy: 0.6610 - val_loss: 470.6414 - val_binary_accuracy: 0.2740\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 817.7058 - binary_accuracy: 0.6622 - val_loss: 434.6060 - val_binary_accuracy: 0.2726\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 818.6975 - binary_accuracy: 0.6640 - val_loss: 124.3689 - val_binary_accuracy: 0.7819\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 947us/step - loss: 620.1022 - binary_accuracy: 0.6635 - val_loss: 247.6335 - val_binary_accuracy: 0.3180\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 458.3876 - binary_accuracy: 0.6645 - val_loss: 127.6358 - val_binary_accuracy: 0.2407\n",
      "116/116 [==============================] - 0s 561us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5888.1050 - binary_accuracy: 0.5772 - val_loss: 1181.6653 - val_binary_accuracy: 0.2910\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 3139.0540 - binary_accuracy: 0.6623 - val_loss: 2008.4102 - val_binary_accuracy: 0.2684\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 2067.3989 - binary_accuracy: 0.6646 - val_loss: 1598.1392 - val_binary_accuracy: 0.2752\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 921us/step - loss: 1794.8751 - binary_accuracy: 0.6670 - val_loss: 2790.4421 - val_binary_accuracy: 0.2277\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 1416.1656 - binary_accuracy: 0.6648 - val_loss: 371.8406 - val_binary_accuracy: 0.7760\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 1098.2936 - binary_accuracy: 0.6676 - val_loss: 2306.9053 - val_binary_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 1020.6468 - binary_accuracy: 0.6682 - val_loss: 272.3219 - val_binary_accuracy: 0.3017\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 842.8328 - binary_accuracy: 0.6615 - val_loss: 606.5717 - val_binary_accuracy: 0.2414\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 678.3884 - binary_accuracy: 0.6632 - val_loss: 257.6324 - val_binary_accuracy: 0.3080\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 558.2546 - binary_accuracy: 0.6633 - val_loss: 385.2798 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 574us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5387.2939 - binary_accuracy: 0.6856 - val_loss: 5227.3584 - val_binary_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 3921.0769 - binary_accuracy: 0.6617 - val_loss: 1370.8901 - val_binary_accuracy: 0.7822\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 2485.3108 - binary_accuracy: 0.6639 - val_loss: 619.5254 - val_binary_accuracy: 0.7813\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 2281.3191 - binary_accuracy: 0.6676 - val_loss: 1781.8250 - val_binary_accuracy: 0.2450\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 1580.9742 - binary_accuracy: 0.6646 - val_loss: 84.4653 - val_binary_accuracy: 0.7220\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 1249.9216 - binary_accuracy: 0.6629 - val_loss: 2704.8262 - val_binary_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 1242.0833 - binary_accuracy: 0.6682 - val_loss: 2356.8103 - val_binary_accuracy: 0.7713\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 920us/step - loss: 938.3743 - binary_accuracy: 0.6633 - val_loss: 1329.3942 - val_binary_accuracy: 0.7834\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 853.1506 - binary_accuracy: 0.6632 - val_loss: 1066.9225 - val_binary_accuracy: 0.7824\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 703.7270 - binary_accuracy: 0.6655 - val_loss: 225.9822 - val_binary_accuracy: 0.7806\n",
      "116/116 [==============================] - 0s 555us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4337.1929 - binary_accuracy: 0.6857 - val_loss: 9173.8711 - val_binary_accuracy: 0.2583\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 3927.1079 - binary_accuracy: 0.6650 - val_loss: 2344.2849 - val_binary_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 2781.2979 - binary_accuracy: 0.6611 - val_loss: 539.5810 - val_binary_accuracy: 0.7788\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 943us/step - loss: 2034.5576 - binary_accuracy: 0.6640 - val_loss: 508.1280 - val_binary_accuracy: 0.6861\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 1658.4163 - binary_accuracy: 0.6661 - val_loss: 1900.2372 - val_binary_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 1182.7524 - binary_accuracy: 0.6631 - val_loss: 1542.1404 - val_binary_accuracy: 0.3190\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 1160.0769 - binary_accuracy: 0.6675 - val_loss: 567.6251 - val_binary_accuracy: 0.2772\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 770.7689 - binary_accuracy: 0.6688 - val_loss: 885.6544 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 917.3785 - binary_accuracy: 0.6649 - val_loss: 98.6829 - val_binary_accuracy: 0.7797\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 1s 998us/step - loss: 499.8233 - binary_accuracy: 0.6683 - val_loss: 292.8875 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 542us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 7874.1128 - binary_accuracy: 0.6869 - val_loss: 4103.5439 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 4458.7261 - binary_accuracy: 0.6613 - val_loss: 1114.1300 - val_binary_accuracy: 0.7554\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 3378.0950 - binary_accuracy: 0.6675 - val_loss: 6606.0986 - val_binary_accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 2581.3826 - binary_accuracy: 0.6639 - val_loss: 1378.1277 - val_binary_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 941us/step - loss: 2360.6875 - binary_accuracy: 0.6649 - val_loss: 2858.7163 - val_binary_accuracy: 0.2513\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 1902.4725 - binary_accuracy: 0.6675 - val_loss: 2104.7722 - val_binary_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 951us/step - loss: 1301.0466 - binary_accuracy: 0.6651 - val_loss: 1747.4666 - val_binary_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 683.5457 - binary_accuracy: 0.6622 - val_loss: 1298.4629 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 1s 978us/step - loss: 725.2192 - binary_accuracy: 0.6680 - val_loss: 261.9017 - val_binary_accuracy: 0.7629\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 456.0720 - binary_accuracy: 0.6685 - val_loss: 104.5039 - val_binary_accuracy: 0.3535\n",
      "116/116 [==============================] - 0s 549us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 6335.0259 - binary_accuracy: 0.5958 - val_loss: 1237.3069 - val_binary_accuracy: 0.7815\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 952us/step - loss: 3926.5249 - binary_accuracy: 0.6647 - val_loss: 741.0692 - val_binary_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3041.8838 - binary_accuracy: 0.6648 - val_loss: 5373.8232 - val_binary_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 939us/step - loss: 2745.4338 - binary_accuracy: 0.6623 - val_loss: 1050.0565 - val_binary_accuracy: 0.7802\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 948us/step - loss: 1707.7222 - binary_accuracy: 0.6646 - val_loss: 3973.2041 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 938us/step - loss: 1600.0856 - binary_accuracy: 0.6644 - val_loss: 1144.6055 - val_binary_accuracy: 0.2854\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 943us/step - loss: 1622.2815 - binary_accuracy: 0.6651 - val_loss: 1638.0299 - val_binary_accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 984us/step - loss: 1078.1814 - binary_accuracy: 0.6690 - val_loss: 413.2239 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 1021.3542 - binary_accuracy: 0.6670 - val_loss: 910.1448 - val_binary_accuracy: 0.7841\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 940us/step - loss: 748.3429 - binary_accuracy: 0.6688 - val_loss: 1360.6293 - val_binary_accuracy: 0.7848\n",
      "116/116 [==============================] - 0s 561us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3607.2517 - binary_accuracy: 0.6910 - val_loss: 4965.0366 - val_binary_accuracy: 0.2367\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 938us/step - loss: 2655.9114 - binary_accuracy: 0.6624 - val_loss: 205.7333 - val_binary_accuracy: 0.7843\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 1750.0187 - binary_accuracy: 0.6637 - val_loss: 1334.0005 - val_binary_accuracy: 0.7684\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 944us/step - loss: 1145.4755 - binary_accuracy: 0.6650 - val_loss: 449.0667 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 892.8900 - binary_accuracy: 0.6661 - val_loss: 1990.0432 - val_binary_accuracy: 0.2231\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 702.5903 - binary_accuracy: 0.6650 - val_loss: 1755.8673 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 981us/step - loss: 617.6975 - binary_accuracy: 0.6680 - val_loss: 119.9248 - val_binary_accuracy: 0.7839\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 1s 967us/step - loss: 481.0689 - binary_accuracy: 0.6656 - val_loss: 235.9437 - val_binary_accuracy: 0.2863\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 942us/step - loss: 481.8860 - binary_accuracy: 0.6694 - val_loss: 146.5135 - val_binary_accuracy: 0.7807\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 945us/step - loss: 300.5973 - binary_accuracy: 0.6650 - val_loss: 666.2239 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 527us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4917.5845 - binary_accuracy: 0.6896 - val_loss: 13084.6562 - val_binary_accuracy: 0.2151\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 3425.5378 - binary_accuracy: 0.6636 - val_loss: 1152.0692 - val_binary_accuracy: 0.7834\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 945us/step - loss: 2449.4304 - binary_accuracy: 0.6656 - val_loss: 3903.4895 - val_binary_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 1732.1857 - binary_accuracy: 0.6590 - val_loss: 1283.7268 - val_binary_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 934us/step - loss: 1586.8077 - binary_accuracy: 0.6643 - val_loss: 1832.5411 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 955us/step - loss: 1403.5449 - binary_accuracy: 0.6678 - val_loss: 1112.0520 - val_binary_accuracy: 0.7817\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 1s 983us/step - loss: 1165.2170 - binary_accuracy: 0.6641 - val_loss: 1996.0062 - val_binary_accuracy: 0.7844\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 975.4266 - binary_accuracy: 0.6666 - val_loss: 574.8157 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 938us/step - loss: 834.4462 - binary_accuracy: 0.6696 - val_loss: 748.4512 - val_binary_accuracy: 0.2392\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 618.8245 - binary_accuracy: 0.6676 - val_loss: 206.1150 - val_binary_accuracy: 0.7745\n",
      "116/116 [==============================] - 0s 553us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 6337.2095 - binary_accuracy: 0.6866 - val_loss: 9662.8750 - val_binary_accuracy: 0.7846\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 990us/step - loss: 3595.7229 - binary_accuracy: 0.6639 - val_loss: 7574.6924 - val_binary_accuracy: 0.2311\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3140.1370 - binary_accuracy: 0.6629 - val_loss: 2802.5005 - val_binary_accuracy: 0.2329\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 2414.6567 - binary_accuracy: 0.6641 - val_loss: 1227.6379 - val_binary_accuracy: 0.2676\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 951us/step - loss: 1847.9602 - binary_accuracy: 0.6628 - val_loss: 1615.5137 - val_binary_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 1695.9446 - binary_accuracy: 0.6633 - val_loss: 2393.1355 - val_binary_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 1266.7444 - binary_accuracy: 0.6648 - val_loss: 2546.8662 - val_binary_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 943us/step - loss: 1000.0101 - binary_accuracy: 0.6677 - val_loss: 1165.9955 - val_binary_accuracy: 0.7829\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 930us/step - loss: 726.7070 - binary_accuracy: 0.6704 - val_loss: 378.5328 - val_binary_accuracy: 0.7839\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 668.0541 - binary_accuracy: 0.6685 - val_loss: 260.2669 - val_binary_accuracy: 0.3471\n",
      "116/116 [==============================] - 0s 543us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 4943.0513 - binary_accuracy: 0.5904 - val_loss: 7834.7764 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 2741.3906 - binary_accuracy: 0.6611 - val_loss: 3922.2573 - val_binary_accuracy: 0.2427\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 2545.0859 - binary_accuracy: 0.6597 - val_loss: 594.0759 - val_binary_accuracy: 0.2926\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 973us/step - loss: 1900.9575 - binary_accuracy: 0.6586 - val_loss: 2604.3198 - val_binary_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 1s 957us/step - loss: 1547.0051 - binary_accuracy: 0.6648 - val_loss: 1612.8739 - val_binary_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 1245.4712 - binary_accuracy: 0.6585 - val_loss: 146.3204 - val_binary_accuracy: 0.3169\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 1074.6848 - binary_accuracy: 0.6635 - val_loss: 592.8708 - val_binary_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 929us/step - loss: 644.8643 - binary_accuracy: 0.6685 - val_loss: 1970.7284 - val_binary_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 923us/step - loss: 633.1787 - binary_accuracy: 0.6651 - val_loss: 401.8418 - val_binary_accuracy: 0.2523\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 935us/step - loss: 513.4328 - binary_accuracy: 0.6659 - val_loss: 1207.9747 - val_binary_accuracy: 0.7846\n",
      "116/116 [==============================] - 0s 564us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5433.1440 - binary_accuracy: 0.6866 - val_loss: 2539.1064 - val_binary_accuracy: 0.7846\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 940us/step - loss: 4171.8452 - binary_accuracy: 0.6618 - val_loss: 7123.5415 - val_binary_accuracy: 0.2217\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 951us/step - loss: 2284.1111 - binary_accuracy: 0.6605 - val_loss: 666.4195 - val_binary_accuracy: 0.7789\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 1s 964us/step - loss: 1721.8550 - binary_accuracy: 0.6617 - val_loss: 1530.1913 - val_binary_accuracy: 0.2225\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 924us/step - loss: 1979.1998 - binary_accuracy: 0.6604 - val_loss: 665.7133 - val_binary_accuracy: 0.7821\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 1207.6553 - binary_accuracy: 0.6629 - val_loss: 2227.1956 - val_binary_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 921us/step - loss: 1075.3094 - binary_accuracy: 0.6642 - val_loss: 569.0369 - val_binary_accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 924us/step - loss: 815.3937 - binary_accuracy: 0.6652 - val_loss: 1061.3788 - val_binary_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 1050.7295 - binary_accuracy: 0.6655 - val_loss: 582.9888 - val_binary_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 632.1930 - binary_accuracy: 0.6644 - val_loss: 450.9072 - val_binary_accuracy: 0.7847\n",
      "116/116 [==============================] - 0s 554us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 5632.9595 - binary_accuracy: 0.6862 - val_loss: 5673.6191 - val_binary_accuracy: 0.2406\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 3999.1282 - binary_accuracy: 0.6644 - val_loss: 5795.5801 - val_binary_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 1s 984us/step - loss: 2902.9832 - binary_accuracy: 0.6632 - val_loss: 1361.1066 - val_binary_accuracy: 0.7807\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 2593.8540 - binary_accuracy: 0.6657 - val_loss: 179.6001 - val_binary_accuracy: 0.5235\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 1925.4832 - binary_accuracy: 0.6623 - val_loss: 1550.0966 - val_binary_accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 1445.5833 - binary_accuracy: 0.6666 - val_loss: 769.5472 - val_binary_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 922us/step - loss: 898.9773 - binary_accuracy: 0.6706 - val_loss: 762.2945 - val_binary_accuracy: 0.2503\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 922us/step - loss: 890.1268 - binary_accuracy: 0.6658 - val_loss: 1174.1917 - val_binary_accuracy: 0.7797\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 937us/step - loss: 849.5306 - binary_accuracy: 0.6652 - val_loss: 932.5075 - val_binary_accuracy: 0.2898\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 910us/step - loss: 604.1873 - binary_accuracy: 0.6661 - val_loss: 1685.0571 - val_binary_accuracy: 0.7849\n",
      "116/116 [==============================] - 0s 545us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1000us/step - loss: 3234.6987 - binary_accuracy: 0.6897 - val_loss: 567.3424 - val_binary_accuracy: 0.2995\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 1s 993us/step - loss: 1902.5930 - binary_accuracy: 0.6606 - val_loss: 3128.2722 - val_binary_accuracy: 0.7820\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 936us/step - loss: 2133.0586 - binary_accuracy: 0.6629 - val_loss: 2488.5627 - val_binary_accuracy: 0.2385\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 933us/step - loss: 983.0916 - binary_accuracy: 0.6629 - val_loss: 1350.4744 - val_binary_accuracy: 0.7703\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 919us/step - loss: 1178.7482 - binary_accuracy: 0.6700 - val_loss: 1062.6648 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 923us/step - loss: 776.9631 - binary_accuracy: 0.6646 - val_loss: 1795.3029 - val_binary_accuracy: 0.7827\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 694.9679 - binary_accuracy: 0.6633 - val_loss: 53.3659 - val_binary_accuracy: 0.3534\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 926us/step - loss: 538.5511 - binary_accuracy: 0.6679 - val_loss: 135.4170 - val_binary_accuracy: 0.7741\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 941us/step - loss: 432.2551 - binary_accuracy: 0.6657 - val_loss: 700.9067 - val_binary_accuracy: 0.7784\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 922us/step - loss: 361.2861 - binary_accuracy: 0.6671 - val_loss: 123.7159 - val_binary_accuracy: 0.7819\n",
      "116/116 [==============================] - 0s 551us/step\n",
      "Epoch 1/10\n",
      "522/522 [==============================] - 1s 1ms/step - loss: 7241.8926 - binary_accuracy: 0.6871 - val_loss: 6846.0610 - val_binary_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 3072.5044 - binary_accuracy: 0.6670 - val_loss: 4541.4614 - val_binary_accuracy: 0.7840\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 3174.7114 - binary_accuracy: 0.6614 - val_loss: 3490.9712 - val_binary_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 0s 924us/step - loss: 2798.4338 - binary_accuracy: 0.6639 - val_loss: 3032.4075 - val_binary_accuracy: 0.7830\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 0s 917us/step - loss: 2229.3928 - binary_accuracy: 0.6659 - val_loss: 1811.9430 - val_binary_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 0s 927us/step - loss: 1444.0009 - binary_accuracy: 0.6657 - val_loss: 810.7766 - val_binary_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 0s 931us/step - loss: 1315.2354 - binary_accuracy: 0.6680 - val_loss: 1058.4989 - val_binary_accuracy: 0.2279\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 0s 928us/step - loss: 1127.5175 - binary_accuracy: 0.6622 - val_loss: 1402.0469 - val_binary_accuracy: 0.7849\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 0s 925us/step - loss: 1099.1123 - binary_accuracy: 0.6668 - val_loss: 156.0490 - val_binary_accuracy: 0.4634\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 0s 932us/step - loss: 851.1087 - binary_accuracy: 0.6671 - val_loss: 862.4923 - val_binary_accuracy: 0.2458\n",
      "116/116 [==============================] - 0s 569us/step\n",
      "Epoch 1/10\n",
      "580/580 [==============================] - 1s 980us/step - loss: 4422.4106 - binary_accuracy: 0.5689 - val_loss: 2132.6772 - val_binary_accuracy: 0.7734\n",
      "Epoch 2/10\n",
      "580/580 [==============================] - 0s 826us/step - loss: 2042.8248 - binary_accuracy: 0.6642 - val_loss: 4219.7251 - val_binary_accuracy: 0.2199\n",
      "Epoch 3/10\n",
      "580/580 [==============================] - 0s 822us/step - loss: 1818.7333 - binary_accuracy: 0.6636 - val_loss: 3507.5195 - val_binary_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "580/580 [==============================] - 0s 821us/step - loss: 1560.7449 - binary_accuracy: 0.6677 - val_loss: 855.2022 - val_binary_accuracy: 0.7769\n",
      "Epoch 5/10\n",
      "580/580 [==============================] - 0s 820us/step - loss: 1464.5044 - binary_accuracy: 0.6643 - val_loss: 1617.3577 - val_binary_accuracy: 0.7846\n",
      "Epoch 6/10\n",
      "580/580 [==============================] - 0s 833us/step - loss: 1236.5349 - binary_accuracy: 0.6658 - val_loss: 921.1230 - val_binary_accuracy: 0.2338\n",
      "Epoch 7/10\n",
      "580/580 [==============================] - 0s 826us/step - loss: 1436.5488 - binary_accuracy: 0.6606 - val_loss: 216.7861 - val_binary_accuracy: 0.3450\n",
      "Epoch 8/10\n",
      "580/580 [==============================] - 0s 822us/step - loss: 1465.6650 - binary_accuracy: 0.6633 - val_loss: 629.7191 - val_binary_accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "580/580 [==============================] - 0s 819us/step - loss: 1139.4172 - binary_accuracy: 0.6648 - val_loss: 1335.3350 - val_binary_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "580/580 [==============================] - 0s 831us/step - loss: 1281.1218 - binary_accuracy: 0.6663 - val_loss: 563.9844 - val_binary_accuracy: 0.7839\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create the model based on hyperparameters\n",
    "def create_model(optimizer='adam', neurons_layer1=64, neurons_layer2=64):\n",
    "    model = Sequential()    \n",
    "    model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(neurons_layer1, activation='relu'))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[metrics_fn])\n",
    "    return model\n",
    "\n",
    "# Wrap the create_model function with KerasClassifier\n",
    "keras_model = KerasClassifier(model=create_model, neurons_layer1=64, neurons_layer2=64, metrics=[metrics_fn])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Define F1 score as the metric\n",
    "f1_scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the metric\n",
    "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=10, scoring=f1_scorer)\n",
    "# Perform grid search\n",
    "grid_result = grid.fit(X_train, y_train_one_hot, epochs=10, batch_size=64, validation_data=(X_val, y_val_one_hot), verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:16:33.679340244Z",
     "start_time": "2024-04-04T22:01:20.380478697Z"
    }
   },
   "id": "beed211fbf595f7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Best parameters found:  {'neurons_layer1': 32, 'neurons_layer2': 32, 'optimizer': 'rmsprop'}\n",
      "\n",
      "\n",
      "- Best F1 score found:  0.78\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"- Best parameters found: \", grid_result.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"- Best F1 score found: \", round(grid_result.best_score_,2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:22:52.840518556Z",
     "start_time": "2024-04-04T22:22:52.791365721Z"
    }
   },
   "id": "f1284f40f00ff475"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verification sur les données de test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc11681d19ba8d8f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 525us/step\n",
      "Best model performance:\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test avec le meilleur modèle\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "f1_best = f1_score(y_test_one_hot, y_pred_best, average='micro')\n",
    "\n",
    "# Afficher les résultats pour le meilleur modèle\n",
    "print(\"Best model performance:\")\n",
    "print(\"F1 Score:\", round(f1_best,3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:35:19.166212561Z",
     "start_time": "2024-04-04T22:35:18.858123697Z"
    }
   },
   "id": "3d6c90b612924247"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
